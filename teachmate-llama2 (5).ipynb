{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9195797,"sourceType":"datasetVersion","datasetId":5559303},{"sourceId":9244340,"sourceType":"datasetVersion","datasetId":5592168},{"sourceId":9293456,"sourceType":"datasetVersion","datasetId":5626415},{"sourceId":9305230,"sourceType":"datasetVersion","datasetId":5634677},{"sourceId":9305255,"sourceType":"datasetVersion","datasetId":5634700},{"sourceId":9348743,"sourceType":"datasetVersion","datasetId":5666582},{"sourceId":9348911,"sourceType":"datasetVersion","datasetId":5666718},{"sourceId":4298,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":3093,"modelId":735},{"sourceId":104449,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":68809,"modelId":91102},{"sourceId":11413,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":6206,"modelId":3301},{"sourceId":10716,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":8658,"modelId":1445}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Installing Dependencies","metadata":{}},{"cell_type":"code","source":"!pip install sentence-transformers PyPDF2  language-tool-python nltk","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T19:31:18.212617Z","iopub.execute_input":"2024-12-24T19:31:18.213055Z","iopub.status.idle":"2024-12-24T19:31:30.742934Z","shell.execute_reply.started":"2024-12-24T19:31:18.213006Z","shell.execute_reply":"2024-12-24T19:31:30.741891Z"}},"outputs":[{"name":"stdout","text":"Collecting sentence-transformers\n  Downloading sentence_transformers-3.3.1-py3-none-any.whl.metadata (10 kB)\nCollecting PyPDF2\n  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\nCollecting language-tool-python\n  Downloading language_tool_python-2.8.1-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.2.4)\nRequirement already satisfied: transformers<5.0.0,>=4.41.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.44.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.66.4)\nRequirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (2.4.0)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.14.0)\nRequirement already satisfied: huggingface-hub>=0.20.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.24.6)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (9.5.0)\nRequirement already satisfied: pip in /opt/conda/lib/python3.10/site-packages (from language-tool-python) (24.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from language-tool-python) (2.32.3)\nRequirement already satisfied: wheel in /opt/conda/lib/python3.10/site-packages (from language-tool-python) (0.43.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from nltk) (1.16.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.6.1)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.5.15)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.4)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.19.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->language-tool-python) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->language-tool-python) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->language-tool-python) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->language-tool-python) (2024.7.4)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.20.0->sentence-transformers) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\nDownloading sentence_transformers-3.3.1-py3-none-any.whl (268 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading language_tool_python-2.8.1-py3-none-any.whl (35 kB)\nInstalling collected packages: PyPDF2, language-tool-python, sentence-transformers\nSuccessfully installed PyPDF2-3.0.1 language-tool-python-2.8.1 sentence-transformers-3.3.1\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":" # Install the nltk library if you haven't already\nimport nltk\nnltk.download('punkt')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T19:31:34.745467Z","iopub.execute_input":"2024-12-24T19:31:34.746346Z","iopub.status.idle":"2024-12-24T19:31:36.722725Z","shell.execute_reply.started":"2024-12-24T19:31:34.746298Z","shell.execute_reply":"2024-12-24T19:31:36.721775Z"}},"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"!pip install faiss-gpu\nimport faiss\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T19:31:39.720432Z","iopub.execute_input":"2024-12-24T19:31:39.721106Z","iopub.status.idle":"2024-12-24T19:31:51.698418Z","shell.execute_reply.started":"2024-12-24T19:31:39.721070Z","shell.execute_reply":"2024-12-24T19:31:51.697481Z"}},"outputs":[{"name":"stdout","text":"Collecting faiss-gpu\n  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\nDownloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: faiss-gpu\nSuccessfully installed faiss-gpu-1.7.2\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import PyPDF2\nfrom sentence_transformers import SentenceTransformer\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T19:31:52.980642Z","iopub.execute_input":"2024-12-24T19:31:52.981448Z","iopub.status.idle":"2024-12-24T19:32:22.632227Z","shell.execute_reply.started":"2024-12-24T19:31:52.981414Z","shell.execute_reply":"2024-12-24T19:32:22.631549Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"# Data Extraction","metadata":{}},{"cell_type":"code","source":"def extract_text_with_metadata(pdf_paths):\n    paragraphs = []\n    metadata = []\n    \n    for name,pdf_path in pdf_paths:\n        with open(pdf_path, 'rb') as file:\n            reader = PyPDF2.PdfReader(file)\n            for page_num, page in enumerate(reader.pages):\n                page_text = page.extract_text()\n                if page_text:\n                    lines = page_text.split('\\n')\n                    page_paragraphs = '\\n'.join(lines) + '\\n\\n'\n                    # Split paragraphs\n                    split_paragraphs = page_paragraphs.split('\\n\\n')\n                    split_paragraphs = [p.strip() for p in split_paragraphs if p.strip()]\n                    paragraphs.extend(split_paragraphs)\n                    # Store metadata for each paragraph\n                    metadata.extend([(name, page_num + 2)] * len(split_paragraphs))\n    \n    return paragraphs, metadata\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T19:32:29.121220Z","iopub.execute_input":"2024-12-24T19:32:29.121814Z","iopub.status.idle":"2024-12-24T19:32:29.128180Z","shell.execute_reply.started":"2024-12-24T19:32:29.121785Z","shell.execute_reply":"2024-12-24T19:32:29.127245Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"pdf_paths = [(\"OS\",\"/kaggle/input/operating-systems/Abraham-Silberschatz-Operating-System-Concepts_removed.pdf\")]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T18:22:15.612312Z","iopub.execute_input":"2024-12-24T18:22:15.612610Z","iopub.status.idle":"2024-12-24T18:22:15.632054Z","shell.execute_reply.started":"2024-12-24T18:22:15.612584Z","shell.execute_reply":"2024-12-24T18:22:15.631338Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"pdf_paths = [(\"Distributed Systems\",\n              \"/kaggle/input/distributed-textbook/Distributed_Systems_trimmed.pdf\")]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T19:32:35.618669Z","iopub.execute_input":"2024-12-24T19:32:35.618994Z","iopub.status.idle":"2024-12-24T19:32:35.623490Z","shell.execute_reply.started":"2024-12-24T19:32:35.618965Z","shell.execute_reply":"2024-12-24T19:32:35.622252Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"paragraphs,metadata = extract_text_with_metadata(pdf_paths)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T19:32:39.947358Z","iopub.execute_input":"2024-12-24T19:32:39.948247Z","iopub.status.idle":"2024-12-24T19:32:53.546840Z","shell.execute_reply.started":"2024-12-24T19:32:39.948180Z","shell.execute_reply":"2024-12-24T19:32:53.546155Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"len(paragraphs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T19:33:04.904834Z","iopub.execute_input":"2024-12-24T19:33:04.905563Z","iopub.status.idle":"2024-12-24T19:33:04.910894Z","shell.execute_reply.started":"2024-12-24T19:33:04.905527Z","shell.execute_reply":"2024-12-24T19:33:04.910011Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"610"},"metadata":{}}],"execution_count":8},{"cell_type":"markdown","source":"# Encoding","metadata":{}},{"cell_type":"code","source":"model = SentenceTransformer('all-MiniLM-L6-v2')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T19:33:12.927344Z","iopub.execute_input":"2024-12-24T19:33:12.928151Z","iopub.status.idle":"2024-12-24T19:33:16.312691Z","shell.execute_reply.started":"2024-12-24T19:33:12.928118Z","shell.execute_reply":"2024-12-24T19:33:16.311918Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d0cbb591b40a46469d32bd8cfde0a284"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc221c0f96a44a958d0703c5f5fde2fa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"497b74d1fe104e3693d4404952442a83"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f577910ae05c4d408e5e566515ae3b30"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b10dd7bccee4f1baa658f38a5cebc54"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"26606774f21a489199a500ea567c11a9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"59712e7beef9416ca2cc05b277b7a1f1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00e0e9e284ba47b991a38bb51a2fd6c0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"590022d03e1a4c7ca73c0027cdcaffa2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d26c7ba92d3d4a5b8cc6e9ea4cdf93b9"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"954a5d4bfc6b4d3c89758e19d6e99b8d"}},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"paragraph_embeddings = model.encode(paragraphs, show_progress_bar=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T19:33:20.837926Z","iopub.execute_input":"2024-12-24T19:33:20.838301Z","iopub.status.idle":"2024-12-24T19:33:24.069289Z","shell.execute_reply.started":"2024-12-24T19:33:20.838270Z","shell.execute_reply":"2024-12-24T19:33:24.068144Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0f7043cecf34a20872b916290944655"}},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"import numpy as np\nparagraph_embeddings = paragraph_embeddings / np.linalg.norm(paragraph_embeddings, axis=1, keepdims=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T19:33:28.038544Z","iopub.execute_input":"2024-12-24T19:33:28.039240Z","iopub.status.idle":"2024-12-24T19:33:28.044018Z","shell.execute_reply.started":"2024-12-24T19:33:28.039208Z","shell.execute_reply":"2024-12-24T19:33:28.043130Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"dimension = paragraph_embeddings.shape[1]\nfaiss_index = faiss.IndexFlatIP(dimension)\nfaiss_index.add(paragraph_embeddings)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T19:33:31.174973Z","iopub.execute_input":"2024-12-24T19:33:31.175863Z","iopub.status.idle":"2024-12-24T19:33:31.181079Z","shell.execute_reply.started":"2024-12-24T19:33:31.175818Z","shell.execute_reply":"2024-12-24T19:33:31.179982Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"def query_faiss_index(query, top_k):\n    query_embedding = model.encode([query])\n    distances, indices = faiss_index.search(query_embedding, top_k)\n    return [paragraphs[i] for i in indices[0]]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T19:33:34.348043Z","iopub.execute_input":"2024-12-24T19:33:34.348950Z","iopub.status.idle":"2024-12-24T19:33:34.353547Z","shell.execute_reply.started":"2024-12-24T19:33:34.348916Z","shell.execute_reply":"2024-12-24T19:33:34.352616Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Loading LLM Model","metadata":{}},{"cell_type":"code","source":"# Load model directly\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\n\ntokenizer = AutoTokenizer.from_pretrained(\"/kaggle/input/llama-2/pytorch/7b-chat-hf/1\", trust_remote_code=True)\nllm_model = AutoModelForCausalLM.from_pretrained(\"/kaggle/input/llama-2/pytorch/7b-chat-hf/1\", trust_remote_code=True,device_map=\"auto\", offload_folder=\"offload\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T19:33:54.632074Z","iopub.execute_input":"2024-12-24T19:33:54.632900Z","iopub.status.idle":"2024-12-24T19:35:14.576595Z","shell.execute_reply.started":"2024-12-24T19:33:54.632866Z","shell.execute_reply":"2024-12-24T19:35:14.575654Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d788a94bbdf4281b6f66efe7d9846e8"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:572: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:572: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"# Generate insight simple","metadata":{}},{"cell_type":"code","source":"def generate_insight_simple(query, context):\n    # Construct a structured prompt with a clear marker\n    combined_input = (\n        f\"\\nINSTRUCTIONS:\\n\"\n        f\"Answer the users QUESTION concisely using the DOCUMENT text above.\\n\"\n        f\"If the DOCUMENT doesn’t contain the facts to answer the QUESTION return NONE\\n\"\n        f\"Use simple terms so that the user can understand\\n\"\n        f\"DOCUMENT:\\n\"\n        f\"{context}\"\n        f\"\\nQUESTION:\\n\"\n        f\"{query}\"        \n        f\"\\nANSWER:\\n\"\n        \n    )\n\n    if tokenizer.pad_token is None:\n        tokenizer.pad_token = tokenizer.eos_token\n\n    # Encode the prompt\n    inputs = tokenizer.encode_plus(\n        combined_input,\n        return_tensors='pt',\n        padding=True,\n        truncation=True,\n        max_length=4000\n    ).to('cuda')\n\n    input_ids = inputs['input_ids']\n    attention_mask = inputs['attention_mask']\n\n    # Generate the output using the model\n    outputs = llm_model.generate(\n        input_ids,\n        attention_mask=attention_mask,\n        max_new_tokens=500,\n        num_return_sequences=1,\n        no_repeat_ngram_size=3,\n        temperature=0.3,\n        top_k=10,\n        do_sample=True,\n        pad_token_id=tokenizer.eos_token_id\n    )\n\n\n    # Decode the generated text\n    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    answer_start = generated_text.index(\"ANSWER:\") + len(\"ANSWER:\")\n    cleaned_output = generated_text[answer_start:].strip()                      \n                                        \n    \n\n\n    return generated_text,cleaned_output\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T19:36:00.338566Z","iopub.execute_input":"2024-12-24T19:36:00.339430Z","iopub.status.idle":"2024-12-24T19:36:00.346113Z","shell.execute_reply.started":"2024-12-24T19:36:00.339393Z","shell.execute_reply":"2024-12-24T19:36:00.345248Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"# Context cleaning","metadata":{}},{"cell_type":"code","source":"import re\ndef clean_context(context):\n    # Remove newline characters and replace them with spaces\n    cleaned_text = context.replace('\\n', ' ')\n    \n    # Remove any sequences like \"DS 4.02 downloaded by UMAG @AM.AMRITA.EDU1.2\"\n    cleaned_text = re.sub(r'DS \\d+\\.\\d+ downloaded by .*?@.*?\\d+\\.\\d+', '', cleaned_text)\n    \n    # Remove extra spaces\n    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text).strip()\n    \n    return cleaned_text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T19:36:06.317618Z","iopub.execute_input":"2024-12-24T19:36:06.318622Z","iopub.status.idle":"2024-12-24T19:36:06.323219Z","shell.execute_reply.started":"2024-12-24T19:36:06.318585Z","shell.execute_reply":"2024-12-24T19:36:06.322477Z"}},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"# Evaluation Metrics","metadata":{}},{"cell_type":"code","source":"from sentence_transformers import CrossEncoder\nimport language_tool_python\n# Initialize CrossEncoder models for query relevance and context fidelity\nquery_relevance_model = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')\n#context_fidelity_model = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T19:36:37.308083Z","iopub.execute_input":"2024-12-24T19:36:37.308938Z","iopub.status.idle":"2024-12-24T19:36:38.640963Z","shell.execute_reply.started":"2024-12-24T19:36:37.308904Z","shell.execute_reply":"2024-12-24T19:36:38.640011Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/794 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db673d49ad174f789d6359ecec271b02"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb34e15a811043368d678eefecf8ed5b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/316 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d592cc2b8a0459daa18839600b0c11a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"10a4403b4cc747d4bd483f14801b5c2d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1aae423515ca4d38917e55916705efe1"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"def calculate_weighted_context_embedding(query, top_k):\n    # Retrieve top-k documents\n    results = query_faiss_index(query, top_k)\n    \n    # Assign weights based on rank\n    weights = [1 / (rank + 1) for rank in range(len(results))]  # Example: Exponential decay\n    normalized_weights = [w / sum(weights) for w in weights]  # Normalize to sum to 1\n    \n    # Encode embeddings and compute the weighted average\n    doc_embeddings = [model.encode(result, convert_to_tensor=True) for result in results]\n    weighted_embedding = sum(weight * embedding for weight, embedding in zip(normalized_weights, doc_embeddings))\n    \n    return weighted_embedding\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T19:36:43.684006Z","iopub.execute_input":"2024-12-24T19:36:43.684419Z","iopub.status.idle":"2024-12-24T19:36:43.690560Z","shell.execute_reply.started":"2024-12-24T19:36:43.684386Z","shell.execute_reply":"2024-12-24T19:36:43.689552Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"import torch\nfrom sentence_transformers import SentenceTransformer, util\nimport language_tool_python\ndef evaluation_metrics(query, context, answer):\n    # Compute query relevance score\n    query_relevance_score = query_relevance_model.predict([(query, answer)])[0]\n    context_embedding = calculate_weighted_context_embedding(query, top_k=3)\n    answer_embedding = model.encode(answer, convert_to_tensor=True)\n    \n    # Compute context fidelity score\n    #context_fidelity_score = context_fidelity_model.predict([(context, answer)])[0]\n    similarity_score_cf = util.pytorch_cos_sim(answer_embedding, context_embedding)\n    \n    # Normalize scores to percentages using sigmoid\n    query_relevance_percentage = torch.sigmoid(torch.tensor(query_relevance_score)).item() * 100\n    #context_fidelity_percentage = torch.sigmoid(torch.tensor(context_fidelity_score)).item() * 100\n    \n    # Grammar checking using LanguageTool\n    tool = language_tool_python.LanguageTool('en-US')  \n    matches = tool.check(answer)\n    \n    # Calculate the number of errors\n    num_errors = len(matches)\n    \n    # Calculate the percentage of errors per word\n    num_words = len(answer.split())\n    error_percentage = (num_errors / num_words) * 100 if num_words > 0 else 0\n\n    return query_relevance_percentage, similarity_score_cf.item()*100, error_percentage\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T19:39:58.677067Z","iopub.execute_input":"2024-12-24T19:39:58.678077Z","iopub.status.idle":"2024-12-24T19:39:58.687436Z","shell.execute_reply.started":"2024-12-24T19:39:58.678029Z","shell.execute_reply":"2024-12-24T19:39:58.686359Z"}},"outputs":[],"execution_count":22},{"cell_type":"markdown","source":"# Testing","metadata":{}},{"cell_type":"markdown","source":"Evaluation criteria:\nClarity (3 points): Is the answer clear, unambiguous, and free of jargon?\nConciseness (2 points): Is the answer concise, avoiding unnecessary information?\nRelevance (3 points): Does the answer directly address the student’s question?\nGrammar & Language (2 points): Is the grammar correct and the language simple enough for students to understand?","metadata":{}},{"cell_type":"markdown","source":"# OOPS","metadata":{}},{"cell_type":"markdown","source":"# **Q1**\n","metadata":{}},{"cell_type":"code","source":"query = \"What are the main purposes of an operating system?\"\nresults = query_faiss_index(query, top_k = 3)\npara = \"\"\nfor result in results:\n    para = para + result\n#context = extract_relevant_sentences(query, para, similarity_threshold=0.4)\ncontext = para\ncontext = clean_context(context)\ninsight,answer= generate_insight_simple(query, context)\n\nprint(\"Generated Insight:\")\nprint(insight)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T09:32:19.111612Z","iopub.execute_input":"2024-12-24T09:32:19.112291Z","iopub.status.idle":"2024-12-24T09:32:46.045693Z","shell.execute_reply.started":"2024-12-24T09:32:19.112256Z","shell.execute_reply":"2024-12-24T09:32:46.044830Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5602878ba8f6464c919396903bd0fc9e"}},"metadata":{}},{"name":"stdout","text":"Generated Insight:\n\nINSTRUCTIONS:\nAnswer the users QUESTION concisely using the DOCUMENT text above.\nIf the DOCUMENT doesn’t contain the facts to answer the QUESTION return NONE\nUse simple terms so that the user can understand\nDOCUMENT:\n4 Chapter 1 Introduction user 1user 2user 3 computer hardwareoperating systemsystem and application programscompiler assembler text editor database systemuser n… … Figure 1.1 Abstract view of the components of a computer system. 1.1 What Operating Systems Do We begin our discussion by looking at the operating system’s role in the overall computer system. A computer system can be divided roughly into four components: the hardware, theoperating system, theapplication programs, and the users (Figure 1.1). The hardware —the central processing unit (CPU),t h e memory ,a n dt h e input/output (I/O)devices —provides the basic computing resources for the system. The application programs —such as word processors, spreadsheets, compilers, and Web browsers—deﬁne the ways in which these resources are used to solve users’ computing problems. The operating system controls the hardware and coordinates its use among the various application programs forthe various users. We can also view a computer system as consisting of hardware, software, and data. The operating system provides the means for proper use of these resources in the operation of the computer system. An operating system issimilar to a government. Like a government, it performs no useful function byitself. It simply provides an environment within which other programs can do useful work. To understand more fully the operating system’s role, we next explore operating systems from two viewpoints: that of the user and that of the system. 1.1.1 User View The user’s view of the computer varies according to the interface being used. Most computer users sit in front of a PC,c o n s i s t i n go fam o n i t o r , keyboard, mouse, and system unit. Such a system is designed for one user1CHAPTER Introduction Anoperating system is a program that manages a computer’s hardware. It also provides a basis for application programs and acts as an intermediary between the computer user and the computer hardware. An amazing aspect of operating systems is how they vary in accomplishing these tasks. Mainframe operating systems are designed primarily to optimize utilization of hardware. Personal computer ( PC) operating systems support complex games, business applications, and everything in between. Operating systems for mobile com- puters provide an environment in which a user can easily interface with the computer to execute programs. Thus, some operating systems are designed to beconvenient, others to be efﬁcient, and others to be some combination of the two. Before we can explore the details of computer system operation, we need to know something about system structure. We thus discuss the basic functions of system startup, I/O, and storage early in this chapter. We also describe the basic computer architecture that makes it possible to write a functional operating system. Because an operating system is large and complex, it must be created piece by piece. Each of these pieces should be a well-delineated portion of the system, with carefully deﬁned inputs, outputs, and functions. In this chapter, we provide a general overview of the major components of a contemporary computer system as well as the functions provided by the operating system. Additionally, we cover several other topics to help set the stage for the remainder of this text: data structures used in operating systems, computing environments, and open-source operating systems. CHAPTER OBJECTIVES •To describe the basic organization of computer systems. •To provide a grand tour of the major components of operating systems. •To give an overview of the many types of computing environments. •To explore several open-source operating systems. 32CHAPTER Operating - System Structures An operating system provides the environment within which programs are executed. Internally, operating systems vary greatly in their makeup, since they are organized along many differ ent lines. The design of a new operating system is a major task. It is important that the goals of the system be well deﬁned before the design begins. These goals form the basis for choices among various algorithms and strategies. We can view an operating system from several vantage points. One view focuses on the services that the system provides; another, on the interface that it makes available to users and programmers; a third, on its components and their interconnections. In this chapter, we explore all three aspects of operating systems, showing the viewpoints of users, programmers, and operating system designers. We consider what services an operating system provides, how they are provided, how they are debugged, and what the various methodologies are for designing such systems. Finally, we describe how operating systems are created and how a computer starts its operating system. CHAPTER OBJECTIVES •To describe the services an operating system provides to users, processes, and other systems. •To discuss the various ways of structuring an operating system. •To explain how operating systems are installed and customized and how they boot. 2.1 Operating-System Services An operating system provides an environment for the execution of programs. It provides certain services to programs and to the users of those programs. The speciﬁc services provided, of course, differ from one operating system to another, but we can identify common classes. These operating system services are provided for the convenience of the programmer, to make the programming 55\nQUESTION:\nWhat are the main purposes of an operating system?\nANSWER:\nThe main purposesof an operating systems include:\n1. Providing an environmentfor the executionof programs\n2. Managing computer hardware resources such as CPU, memory, and I/ O devices\n3. Coordinating the use of hardware resourcesamong different application programs\n4. Provide a user interface for interacting with thecomputer\n5. Loading and starting programs\n6. Manage and organize files and directories\n7. Provides security features to protect the computer and its data\n8. Manages the computer's power and resource allocation\n9. Providedebugging and troubleshooting tools\n10. Supports multitasking and multithreading\n\nNote: The above answer is based on the information provided in the document you uploaded.\n","output_type":"stream"}],"execution_count":102},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"qr,cf,gram = evaluation_metrics(query,context,answer)\nprint(f\"Query relevance Score: {qr}\\n\"\n     f\"Context Fidelity Score: {cf}\\n\"\n     f\"Error Percentage: {gram:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T09:34:58.064886Z","iopub.execute_input":"2024-12-24T09:34:58.065301Z","iopub.status.idle":"2024-12-24T09:35:38.952411Z","shell.execute_reply.started":"2024-12-24T09:34:58.065270Z","shell.execute_reply":"2024-12-24T09:35:38.951585Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c2c94d256be8489ea68d811bd4aa209d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"635ca59d2fe94c3daf8300f2a413d4ce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0677aef3e8534526b21b7b938c619e39"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a905a6273b04d4c94bf2d61569d3761"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"038a09c75f0e45a785c478522349a1e9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ebba2f46e1f34850b6a1be2b86338558"}},"metadata":{}},{"name":"stdout","text":"Query relevance Score: 99.99539852142334\nContext Fidelity Score: 74.63601231575012\nError Percentage: 6.86%\n","output_type":"stream"}],"execution_count":107},{"cell_type":"code","source":"qr,cf,gram = evaluation_metricss(query,context,answer)\nprint(f\"Query relevance Score: {qr}\\n\"\n     f\"Context Fidelity Score: {cf}\\n\"\n     f\"Error Percentage: {gram:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T08:25:11.953312Z","iopub.execute_input":"2024-12-24T08:25:11.953934Z","iopub.status.idle":"2024-12-24T08:25:26.086908Z","shell.execute_reply.started":"2024-12-24T08:25:11.953902Z","shell.execute_reply":"2024-12-24T08:25:26.085491Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f422b72d5c934b8698380d1504a7329a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3901c34721834b659393a089feb2fd82"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7747de20c58c429cb9f5f8b2e316728d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"31cfe1da96674532b90d06cbffee3f7b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"942fff95b58c4de0b38d2de9f41f7f13"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"abe736bf3a9742f8b8041ace0b224ac0"}},"metadata":{}},{"name":"stdout","text":"Query relevance Score: 85.43357849121094\nContext Fidelity Score: 76.58169269561768\nError Percentage: 4.35%\n","output_type":"stream"}],"execution_count":32},{"cell_type":"markdown","source":"Overall grade - 8.25/10","metadata":{}},{"cell_type":"markdown","source":"# **Q2**","metadata":{}},{"cell_type":"code","source":"\nquery = \"Explain the concept of multiprogramming.\"\nresults = query_faiss_index(query, top_k = 3)\npara = \"\"\nfor result in results:\n    para = para + result\n#context = extract_relevant_sentences(query, para, similarity_threshold=0.4)\ncontext = para\ncontext = clean_context(context)\ninsight,answer= generate_insight_simple(query, context)\n\nprint(\"Generated Insight:\")\nprint(insight)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T09:35:47.540845Z","iopub.execute_input":"2024-12-24T09:35:47.541696Z","iopub.status.idle":"2024-12-24T09:36:08.623715Z","shell.execute_reply.started":"2024-12-24T09:35:47.541657Z","shell.execute_reply":"2024-12-24T09:36:08.622843Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c88988f0f536453b959d0804a827fe60"}},"metadata":{}},{"name":"stdout","text":"Generated Insight:\n\nINSTRUCTIONS:\nAnswer the users QUESTION concisely using the DOCUMENT text above.\nIf the DOCUMENT doesn’t contain the facts to answer the QUESTION return NONE\nUse simple terms so that the user can understand\nDOCUMENT:\n3CHAPTER Processes Early computers allowed only one program to be executed at a time. This program had complete control of the system and had access to all the system’s resources. In contrast, contemporary computer systems allow multiple pro- grams to be loaded into memory and executed concurrently. This evolution required ﬁrmer control and more compartmentalization of the various pro- grams; and these needs resulted in the notion of a process , which is a program in execution. A process is the unit of work in a modern time-sharing system. The more complex the operating system is, the more it is expected to do on behalf of its users. Although its main concern is the execution of user programs, it also needs to take care of various system tasks that are better left outside the kernel itself. A system therefore consists of a collection of processes: operating- system processes executing system code and user processes executing user code. Potentially, all these processes ca n execute concurrently, with the CPU (or CPUs) multiplexed among them. By switching the CPU between processes, the operating system can make the computer more productive. In this chapter, you will read about what processes are and how they work. CHAPTER OBJECTIVES •To introduce the notion of a process—a program in execution, which forms the basis of all computation. •To describe the various features of processes, including scheduling, creation, and termination. •To explore interprocess communication using shared memory and mes- sage passing. •To describe communication in client–server systems. 3.1 Process Concept A question that arises in discussing operating systems involves what to call all the CPU activities. A batch system executes jobs , whereas a time-shared 10520 Chapter 1 Introduction Multiprogrammed systems provide an environment in which the various system resources (for example, CPU, memory, and peripheral devices) are utilized effectively, but they do not provide for user interaction with the computer system. Time sharing (ormultitasking ) is a logical extension of multiprogramming. In time-sharing systems, the CPU executes multiple jobs by switching among them, but the switches occur so frequently that the users can interact with each program while it is running. Time sharing requires an interactive computer system, which provides direct communication between the user and the system. The user givesinstructions to the operating system or to a program directly, using a input device such as a keyboard, mouse, touch pad, or touch screen, and waits for immediate results on an output device. Accordingly, the response time should be short—typically less than one second. A time-shared operating system allows many users to share the computer simultaneously. Since each action or command in a time-shared system tends to be short, only a little CPU time is needed for each user. As the system switches rapidly from one user to the next, each user is given the impression that the entire computer system is dedicated to his use, even though it is being shared among many users. A time-shared operating system uses CPU scheduling and multiprogram- ming to provide each user with a small portion of a time-shared computer.Each user has at least one separate program in memory. A program loaded into memory and executing is called a process . When a process executes, it typically executes for only a short time before i t either ﬁnishes or needs to perform I/O. I/Omay be interactive; that is, output goes to a display for the user, and input comes from a user keyboard, mouse, or other device. Since interactive I/O typically runs at “people speeds, ”it may take a long time to complete. Input, for example, may be bounded by the user’s typing speed; seven characters persecond is fast for people but incredibly slow for computers. Rather than letthe CPU sit idle as this interactive input takes place, the operating system will rapidly switch the CPU to the program of some other user. Time sharing and multiprogramming require that several jobs be kept simultaneously in memory. If several jobs are ready to be brought into memory,and if there is not enough room for all of them, then the system must choose among them. Making this decision involves job scheduling , which we discuss in Chapter 6. When the operating system selects a job from the job pool, it loadsthat job into memory for execution. Having several programs in memory atthe same time requires some form of memory management, which we cover in Chapters 8 and 9. In addition, if several jobs are ready to run at the same time, the system must choose which job will run ﬁrst. Making this decision is CPU scheduling , which is also discussed in Chapter 6. Finally, running multiple jobs concurrently requires that their ability to affect one another be limited in all phases of the operating system, including process scheduling, disk storage, and memory management. We discuss these considerations throughout thetext. In a time-sharing system, the operating system must ensure reasonable response time. This goal is sometimes accomplished through swapping , whereby processes are swapped in and out of main memory to the disk. A morecommon method for ensuring reasonable response time is virtual memory ,a technique that allows the execution of a process that is not completely in1.4 Operating-System Structure 19 job 10 Maxoperating system job 2 job 3 job 4 Figure 1.9 Memory layout for a multiprogramming system. 1.4 Operating-System Structure Now that we have discussed basic computer-system organization and archi- tecture, we are ready to talk about operating systems. An operating system provides the environment within which programs are executed. Internally, operating systems vary greatly in their makeup, since they are organizedalong many different lines. There a re, however, many commonalities, which we consider in this section. One of the most important aspects of operating systems is the ability to multiprogram. A single program cannot, in general, keep either the CPU or the I/O devices busy at all times. Single users frequently have multiple programs running. Multiprogramming increases CPU utilization by organizing jobs (code and data) so that the CPU always has one to execute. The idea is as follows: The operating system keeps several jobs in memory simultaneously (Figure 1.9). Since, in general, main memory is too small to accommodate all jobs, the jobs are kept initially on the disk in the job pool . This pool consists of all processes residing on disk awaiting allocation of mainmemory. The set of jobs in memory can be a subset of the jobs kept in the job pool. The operating system picks and begins to execute one of the jobs in memory. Eventually, the job may have to wait for some task, such as an I/O operation, to complete. In a non-multiprogrammed system, the CPU would sit idle. In a multiprogrammed system, the operating system simply switches to, and executes, another job. When that job needs to wait, the CPU switches to another job, and so on. Eventually, the ﬁrst job ﬁnishes waiting and gets the CPU back. As long as at least one job needs to execute, the CPU is never idle. This idea is common in other life situations. A lawyer does not work for only one client at a time, for example. While one case is waiting to go to trial or have papers typed, the lawyer can work on another case. If he has enoughclients, the lawyer will never be idle for lack of work. (Idle lawyers tend to become politicians, so there is a certain social value in keeping lawyers busy.)\nQUESTION:\nExplain the concept of multiprogramming.\nANSWER:\nMultipro gramming is the capability of an operating system to allow multiple programs to be run concurrently in memory, utilizing the computer's resources more efficiently. In multipro gram- mming, multiple jobs are stored in memory and the CPU switched among them rapidly, giving the impression to each user that the computer is dedicated exclusively to their use. This allows for more efficient use of the computer resources as multiple tasks can be performed simultaneously.\n","output_type":"stream"}],"execution_count":108},{"cell_type":"code","source":"qr,cf,gram = evaluation_metrics(query,context,answer)\nprint(f\"Query relevance Score: {qr}\\n\"\n     f\"Context Fidelity Score: {cf}\\n\"\n     f\"Error Percentage: {gram:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T09:36:22.264750Z","iopub.execute_input":"2024-12-24T09:36:22.265450Z","iopub.status.idle":"2024-12-24T09:37:04.983739Z","shell.execute_reply.started":"2024-12-24T09:36:22.265417Z","shell.execute_reply":"2024-12-24T09:37:04.980754Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e25e583fb3894d45a3232581ab745036"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0304610ee3ef4172bda1f723db31dc21"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"759f3d0e4c07475cb8601475a097ffd8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11e26c6d6e0542338683f191b1cc9257"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f37e37c202a484e8efdec62bcbc3736"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"10d7b048a43f49068690a842c14006fc"}},"metadata":{}},{"name":"stdout","text":"Query relevance Score: 99.67774748802185\nContext Fidelity Score: 63.34573030471802\nError Percentage: 4.05%\n","output_type":"stream"}],"execution_count":109},{"cell_type":"code","source":"qr,cf,gram = evaluation_metricss(query,context,answer)\nprint(f\"Query relevance Score: {qr}\\n\"\n     f\"Context Fidelity Score: {cf}\\n\"\n     f\"Error Percentage: {gram:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T08:28:20.279621Z","iopub.execute_input":"2024-12-24T08:28:20.279969Z","iopub.status.idle":"2024-12-24T08:28:40.035689Z","shell.execute_reply.started":"2024-12-24T08:28:20.279939Z","shell.execute_reply":"2024-12-24T08:28:40.034715Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"730e4e04c1f949339e910c6d0e7ac742"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"143fe9d502304beabd59b931bcaac26a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c58fed109db4f8a907d63befe6a6583"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d73a4a5796c42a68cbd187d80f1e86b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"54816bd3c01d406093c717526de1e335"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f06ca58223ad48918d01a9b9559c127c"}},"metadata":{}},{"name":"stdout","text":"Query relevance Score: 67.99759268760681\nContext Fidelity Score: 72.56436944007874\nError Percentage: 29.30%\n","output_type":"stream"}],"execution_count":35},{"cell_type":"markdown","source":"Overall grade - 7.6/10","metadata":{}},{"cell_type":"markdown","source":"# Q3","metadata":{}},{"cell_type":"code","source":"query = \"What is a system call?\"\nresults = query_faiss_index(query, top_k = 3)\npara = \"\"\nfor result in results:\n    para = para + result\n#context = extract_relevant_sentences(query, para, similarity_threshold=0.4)\ncontext = para\ncontext = clean_context(context)\ninsight,answer= generate_insight_simple(query, context)\n\nprint(\"Generated Insight:\")\nprint(insight)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T09:39:25.455690Z","iopub.execute_input":"2024-12-24T09:39:25.456061Z","iopub.status.idle":"2024-12-24T09:40:33.833390Z","shell.execute_reply.started":"2024-12-24T09:39:25.456030Z","shell.execute_reply":"2024-12-24T09:40:33.832031Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"56d4e0a923584bf095ffbbc426128fec"}},"metadata":{}},{"name":"stderr","text":"This is a friendly reminder - the current text generation call will exceed the model's predefined maximum length (2048). Depending on the model, you may observe exceptions, performance degradation, or nothing at all.\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","Cell \u001b[0;32mIn[110], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m context \u001b[38;5;241m=\u001b[39m para\n\u001b[1;32m      8\u001b[0m context \u001b[38;5;241m=\u001b[39m clean_context(context)\n\u001b[0;32m----> 9\u001b[0m insight,answer\u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_insight_simple\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerated Insight:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(insight)\n","Cell \u001b[0;32mIn[16], line 32\u001b[0m, in \u001b[0;36mgenerate_insight_simple\u001b[0;34m(query, context)\u001b[0m\n\u001b[1;32m     29\u001b[0m attention_mask \u001b[38;5;241m=\u001b[39m inputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Generate the output using the model\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mllm_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_return_sequences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mno_repeat_ngram_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Decode the generated text\u001b[39;00m\n\u001b[1;32m     46\u001b[0m generated_text \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(outputs[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:2024\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2016\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2017\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2018\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   2019\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2020\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2021\u001b[0m     )\n\u001b[1;32m   2023\u001b[0m     \u001b[38;5;66;03m# 13. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 2024\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2025\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2026\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2027\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_warper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_warper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2028\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2029\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2030\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2031\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2032\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2033\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2035\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   2036\u001b[0m     \u001b[38;5;66;03m# 11. prepare logits warper\u001b[39;00m\n\u001b[1;32m   2037\u001b[0m     prepared_logits_warper \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2038\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_logits_warper(generation_config, device\u001b[38;5;241m=\u001b[39minput_ids\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   2039\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m generation_config\u001b[38;5;241m.\u001b[39mdo_sample\n\u001b[1;32m   2040\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2041\u001b[0m     )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:2982\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, logits_warper, **model_kwargs)\u001b[0m\n\u001b[1;32m   2979\u001b[0m model_inputs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_hidden_states\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_hidden_states} \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[1;32m   2981\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2982\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   2984\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2985\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/hooks.py:169\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:1189\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1186\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1189\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1190\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1194\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1200\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1202\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpretraining_tp \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:1001\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    989\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    990\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    991\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    998\u001b[0m         position_embeddings,\n\u001b[1;32m    999\u001b[0m     )\n\u001b[1;32m   1000\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1001\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1002\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1003\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1004\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1005\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1006\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1007\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1008\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1009\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1010\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1012\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/hooks.py:169\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:734\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    731\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm(hidden_states)\n\u001b[1;32m    733\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[0;32m--> 734\u001b[0m hidden_states, self_attn_weights, present_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    735\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    739\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    740\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    742\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    743\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    745\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    747\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/hooks.py:169\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:640\u001b[0m, in \u001b[0;36mLlamaSdpaAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    638\u001b[0m     \u001b[38;5;66;03m# sin and cos are specific to RoPE models; cache_position needed for the static cache\u001b[39;00m\n\u001b[1;32m    639\u001b[0m     cache_kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msin\u001b[39m\u001b[38;5;124m\"\u001b[39m: sin, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcos\u001b[39m\u001b[38;5;124m\"\u001b[39m: cos, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcache_position\u001b[39m\u001b[38;5;124m\"\u001b[39m: cache_position}\n\u001b[0;32m--> 640\u001b[0m     key_states, value_states \u001b[38;5;241m=\u001b[39m \u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    642\u001b[0m key_states \u001b[38;5;241m=\u001b[39m repeat_kv(key_states, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_key_value_groups)\n\u001b[1;32m    643\u001b[0m value_states \u001b[38;5;241m=\u001b[39m repeat_kv(value_states, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_key_value_groups)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/cache_utils.py:383\u001b[0m, in \u001b[0;36mDynamicCache.update\u001b[0;34m(self, key_states, value_states, layer_idx, cache_kwargs)\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue_cache\u001b[38;5;241m.\u001b[39mappend(value_states)\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 383\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey_cache[layer_idx] \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlayer_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey_states\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue_cache[layer_idx] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue_cache[layer_idx], value_states], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey_cache[layer_idx], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue_cache[layer_idx]\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 38.00 MiB. GPU 1 has a total capacity of 14.74 GiB of which 12.12 MiB is free. Process 3105 has 14.73 GiB memory in use. Of the allocated memory 13.98 GiB is allocated by PyTorch, and 638.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"],"ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 38.00 MiB. GPU 1 has a total capacity of 14.74 GiB of which 12.12 MiB is free. Process 3105 has 14.73 GiB memory in use. Of the allocated memory 13.98 GiB is allocated by PyTorch, and 638.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)","output_type":"error"}],"execution_count":110},{"cell_type":"markdown","source":"# Cache","metadata":{}},{"cell_type":"code","source":"import torch\nimport gc\nprint(torch.cuda.device_count())\n\n# Loop through all GPUs and clear their memory\nfor i in range(torch.cuda.device_count()):\n    torch.cuda.set_device(i)\n    torch.cuda.empty_cache()\n\n# Optionally, collect garbage\ngc.collect()\n\nprint(\"CUDA memory cache cleared for all GPUs.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T19:51:50.614621Z","iopub.execute_input":"2024-12-24T19:51:50.614949Z","iopub.status.idle":"2024-12-24T19:51:50.977702Z","shell.execute_reply.started":"2024-12-24T19:51:50.614922Z","shell.execute_reply":"2024-12-24T19:51:50.976736Z"}},"outputs":[{"name":"stdout","text":"2\nCUDA memory cache cleared for all GPUs.\n","output_type":"stream"}],"execution_count":38},{"cell_type":"markdown","source":"Grading for the answer (out of 10): 9.03/10","metadata":{}},{"cell_type":"code","source":"import torch\n#torch.cuda.set_device(0)\ntorch.cuda.empty_cache()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T19:51:47.138442Z","iopub.execute_input":"2024-12-24T19:51:47.138756Z","iopub.status.idle":"2024-12-24T19:51:47.142880Z","shell.execute_reply.started":"2024-12-24T19:51:47.138730Z","shell.execute_reply":"2024-12-24T19:51:47.141969Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"qr,cf,gram = evaluation_metrics(query,context,answer)\nprint(f\"Query relevance Score: {qr}\\n\"\n     f\"Context Fidelity Score: {cf}\\n\"\n     f\"Error Percentage: {gram:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T08:34:58.100928Z","iopub.execute_input":"2024-12-24T08:34:58.101759Z","iopub.status.idle":"2024-12-24T08:35:19.439114Z","shell.execute_reply.started":"2024-12-24T08:34:58.101723Z","shell.execute_reply":"2024-12-24T08:35:19.438204Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3c83512cef834d2c9cc6c56e52c57de2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"80244d921c6f4307a16accd5e2ee90fa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c40a319414774514adfdb0fd2d14a6c3"}},"metadata":{}},{"name":"stdout","text":"Query relevance Score: 88.19022178649902\nContext Fidelity Score: 78.09152603149414\nError Percentage: 5.26%\n","output_type":"stream"}],"execution_count":42},{"cell_type":"markdown","source":"# Q4","metadata":{}},{"cell_type":"code","source":"query = \"Describe the structure and purpose of a file system.\"\nresults = query_faiss_index(query, top_k = 3)\npara = \"\"\nfor result in results:\n    para = para + result\n#context = extract_relevant_sentences(query, para, similarity_threshold=0.4)\ncontext = para\ncontext = clean_context(context)\ninsight,answer= generate_insight_simple(query, context)\n\nprint(\"Generated Insight:\")\nprint(insight)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T09:41:32.248492Z","iopub.execute_input":"2024-12-24T09:41:32.249112Z","iopub.status.idle":"2024-12-24T09:42:03.420471Z","shell.execute_reply.started":"2024-12-24T09:41:32.249077Z","shell.execute_reply":"2024-12-24T09:42:03.419586Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f4a2feff42644e6abd5a01209ab5d11"}},"metadata":{}},{"name":"stdout","text":"Generated Insight:\n\nINSTRUCTIONS:\nAnswer the users QUESTION concisely using the DOCUMENT text above.\nIf the DOCUMENT doesn’t contain the facts to answer the QUESTION return NONE\nUse simple terms so that the user can understand\nDOCUMENT:\nPart Four Storage Management Since main memory is usually too small to accommodate all the data and programs permanently, the computer system must provide secondary storage to back up main memory. Modern computer systems use disksas the primary on-line storage me dium for information (both programs and data). The ﬁle system provides the mechanism for on-line storage of and access to both data and programs residing on the disks. A ﬁle is a collection of related information deﬁned by its creator. The ﬁles aremapped by the operating system onto physical devices. Files are normally organized into directories for ease of use. The devices that attach to a computer vary in many aspects. Some devices transfer a character or a bl ock of characters at a time. Some can be accessed only sequentially, others randomly. Some transfer data synchronously, others asynch ronously. Some are dedicated, some shared. They can be read-only or read–write. They vary greatly in speed. In many ways, they are also the slowest major component of the computer. Because of all this device variation, the operating system needs to provide a wide range of functionality to applications, to allow them to control all aspects of the devices. One key goal of an operating system’s I/Osubsystem is to provide the simplest interface possible to the rest of the system. Because devices are a performance bottleneck, another key is to optimize I/Ofor maximum concurrency.544 Chapter 12 File-System Implementation on the disk drive, sector size varies from 32 bytes to 4,096 bytes; the usual size is 512 bytes. File systems provide efﬁcient and convenient access to the disk by allowing data to be stored, located, and retrieved easily. A ﬁle system poses two quitedifferent design problems. The ﬁrst problem is deﬁning how the ﬁle systemshould look to the user. This task involves deﬁning a ﬁle and its attributes, the operations allowed on a ﬁle, and the directory structure for organizing ﬁles. The second problem is creating algorithms and data structures to map thelogical ﬁle system onto the physical secondary-storage devices. The ﬁle system itself is generally composed of many different levels. The structure shown in Figure 12.1 is an example of a layered design. Each level in the design uses the features of lower levels to create new features for use byhigher levels. The I/Ocontrol level consists of device drivers and interrupt handlers to transfer information between the main memory and the disk system. A device driver can be thought of as a translator. Its input consists of high- level commands such as “retrieve block 123. ”Its output consists of low-level, hardware-speciﬁc instructions that are use d by the hardware controller, which interfaces the I/Odevice to the rest of the system. The device driver usually writes speciﬁc bit patterns to special locations in the I/Ocontroller’s memory to tell the controller which device location to act on and what actions to take.The details of device drivers and the I/Oinfrastructure are covered in Chapter 13. The basic ﬁle system needs only to issue generic commands to the appropriate device driver to read and write physical blocks on the disk. Eachphysical block is identiﬁed by its numeric disk address (for example, drive 1, cylinder 73, track 2, sector 10). This layer also manages the memory buffers and caches that hold various ﬁle-system, directory, and data blocks. A blockin the buffer is allocated before the transfer of a disk block can occur. Whenthe buffer is full, the buffer manager must ﬁnd more buffer memory or free application programs file-organization module basic file system I/O control deviceslogical file system Figure 12.1 Layered ﬁle system.546 Chapter 12 File-System Implementation 12.2 File-System Implementation As was described in Section 11.1.2, operating systems implement open() and close() systems calls for processes to request access to ﬁle contents. In this section, we delve into the structures and operations used to implementﬁle-system operations. 12.2.1 Overview Several on-disk and in-memory structures are used to implement a ﬁle system.These structures vary depending on the operating system and the ﬁle system,but some general principles apply. On disk, the ﬁle system may contain information about how to boot an operating system stored there, the total number of blocks, the number and location of free blocks, the directory structure, and individual ﬁles. Many ofthese structures are detailed throughout the remainder of this chapter. Here,we describe them brieﬂy: •Aboot control block (per volume) can contain information needed by the system to boot an operating system from that volume. If the disk does notcontain an operating system, this block can be empty. It is typically the ﬁrst block of a volume. In UFS, it is called the boot block .I n NTFS ,i ti st h e partition boot sector . •Avolume control block (per volume) contains volume (or partition) details, such as the number of blocks in the partition, the size of the blocks,a free-block count and free-block pointers, and a free- FCB count and FCB pointers. In UFS, this is called a superblock .I n NTFS ,i ti ss t o r e di nt h e master ﬁle table . •A directory structure (per ﬁle system) is used to organize the ﬁles. In UFS, this includes ﬁle names and associated inode numbers. In NTFS ,i ti ss t o r e d in the master ﬁle table. •Ap e r - ﬁ l e FCB contains many details about the ﬁle. It has a unique identiﬁer number to allow association with a directory entry. In NTFS , this information is actually stored within the master ﬁle table, which uses a relational database structure, with a row per ﬁle. The in-memory information is used for both ﬁle-system management and performance improvement via cachin g. The data are loaded at mount time, updated during ﬁle-system operations, and discarded at dismount. Severaltypes of structures may be included. •An in-memory mount table contains information about each mounted volume. •An in-memory directory-structure cache holds the directory informationof recently accessed directories. (For directories at which volumes aremounted, it can contain a pointer to the volume table.) •The system-wide open-ﬁle table contains a copy of the FCB of each open ﬁle, as well as other information.\nQUESTION:\nDescribe the structure and purpose of a file system.\nANSWER:\nA file system is a critical component of a computer system that provides a mechanism for organising and managing files on a storage device such as a hard drive. The file system structure consists of several layers, including the logical file system, the I /O control level, the device drivers, and hardware controllers. The logical file structure is responsible for defining how the file system appears to the users, while the I O control level manages communication between the memory and disk system, including device drivers that translate high-level commands into low- level hardware instructions. The purpose of the file is to make it easier for users to access and manage their files by providing a hierarchical directory structure and allowing users to create, delete, and modify files. Additionally, the file provides a way to organise data on a disk into logical groups, making it easier to manage and locate files.\n","output_type":"stream"}],"execution_count":114},{"cell_type":"markdown","source":"","metadata":{"execution":{"iopub.status.busy":"2024-12-07T09:40:00.947409Z","iopub.execute_input":"2024-12-07T09:40:00.948280Z","iopub.status.idle":"2024-12-07T09:41:11.736835Z","shell.execute_reply.started":"2024-12-07T09:40:00.948247Z","shell.execute_reply":"2024-12-07T09:41:11.735979Z"}}},{"cell_type":"code","source":"qr,cf,gram = evaluation_metrics(query,context,answer)\nprint(f\"Query relevance Score: {qr}\\n\"\n     f\"Context Fidelity Score: {cf}\\n\"\n     f\"Error Percentage: {gram:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T09:45:12.516447Z","iopub.execute_input":"2024-12-24T09:45:12.517176Z","iopub.status.idle":"2024-12-24T09:45:58.579173Z","shell.execute_reply.started":"2024-12-24T09:45:12.517140Z","shell.execute_reply":"2024-12-24T09:45:58.578262Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"87a50edce8a445eba79e6376bd016fe3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"448f512623644a6b9249f1275733ea71"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e40c8d4c9f4c4089be3f8d586bc29257"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"81712c73a49a4454896a02a1c44ff7ca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec7b2f66232f44638f19e6214c8ef9d8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a47c6712e968446b9aa4f066ecd27f0b"}},"metadata":{}},{"name":"stdout","text":"Query relevance Score: 99.98220801353455\nContext Fidelity Score: 77.71925926208496\nError Percentage: 1.99%\n","output_type":"stream"}],"execution_count":116},{"cell_type":"markdown","source":"Overall grade - 8.3/10","metadata":{}},{"cell_type":"markdown","source":"# Q5","metadata":{}},{"cell_type":"code","source":"query = \"Discuss the key differences between batch systems, time-sharing systems, and real-time systems.\"\nresults = query_faiss_index(query, top_k = 2)\npara = \"\"\nfor result in results:\n    para = para + result\n#context = extract_relevant_sentences(query, para, similarity_threshold=0.4)\ncontext = para\ncontext = clean_context(context)\ninsight,answer= generate_insight_simple(query, context)\n\nprint(\"Generated Insight:\")\nprint(insight)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T09:47:48.288460Z","iopub.execute_input":"2024-12-24T09:47:48.288844Z","iopub.status.idle":"2024-12-24T09:48:48.294636Z","shell.execute_reply.started":"2024-12-24T09:47:48.288813Z","shell.execute_reply":"2024-12-24T09:48:48.293728Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f898cab9c60f4b6692495ec941367fce"}},"metadata":{}},{"name":"stdout","text":"Generated Insight:\n\nINSTRUCTIONS:\nAnswer the users QUESTION concisely using the DOCUMENT text above.\nIf the DOCUMENT doesn’t contain the facts to answer the QUESTION return NONE\nUse simple terms so that the user can understand\nDOCUMENT:\n798 Chapter 18 The Linux System difference between FCFS and round-robin scheduling is that FCFS processes continue to run until they either exit or b lock, whereas a round-robin process will be preempted after a while and will be moved to the end of the scheduling queue, so round-robin processes of equal priority will automatically time-shareamong themselves. Linux’s real-time scheduling is soft—rather than hard—real time. The scheduler offers strict guarantees about the relative priorities of real-time processes, but the kernel does not offer any guarantees about how quicklya real-time process will be scheduled once that process becomes runnable. Incontrast, a hard real-time system can guarantee a minimum latency between when a process becomes runnable and when it actually runs. 18.5.3 Kernel Synchronization The way the kernel schedules its ow n operations is fundamentally different from the way it schedules processes. A request for kernel-mode executioncan occur in two ways. A running program may request an operating-systemservice, either explicitly via a system call or implicitly—for example, when a page fault occurs. Alternatively, a device controller may deliver a hardware interrupt that causes the CPU to start executing a kernel-deﬁned handler for that interrupt. The problem for the kernel is that all these tasks may try to access the same internal data structures. If one kernel task is in the middle of accessing some data structure when an interrupt servic e routine executes, then that service routine cannot access or modify the same data without risking data corruption.This fact relates to the idea of critical sections—portions of code that access shared data and thus must not be allowed to execute concurrently. As a result, kernel synchronization involves much more than just process scheduling. Aframework is required that allows kernel tasks to run without violating theintegrity of shared data. Prior to version 2.6, Linux was a nonpreemptive kernel, meaning that a process running in kernel mode could not be preempted—even if a higher-priority process became available to run. With version 2.6, the Linux kernelbecame fully preemptive. Now, a task can be preempted when it is running in the kernel. The Linux kernel provides spinlocks an d semaphores (as well as reader– writer versions of these two locks) for locking in the kernel. On SMP machines, the fundamental locking mechanism is a spinlock, and the kernel is designed so that spinlocks are held for only short durations. On single-processor machines, spinlocks are not appropriate for use and are replaced by enablingand disabling kernel preemption. That is, rather than holding a spinlock, thetask disables kernel preemption. When the task would otherwise release the spinlock, it enables kernel preemption. This pattern is summarized below: single processor multiple processors Acquire spin lock. Release spin lock.Disable kernel preemption. Enable kernel preemption.20 Chapter 1 Introduction Multiprogrammed systems provide an environment in which the various system resources (for example, CPU, memory, and peripheral devices) are utilized effectively, but they do not provide for user interaction with the computer system. Time sharing (ormultitasking ) is a logical extension of multiprogramming. In time-sharing systems, the CPU executes multiple jobs by switching among them, but the switches occur so frequently that the users can interact with each program while it is running. Time sharing requires an interactive computer system, which provides direct communication between the user and the system. The user givesinstructions to the operating system or to a program directly, using a input device such as a keyboard, mouse, touch pad, or touch screen, and waits for immediate results on an output device. Accordingly, the response time should be short—typically less than one second. A time-shared operating system allows many users to share the computer simultaneously. Since each action or command in a time-shared system tends to be short, only a little CPU time is needed for each user. As the system switches rapidly from one user to the next, each user is given the impression that the entire computer system is dedicated to his use, even though it is being shared among many users. A time-shared operating system uses CPU scheduling and multiprogram- ming to provide each user with a small portion of a time-shared computer.Each user has at least one separate program in memory. A program loaded into memory and executing is called a process . When a process executes, it typically executes for only a short time before i t either ﬁnishes or needs to perform I/O. I/Omay be interactive; that is, output goes to a display for the user, and input comes from a user keyboard, mouse, or other device. Since interactive I/O typically runs at “people speeds, ”it may take a long time to complete. Input, for example, may be bounded by the user’s typing speed; seven characters persecond is fast for people but incredibly slow for computers. Rather than letthe CPU sit idle as this interactive input takes place, the operating system will rapidly switch the CPU to the program of some other user. Time sharing and multiprogramming require that several jobs be kept simultaneously in memory. If several jobs are ready to be brought into memory,and if there is not enough room for all of them, then the system must choose among them. Making this decision involves job scheduling , which we discuss in Chapter 6. When the operating system selects a job from the job pool, it loadsthat job into memory for execution. Having several programs in memory atthe same time requires some form of memory management, which we cover in Chapters 8 and 9. In addition, if several jobs are ready to run at the same time, the system must choose which job will run ﬁrst. Making this decision is CPU scheduling , which is also discussed in Chapter 6. Finally, running multiple jobs concurrently requires that their ability to affect one another be limited in all phases of the operating system, including process scheduling, disk storage, and memory management. We discuss these considerations throughout thetext. In a time-sharing system, the operating system must ensure reasonable response time. This goal is sometimes accomplished through swapping , whereby processes are swapped in and out of main memory to the disk. A morecommon method for ensuring reasonable response time is virtual memory ,a technique that allows the execution of a process that is not completely in\nQUESTION:\nDiscuss the key differences between batch systems, time-sharing systems, and real-time systems.\nANSWER:\nBatch systems, Time-sharring systems,and real-tims are three types of operating systems that differ in their design and functionality.\n\nBatch Systems:\n\n* Batch systems are non-interactive operating systems where users submit jobs to be executed in a queue.\n* The operating system schedules the jobs and executes them in a batch manner, meaning all jobs are executed in sequence.\n * Batch system are designed for tasks that require a long execution time, such as compilations, scientific simulations, or data processing.\n \nTime-Sharing Systems: \n\n * Time-Sharring systems are interactive operating systems, where multiple users can access the system simultaneously.\n\t* The Operating system switch between users quickly, allowing each user to interact with the system in real- time.\n Time- sharing systems are designed to provide fast response times, typically less than 1 second, and are used in applications such as online banking, email, and gaming.\nReal-Time Systems: * Real-time Systems are designed  for applications that require strict timing guarantees, such  as embedded systems, industrial control systems, or medical devices.\n Real-Time systems prioritize tasks based on their priority and schedule them accordingly, ensuring that critical tasks are executed on time. \n * Real -time systems use specialized scheduling algorithms, such a s Rate Monotonic Scheduling (RMS) or Deadline Monotomic Schedulin (DMS), to ensure predictable and deterministic behavior.\nIn summary, batch systems are for long-running tasks, time -sharing  systems are  for interactive applications with fast response time, and Real- Time systems are design for applications with strict timing requirements. Each type of operating system has its own design and functionalities, and they differ in the way they manage resources, schedule tasks, and provide services to users.\n","output_type":"stream"}],"execution_count":117},{"cell_type":"markdown","source":"Overall grade - 9.3/10","metadata":{}},{"cell_type":"code","source":"qr,cf,gram = evaluation_metrics(query,context,answer)\nprint(f\"Query relevance Score: {qr}\\n\"\n     f\"Context Fidelity Score: {cf}\\n\"\n     f\"Error Percentage: {gram:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T09:49:30.440646Z","iopub.execute_input":"2024-12-24T09:49:30.441558Z","iopub.status.idle":"2024-12-24T09:50:21.017673Z","shell.execute_reply.started":"2024-12-24T09:49:30.441521Z","shell.execute_reply":"2024-12-24T09:50:21.016470Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d2b2956098214d3b966e913428ba6485"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c96ed8749394fd8ab1c6acb223e63e9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bee820939e304823a290ad895dba9345"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bcc8dc2ca7834ef6801e2c145f13cce1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f52128127577479eb3fc28cae537de0a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c99255ac34644bd9a5a5c5745d25ff5"}},"metadata":{}},{"name":"stdout","text":"Query relevance Score: 99.95736479759216\nContext Fidelity Score: 78.96842956542969\nError Percentage: 5.56%\n","output_type":"stream"}],"execution_count":118},{"cell_type":"markdown","source":"# Q6","metadata":{}},{"cell_type":"code","source":"query = \"How does an operating system ensure memory protection and prevent a process from accessing another process’s memory?\"\nresults = query_faiss_index(query, top_k = 3)\npara = \"\"\nfor result in results:\n    para = para + result\n#context = extract_relevant_sentences(query, para, similarity_threshold=0.4)\ncontext = para\ncontext = clean_context(context)\ninsight,answer= generate_insight_simple(query, context)\n\nprint(\"Generated Insight:\")\nprint(insight)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T09:51:05.292018Z","iopub.execute_input":"2024-12-24T09:51:05.292965Z","iopub.status.idle":"2024-12-24T09:51:46.326994Z","shell.execute_reply.started":"2024-12-24T09:51:05.292928Z","shell.execute_reply":"2024-12-24T09:51:46.326138Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ccc1c9ae4db844cfaaaa0755c43a202a"}},"metadata":{}},{"name":"stdout","text":"Generated Insight:\n\nINSTRUCTIONS:\nAnswer the users QUESTION concisely using the DOCUMENT text above.\nIf the DOCUMENT doesn’t contain the facts to answer the QUESTION return NONE\nUse simple terms so that the user can understand\nDOCUMENT:\n14CHAPTER Protection The processes in an operating system must be protected from one another’s activities. To provide such protection, we can use various mechanisms to ensure that only processes that have gained proper authorization from the operating system can operate on the ﬁles, memory segments, CPU, and other resources of a system. Protection refers to a mechanism for controlling the access of programs, processes, or users to the resources deﬁned by a computer system. This mechanism must provide a means for specifying the controls to be imposed, together with a means of enforcemen t. We distinguish between protection and security, which is a measure of conﬁdence that the integrity of a system and its data will be preserved. In this cha pter, we focus on protection. Security assurance is a much broader topic, and we address it in Chapter 15. CHAPTER OBJECTIVES •To discuss the goals and principles of protection in a modern computer system. •To explain how protection domains, combined with an access matrix, are used to specify the resources a process may access. •To examine capability- and language-based protection systems. 14.1 Goals of Protection As computer systems have become more sophisticated and pervasive in their applications, the need to protect their integrity has also grown. Protection was originally conceived as an adjunct to multiprogramming operating systems, so that untrustworthy users might safely share a common logical name space, such as a directory of ﬁles, or share a common physical name space, such as memory. Modern protection concepts have evolved to increase the reliability of any complex system that makes use of shared resources. We need to provide protection for several reasons. The most obvious is the need to prevent the mischievous, inten tional violation of an access restriction 6258.1 Background 353 operating system0 256000 300040300040 base 120900 limit420940 880000 1024000process process process Figure 8.1 A base and a limit register deﬁne a logical address space. 300040 and the limit register is 120900, then the program can legally access all addresses from 300040 through 420939 (inclusive). Protection of memory space is accomplished by having the CPU hardware compare every address generated in user mode with the registers. Any attemptby a program executing in user mode to access operating-system memory or other users’ memory results in a trap to the operating system, which treats the attempt as a fatal error (Figure 8.2). This scheme prevents a user program from(accidentally or deliberately) modifying the code or data structures of eitherthe operating system or other users. The base and limit registers can be loaded only by the operating system, which uses a special privileged instruction. Since privileged instructions canbe executed only in kernel mode, and since only the operating system executesin kernel mode, only the operating system can load the base and limit registers. base memorytrap to operating system monitor—addressing erroraddress yes yes no noCPUbase /H11001 limit ≥ < Figure 8.2 Hardware address protection with base and limit registers.Part Five Protection and Security Protection mechanisms control access to a system by limiting the types of ﬁle access permitted to users. In addition, protection must ensure that only processes that have ga ined proper authorization from the operating system can operate on memory segments, the CPU , and other resources. Protection is provided by a mechanis m that controls the access of programs, processes, or users to the resources deﬁned by a computersystem. This mechanism must provide a means for specifying the controls to be imposed, together with a means of enforcing them. Security ensures the authentication of system users to protect the integrity of the information stored in the system (both data and code),as well as the physical resources of the computer system. The securitysystem prevents unauthorized access, malicious destruction or alteration of data, and accidental introdu ction of inconsistency.\nQUESTION:\nHow does an operating system ensure memory protection and prevent a process from accessing another process’s memory?\nANSWER:\nAn operating system ensures memory protection by using a combination of hardware and software mechanisms. The hardware mechanism is the Memory Management Unit (MMU), which maps the virtual memory addresses used by a process to the physical memory addresses in the computer's memory. The MMU checks every memory access request from a process against the protection rules set by the operator ing system, and if the request is not allowed, it raises a page fault exception that is handled by the kernel.\nThe software mechanism used by the OS is the protection domain, which defines the set of processes that can access a particular resource, such a  file or a network connection. The kernel enforces the protection domains by checking the access control list (ACL) associated with each resource before allowing a process access to it.\nAdditionally, the OS can use capability based protection, where each process is assigned a set of capabilities that define what it can do, suchas read, write, or execute a file. The capabilities are checked by the MMU when a process makes a memory accessrequest, and the request will be allowed only if the capability is present in the process's capability set.\nIn summary, the operating systems ensures mem ory protection by combining hardware and softw are protection mechanisms, such s MMU, protection domains and capability -based protection, to prevent a proces s from accessing anothe r process' s memory.\n","output_type":"stream"}],"execution_count":119},{"cell_type":"markdown","source":"Overall grade - 8.12/10","metadata":{}},{"cell_type":"code","source":"qr,cf,gram = evaluation_metrics(query,context,answer)\nprint(f\"Query relevance Score: {qr}\\n\"\n     f\"Context Fidelity Score: {cf}\\n\"\n     f\"Error Percentage: {gram:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T09:51:51.825661Z","iopub.execute_input":"2024-12-24T09:51:51.826428Z","iopub.status.idle":"2024-12-24T09:52:44.121176Z","shell.execute_reply.started":"2024-12-24T09:51:51.826393Z","shell.execute_reply":"2024-12-24T09:52:44.120014Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12b1aea9482141ae90a400ec65c46d2e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5df6b566aa8a4144bd9966b3371451c4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5bf41dfa25504fdbbc022517e1d0c39a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b43d4a7c2d743249325eecd94752d29"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c29f53ea9d4432fb61e0c974ecd1078"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"41aee0eb36954e41b67a9221bc52b49b"}},"metadata":{}},{"name":"stdout","text":"Query relevance Score: 99.98562335968018\nContext Fidelity Score: 79.14291620254517\nError Percentage: 4.26%\n","output_type":"stream"}],"execution_count":120},{"cell_type":"markdown","source":"# Q7","metadata":{}},{"cell_type":"code","source":"query = \"Explain the role of interrupts in modern operating systems.\"\nresults = query_faiss_index(query, top_k = 3)\npara = \"\"\nfor result in results:\n    para = para + result\n#context = extract_relevant_sentences(query, para, similarity_threshold=0.4)\ncontext = para\ncontext = clean_context(context)\ninsight,answer= generate_insight_simple(query, context)\n\nprint(\"Generated Insight:\")\nprint(insight)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T09:53:57.808690Z","iopub.execute_input":"2024-12-24T09:53:57.809058Z","iopub.status.idle":"2024-12-24T09:55:13.906908Z","shell.execute_reply.started":"2024-12-24T09:53:57.809027Z","shell.execute_reply":"2024-12-24T09:55:13.905958Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"781ea92db5b143a9b476c44b56df2a38"}},"metadata":{}},{"name":"stdout","text":"Generated Insight:\n\nINSTRUCTIONS:\nAnswer the users QUESTION concisely using the DOCUMENT text above.\nIf the DOCUMENT doesn’t contain the facts to answer the QUESTION return NONE\nUse simple terms so that the user can understand\nDOCUMENT:\n592 Chapter 13 I/O Systems device driver initiates I/O CPU receiving interrupt, transfers control to interrupt handler CPU resumes processing of interrupted taskCPU 1I/O controller CPU executing checks for interrupts between instructions 5 interrupt handler processes data, returns from interruptinitiates I/O 32 4 7input ready, output complete, or error generates interrupt signal 6 Figure 13.3 Interrupt-driven I/O cycle. 13.2.2 Interrupts The basic interrupt mechanism works as follows. The CPU hardware has a wire called the interrupt-request line that the CPU senses after executing every instruction. When the CPU detects that a controller has asserted a signal on the interrupt-request line, the CPU performs a state save and jumps to the interrupt-handler routine at a ﬁxed address in memory. The interrupt handler determines the cause of the interrupt, performs the necessary processing, performs a state restore, and executes a return from interrupt instruction to return the CPU to the execution state prior to the interrupt. We say that the device controller raises an interrupt by asserting a signal on the interrupt request line, the CPU catches the interrupt and dispatches it to the interrupt handler, and the handler clears the interrupt by servicing the device. Figure 13.3 summarizes the interrupt-driven I/Ocycle. We stress interrupt management in this chapter because even single-user modern systems manage hundreds ofinterrupts per second and servers hundreds of thousands per second. The basic interrupt mechanism just described enables the CPU to respond to an asynchronous event, as when a d evice controller becomes ready for service. In a modern operating system, however, we need more sophisticatedinterrupt-handling features.30 Chapter 1 Introduction devices are hidden from the bulk of the operating system itself by the I/O subsystem .T h e I/Osubsystem consists of several components: •A memory-management component that includes buffering, caching, and spooling •A general device-driver interface •Drivers for speciﬁc hardware devices Only the device driver knows the pecu liarities of the speciﬁc device to which it is assigned. We discussed in Section 1.2.3 how interrupt handlers and device drivers are used in the construction of efﬁcient I/Osubsystems. In Chapter 13, we discuss how the I/Osubsystem interfaces to the other system components, manages devices, transfers data, and detects I/Ocompletion. 1.9 Protection and Security If a computer system has multiple users and allows the concurrent execution of multiple processes, then access to data must be regulated. For that purpose, mechanisms ensure that ﬁles, memory segments, CPU, and other resources can be operated on by only those processes that have gained proper authoriza-tion from the operating system. For example, memory-addressing hardwareensures that a process can execute on ly within its own address space. The timer ensures that no process can gain control of the CPU without eventually relinquishing control. Device-control registers are not accessible to users, sothe integrity of the various periph eral devices is protected. Protection , then, is any mechanism for controlling the access of processes or users to the resources deﬁned by a computer system. This mechanism must provide means to specify the controls to be imposed and to enforce the controls. Protection can improve reliability by detecting latent errors at the interfaces between component subsystems. Early detection of interface errors can often prevent contamination of a healthy subsystem by another subsystem that is malfunctioning. Furthermore, an unprotected resource cannot defend againstuse (or misuse) by an unauthorized or incompetent user. A protection-orientedsystem provides a means to distinguish between authorized and unauthorized usage, as we discuss in Chapter 14. A system can have adequate protection but still be prone to failure and allow inappropriate access. Consider a user whose authentication information(her means of identifying herself to the system) is stolen. Her data could be copied or deleted, even though ﬁle and memory protection are working. It is the job of security to defend a system from external and internal attacks. Such attacks spread across a huge range and include viruses and worms, denial-of-service attacks (which use all of a system’s resources and so keep legitimate users out of the system), identity theft, and theft of service (unauthorized use of a system). Prevention of some of these attacks is considered anoperating-system function on some systems, while other systems leave it topolicy or additional software. Due to the alarming rise in security incidents,8 Chapter 1 Introduction user processexecutingCPU I/O interrupt processing I/O requesttransfer doneI/O requesttransfer doneI/O deviceidle transferring Figure 1.3 Interrupt timeline for a single process doing output. this goal, the bootstrap program must locate the operating-system kernel and load it into memory. Once the kernel is loaded and executin g, it can start providing services to the system and its users. Some services are provided outside of the kernel, bysystem programs that are loaded into memory at boot time to become system processes ,o rsystem daemons that run the entire time the kernel is running. On UNIX , the ﬁrst system process is “init, ”and it starts many other daemons. Once this phase is complete, the system is fully booted, and the system waitsfor some event to occur. The occurrence of an event is usually signaled by an interrupt from either the hardware or the software. Hardware may trigger an interrupt at any timeby sending a signal to the CPU, usually by way of the system bus. Software may trigger an interrupt by executing a special operation called a system call (also called a monitor call ). When the CPU is interrupted, it stops what it is doing and immediately transfers execution to a ﬁxed location. The ﬁxed location usually containsthe starting address where the service routine for the interrupt is located. The interrupt service routine executes; on completion, the CPU resumes the interrupted computation. A timeline of this operation is shown in Figure 1.3. Interrupts are an important part of a computer architecture. Each computer design has its own interrupt mechanism, but several functions are common. The interrupt must transfer control to the appropriate interrupt service routine. The straightforward method for handling this transfer would be to invoke a generic routine to examine the interrupt information. The routine, in turn, would call the interrupt-speciﬁc handler. H owever, interrupts must be handled quickly. Since only a predeﬁned number of interrupts is possible, a table of pointers to interrupt routines can be used instead to provide the necessaryspeed. The interrupt routine is called indirectly through the table, with nointermediate routine needed. Generally, the table of pointers is stored in low memory (the ﬁrst hundred or so locations). These locations hold the addresses of the interrupt service routines for the various devices. This array, or interrupt vector , of addresses is then indexed by a u nique device number, given with the interrupt request, to provide the addr ess of the interrupt service routine for\nQUESTION:\nExplain the role of interrupts in modern operating systems.\nANSWER:\nInterrupts play a crucial role in modern operatingsystems, as they enable the CPUto respond to asynchronous events, such as device ready for servicing, without disrupting the current task. The following are the key roles of interruptsin modern operating syste ms:\n\n1. Interruption handling: Interrupt handlers are responsible for servic ing the device that has generated an interrupt. This includes reading data from or writing data to the device, as well as handling any errors that may have occurred during the I O operation.\n\n2. Prioritization: Interruptions can be prioritized based on their severity, with higher-priority interrupts being serviced before lower-priorit y ones. This helps to ensure that critical I/ O operations are completed promptly, while less important ones can be delayed.\n3. Resource allocation: Inter rupts can also be used to allocate resources, such a s memory or I/0 devices, when they are needed.\n4. Event handling:Interrupt s can be triggered by a variety of events, including timer expirations, network packets arrival, and hardware interrupts.\n5. System maintenance: Interr upts can beused to perform system maintenance tasks, such astask scheduling, memory management, and disk maintenance.\n6. Protect ion: Interupts can provide a mechanism for protecting system resources from unautho rized access or misuse.\n7. Performance optimization: Inter rupt-based scheduling can be u sed to optimize system performance by allowing the CPU t o switch between tasks more quickly and efficiently.\n8. Real-time operation: Interrup t s can enable a system to operate in real-time, by allowing it to respond quickly to external events and changes in the system environment.\n9. Multitasking: Interruption s can also enable a sy stem to support multitask ing, by allowin g it to switch between multiple tasks quickly and ef ficiently.\n10. Fault tolerance: Interrupted s can provide fault tolerance by allowing a system t o recover from errors or failures more quickly.\nIn summary, interrupt s play a critical role in enabling modern oper ating systems to manage the complex and dynamic nature of I/ 0 operations, while providing a foundation for other important system functions such as multitaki g, protection,\n","output_type":"stream"}],"execution_count":121},{"cell_type":"markdown","source":"Overall grade - 7.27/10","metadata":{}},{"cell_type":"code","source":"qr,cf,gram = evaluation_metrics(query,context,answer)\nprint(f\"Query relevance Score: {qr}\\n\"\n     f\"Context Fidelity Score: {cf}\\n\"\n     f\"Error Percentage: {gram:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T10:02:41.655986Z","iopub.execute_input":"2024-12-24T10:02:41.656706Z","iopub.status.idle":"2024-12-24T10:03:37.467590Z","shell.execute_reply.started":"2024-12-24T10:02:41.656670Z","shell.execute_reply":"2024-12-24T10:03:37.466566Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b7b685aea585441293ce64045e78f8ca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"221a7aeb76bd434280abf8730c2f9a98"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1baa2b3cbc634934980e051f255d202f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d5fa3c6adb744ea48ed7f158f860f773"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e2c959ef2e448ae851232c2efbf3b6a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a7cde03e9da3447193646c515676bc30"}},"metadata":{}},{"name":"stdout","text":"Query relevance Score: 99.99234676361084\nContext Fidelity Score: 77.30997800827026\nError Percentage: 6.92%\n","output_type":"stream"}],"execution_count":122},{"cell_type":"markdown","source":"# Q8","metadata":{}},{"cell_type":"code","source":"query = \"Analyze the storage hierarchy in operating systems\"\nresults = query_faiss_index(query, top_k = 3)\npara = \"\"\nfor result in results:\n    para = para + result\n#context = extract_relevant_sentences(query, para, similarity_threshold=0.4)\ncontext = para\ncontext = clean_context(context)\ninsight,answer= generate_insight_simple(query, context)\n\nprint(\"Generated Insight:\")\nprint(insight)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T10:03:48.866806Z","iopub.execute_input":"2024-12-24T10:03:48.867516Z","iopub.status.idle":"2024-12-24T10:04:56.106646Z","shell.execute_reply.started":"2024-12-24T10:03:48.867478Z","shell.execute_reply":"2024-12-24T10:04:56.105689Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c31085d9efd4902943ec9942a9e0a8b"}},"metadata":{}},{"name":"stdout","text":"Generated Insight:\n\nINSTRUCTIONS:\nAnswer the users QUESTION concisely using the DOCUMENT text above.\nIf the DOCUMENT doesn’t contain the facts to answer the QUESTION return NONE\nUse simple terms so that the user can understand\nDOCUMENT:\n502 Chapter 10 Mass-Storage Structure are opened for reading are read sequentially in their entirety, and most seeks are short. The concept of a storage hierarchy has been studied for more than forty years. For instance, a 1970 paper by [Mattson et al. (1970)] describes amathematical approach to predicting the performance of a storage hierarchy. Bibliography [Kim et al. (2009)] J. Kim, Y. Oh, E. Kim, J. C. D. Lee, and S. Noh, “Disk schedulers for solid state drivers ”(2009), pages 295–304. [Love (2010)] R. Love, Linux Kernel Development, Third Edition, Developer’s Library (2010). [Lumb et al. (2000)] C. Lumb, J. Schindler, G. R. Ganger, D. F. Nagle, and E. Riedel, “Towards Higher Disk Head Utilization: Extracting Free Bandwidth From Busy Disk Drives ”,Symposium on Operating Systems Design and Implemen- tation (2000). [Mattson et al. (1970)] R. L. Mattson, J. Gecsei, D. R. Slutz, and I. L. Traiger, “Evaluation Techniques for Storage Hierarchies ”,IBM Systems Journal ,V o l u m e 9, Number 2 (1970), pages 78–117. [McDougall and Mauro (2007)] R. McDougall and J. Mauro, Solaris Internals, Second Edition, Prentice Hall (2007). [Ousterhout et al. (1985)] J. K. Ousterhout, H. D. Costa, D. Harrison, J. A. Kunze, M. Kupfer, and J. G. Thompson, “A Trace-Driven Analysis of the UNIX 4.2 BSD File System ”,Proceedings of the ACM Symposium on Operating Systems Principles (1985), pages 15–24. [Patterson et al. (1988)] D. A. Patterson, G. Gibson, and R. H. Katz, “AC a s e for Redundant Arrays of Inexpensive Disks (RAID) ”,Proceedings of the ACM SIGMOD International Conference on the Management of Data (1988), pages 109– 116. [Ruemmler and Wilkes (1993)] C. Ruemmler and J. Wilkes, “Unix Disk Access Patterns ”,Proceedings of the Winter USENIX Conference (1993), pages 405–420. [Russinovich and Solomon (2009)] M. E. Russinovich and D. A. Solomon, Win- dows Internals: Including Windows Server 2008 and Windows Vista, Fifth Edition, Microsoft Press (2009). [Services (2012)] E. E. Services, Information Storage and Management: Storing, Managing, and Protecting Digital Information in Classic, Virtualized, and CloudEnvironments , Wiley (2012). [Teorey and Pinkerton (1972)] T. J. Teorey and T. B. Pinkerton, “A Comparative Analysis of Disk Scheduling Policies ”,Communications of the ACM , Volume 15, Number 3 (1972), pages 177–184.26 Chapter 1 Introduction management schemes are used. These schemes reﬂect various approaches, and the effectiveness of any given algorithm d epends on the situation. In selecting a memory-management scheme for a speciﬁc system, we must take into account many factors—especially the hardware design of the system. Each algorithm requires its own hardware support. The operating system is responsible for the following activities in connec- tion with memory management: •Keeping track of which parts of memory are currently being used and who is using them •Deciding which processes (or parts of processes) and data to move intoand out of memory •Allocating and deallocating memory space as needed Memory-management techniques are discussed in Chapters 8 and 9. 1.8 Storage Management To make the computer system convenient for users, the operating system provides a uniform, logical view of information storage. The operating system abstracts from the physical properties of its storage devices to deﬁne a logicalstorage unit, the ﬁle. The operating system maps ﬁles onto physical media and accesses these ﬁles via the storage devices. 1.8.1 File-System Management File management is one of the most visible components of an operating system. Computers can store information on several different types of physical media. Magnetic disk, optical disk, and magnetic tape are the most common. Eachof these media has its own characteristics and physical organization. Eachmedium is controlled by a device, such as a disk drive or tape drive, that also has its own unique characteristics. These properties include access speed, capacity, data-transfer rate, and access method (sequential or random). A ﬁle is a collection of related information deﬁned by its creator. Commonly, ﬁles represent programs (both source and object forms) and data. Data ﬁles may be numeric, alphabetic, alphanumeric, or binary. Files may be free-form (for example, text ﬁles), or they may be formatted rigidly (for example, ﬁxed ﬁelds).Clearly, the concept of a ﬁle is an extremely general one. The operating system implements the abstract concept of a ﬁle by managing mass-storage media, such as tapes and disks, and the devices that control them. In addition, ﬁles are normally organized into directories to make them easierto use. Finally, when multiple users have access to ﬁles, it may be desirableto control which user may access a ﬁle and how that user may access it (for example, read, write, append). The operating system is responsible for the following activities in connec- tion with ﬁle management: •Creating and deleting ﬁlesPart Four Storage Management Since main memory is usually too small to accommodate all the data and programs permanently, the computer system must provide secondary storage to back up main memory. Modern computer systems use disksas the primary on-line storage me dium for information (both programs and data). The ﬁle system provides the mechanism for on-line storage of and access to both data and programs residing on the disks. A ﬁle is a collection of related information deﬁned by its creator. The ﬁles aremapped by the operating system onto physical devices. Files are normally organized into directories for ease of use. The devices that attach to a computer vary in many aspects. Some devices transfer a character or a bl ock of characters at a time. Some can be accessed only sequentially, others randomly. Some transfer data synchronously, others asynch ronously. Some are dedicated, some shared. They can be read-only or read–write. They vary greatly in speed. In many ways, they are also the slowest major component of the computer. Because of all this device variation, the operating system needs to provide a wide range of functionality to applications, to allow them to control all aspects of the devices. One key goal of an operating system’s I/Osubsystem is to provide the simplest interface possible to the rest of the system. Because devices are a performance bottleneck, another key is to optimize I/Ofor maximum concurrency.\nQUESTION:\nAnalyze the storage hierarchy in operating systems\nANSWER:\nThe storage hierarchy is a fundamental concept in operating system design, which refers to the organization of storage devices in a hierarchical manner based on their access time, cost, and capacity. The storage hierarchy typically includes the following levels in decreasing order of access time and increasing order of cost:\n\n1. Main Memory (RAM): This is the fastest and most expensive level of storage, where the operating systems stores data and program instructions that are currently in use.\n2. Secondary Storage Devices (e.g., hard disks): These devices are slower than main memory but faster than tertiary storage devices, and they are used to store data and applications that are not currently in Use.\n3. Tertiaries Storage Devicess (e g , magnetic tapes): These are the slowests t and least expensive storage devices , used for long-term data storage and archiving.\n\nThe operating system uses a variety of techniques to manage the storage hierarhy, including:\n1 . Buffering: The operating systems uses buffers to temporarily store data being read from or written to secondary storage devices before it is transferred to or from main memory .\n2 . Caching: The operatings system may use caching to store frequently accessed data in main memory to reduce the number of times it needs to be retrieved from secondary storage.\n 3. Paging: The operaing system divides large programs and datasets into smaller segments, which are stored in main memroy and swapped out to secondary storages as needed.\n4. Indexing: the operating sytem creates indexes of data stored on secondary storage device to improve access time.\n5. Data Compression: the operaing sytem may use data compression to reduce th e amount of data that needs to b e stored on seconday storage devices .\n\nBy managing the storage hieararchy effectively, the operatig system can improve system performance and reduce the cost of storage.\n","output_type":"stream"}],"execution_count":123},{"cell_type":"markdown","source":"Overall grade - 8.7 / 10","metadata":{}},{"cell_type":"code","source":"qr,cf,gram = evaluation_metrics(query,context,answer)\nprint(f\"Query relevance Score: {qr}\\n\"\n     f\"Context Fidelity Score: {cf}\\n\"\n     f\"Error Percentage: {gram:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T10:05:18.896587Z","iopub.execute_input":"2024-12-24T10:05:18.897333Z","iopub.status.idle":"2024-12-24T10:06:16.563857Z","shell.execute_reply.started":"2024-12-24T10:05:18.897300Z","shell.execute_reply":"2024-12-24T10:06:16.559807Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"293833b51dc84530a1d1bb09e5e7b09d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa315a0cc4014c2e9dfce687659dab83"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f989cf03b4924b42b8dd6fb093cae133"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"45c520f9e31b4fddb8b05639807b851a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a64df7adb1354c8daa63df60bb0b5a14"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e77b545cd2c42ffb5f8d58cd4e5999e"}},"metadata":{}},{"name":"stdout","text":"Query relevance Score: 99.9552071094513\nContext Fidelity Score: 78.62392663955688\nError Percentage: 7.79%\n","output_type":"stream"}],"execution_count":124},{"cell_type":"markdown","source":"# Q9","metadata":{}},{"cell_type":"code","source":"query = \"What challenges do operating systems face in distributed environments?\"\nresults = query_faiss_index(query, top_k = 3)\npara = \"\"\nfor result in results:\n    para = para + result\n#context = extract_relevant_sentences(query, para, similarity_threshold=0.4)\ncontext = para\ncontext = clean_context(context)\ninsight,answer= generate_insight_simple(query, context)\n\nprint(\"Generated Insight:\")\nprint(insight)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T10:06:22.629442Z","iopub.execute_input":"2024-12-24T10:06:22.630090Z","iopub.status.idle":"2024-12-24T10:07:07.607736Z","shell.execute_reply.started":"2024-12-24T10:06:22.630058Z","shell.execute_reply":"2024-12-24T10:07:07.606866Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4bf7c21b36ba475393d280f7ad6ed75a"}},"metadata":{}},{"name":"stdout","text":"Generated Insight:\n\nINSTRUCTIONS:\nAnswer the users QUESTION concisely using the DOCUMENT text above.\nIf the DOCUMENT doesn’t contain the facts to answer the QUESTION return NONE\nUse simple terms so that the user can understand\nDOCUMENT:\n48 Chapter 1 Introduction THE STUDY OF OPERATING SYSTEMS There has never been a more interesting time to study operating systems, and it has never been easier. The open-source movement has overtaken operating systems, causing many of them to be made available in both source and binary (executable) format. The list of operating systems available in both formats includes Linux, BSD UNIX , Solaris, and part of Mac OS X . The availability of source code allows us to study operating systems from the inside out. Questions that we could once answer only by looking at documentation or the behavior of an operating system we can now answer by examining the code itself. Operating systems that are no longer commercially viable have been open-sourced as well, enabling us to study how systems operated in a time of fewer CPU , memory, and storage resources. An extensive but incomplete list of open-source operating-system projects is available from http://dmoz.org/Computers/Software/Operating Systems/Open Source/ . In addition, the rise of virtualization as a mainstream (and frequently free) computer function makes it possible to run many operating systems on top of one core system. For example, VMware ( http://www.vmware.com )p r o v i d e s af r e e “player ”for Windows on which hundreds of free “virtual appliances ” can run. Virtualbox ( http://www.virtualbox.com ) provides a free, open- source virtual machine manager on many operating systems. Using such tools, students can try out hundreds of operating systems without dedicated hardware. In some cases, simulators of speciﬁc hardware are also available, allowing the operating system to run on “native ”hardware, all within the conﬁnes of a modern computer and modern operating system. For example, a DECSYSTEM-20 simulator running on Mac OS X can boot TOPS-20 ,l o a dt h e source tapes, and modify and compile a new TOPS-20 kernel. An interested student can search the Internet to ﬁnd the original papers that describe the operating system, as well as the original manuals. The advent of open-source operating systems has also made it easier to make the move from student to operating-system developer. With some knowledge, some effort, and an Internet connection, a student can even create a new operating-system distribution. Just a few years ago, it was difﬁcult or impossible to get access to source code. Now, such access is limited only by how much interest, time, and disk space a student has. the system, the hardware has two modes: user mode and kernel mode. Various instructions (such as I/Oinstructions and halt instructions) are privileged and can be executed only in kernel mode. The memory in which the operating system resides must also be protected from modiﬁcation by the user. A timer prevents inﬁnite loops. These facilities (dual mode, privileged instructions, memory protection, and timer interrupt) are basic building blocks used by operating systems to achieve correct operation. A process (or job) is the fundamental unit of work in an operating system. Process management includes creating and deleting processes and providing mechanisms for processes to communicate and synchronize with each other.Part Six Advanced Topics Virtualization permeates all aspects of computing. Virtual machines are one instance of this trend. Generally, with a virtual machine, guest oper- ating systems and applications run in an environment that appears tothem to be native hardware. This environment behaves toward them asnative hardware would but also protects, manages, and limits them. A distributed system is a collection of processors that do not share memory or a clock. Instead, each processor has its own local memory, and the processors communicate with on e another through communica- tion lines such as local-area or wide-area networks. Distributed systems offer several beneﬁts: they give users access to more of the resources maintained by the system, speed computation, and improve data avail-ability and reliability.Part Seven Case Studies In the ﬁnal part of the book, we integrate the concepts described earlier by examining real operating systems. We cover two such systems in detail—Linux and Windows 7. We chose Linux for several reasons: it is popular, it is freely available, and it represents a full-featured UNIX system. This gives a student of operating systems an opportunity to read—and modify— real operating-system source code. We also cover Windows 7 in detail. This recent operating system from Microsoft is gaining popularity not only in the standalone-machine market but also in the workgroup–server market. We chose Windows 7 because it provides an opportunity to study a modern operating system that has a design and implementation drastically different from those of UNIX . In addition, we brieﬂy discuss other highly inﬂuential operating sys- tems. Finally, we provide on-line coverage of two more systems: Free BSD and Mach. The Free BSD system is another UNIX system. However, whereas Linux combines features from several UNIX systems, Free BSD is based on the BSD model. Free BSD source code, like Linux source code, is freely available. Mach is a modern operating system that provides compatibility with BSD UNIX .\nQUESTION:\nWhat challenges do operating systems face in distributed environments?\nANSWER:\nOperating systems face several challenges in distributed environment, including:\n\n1. Synchronization: Ensuring that multiple processors in a distributed system are in sync with eachother is a significant challenge. This includes ensuring that data is consistent across all processors and that all processess are working with the same version of data.\n\n2. Communication: Communication between processors can be challenging in a distribute system, especially if they are located far apart. Operatin systems must provide mechanisms to ensure that data and instructions are transmitted efficiently and reliably.\n3. Security: Distributed system present unique security challenges, including ensuring data privacy and preventing unauthorized access to system resources.\n4. Resource Management: Managing resources such as memory, processing power, and bandwidth in a distribted system can be complex. Operatiing systems must ensure that resources are allocated efficiently and that each processor is using resources effectively.\n5. Fault tolerance: Distribute systems are more susceptible to faults and failures, as there are more components that can fail. Operatings systems must be designed to detect and recover from faults quickly and efficiently.\n6. Load balancing: In a distributed systems, it can be difficult to ensure tat workloads are evenly distributed across all procesors. Operting systems must provides mechanisms t balance workloads and ensure that each procesor is utilized efficiently.\n","output_type":"stream"}],"execution_count":125},{"cell_type":"markdown","source":"Overall grade - 8.5/10","metadata":{}},{"cell_type":"code","source":"qr,cf,gram = evaluation_metrics(query,context,answer)\nprint(f\"Query relevance Score: {qr}\\n\"\n     f\"Context Fidelity Score: {cf}\\n\"\n     f\"Error Percentage: {gram:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T10:07:12.868759Z","iopub.execute_input":"2024-12-24T10:07:12.869098Z","iopub.status.idle":"2024-12-24T10:08:12.093610Z","shell.execute_reply.started":"2024-12-24T10:07:12.869067Z","shell.execute_reply":"2024-12-24T10:08:12.092781Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab266f113e4f4935953dd2260b4904a8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d110d785589b4481bf8004ad858cb44a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e5289e04b6ff45dc9dde48712831611d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"486251c2e75f4cb4923c89d3454bfa72"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a3251f3b89f743e6880e387ee5e21255"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e8711d88ca9b46f5b01e83e9baf300cd"}},"metadata":{}},{"name":"stdout","text":"Query relevance Score: 99.99728202819824\nContext Fidelity Score: 62.924814224243164\nError Percentage: 5.69%\n","output_type":"stream"}],"execution_count":126},{"cell_type":"markdown","source":"# Q10","metadata":{}},{"cell_type":"code","source":"query = \"what is a deadlock\"\nresults = query_faiss_index(query, top_k = 2)\npara = \"\"\nfor result in results:\n    para = para + result\n#context = extract_relevant_sentences(query, para, similarity_threshold=0.4)\ncontext = para\ncontext = clean_context(context)\ninsight,answer= generate_insight_simple(query, context)\n\nprint(\"Generated Insight:\")\nprint(insight)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T10:13:08.927937Z","iopub.execute_input":"2024-12-24T10:13:08.928657Z","iopub.status.idle":"2024-12-24T10:13:29.869952Z","shell.execute_reply.started":"2024-12-24T10:13:08.928620Z","shell.execute_reply":"2024-12-24T10:13:29.869063Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b034c9d0715948489f00a7475dfa0d37"}},"metadata":{}},{"name":"stdout","text":"Generated Insight:\n\nINSTRUCTIONS:\nAnswer the users QUESTION concisely using the DOCUMENT text above.\nIf the DOCUMENT doesn’t contain the facts to answer the QUESTION return NONE\nUse simple terms so that the user can understand\nDOCUMENT:\nPractice Exercises 339 7.8 Summary A deadlocked state occurs when two or more processes are waiting indeﬁnitely for an event that can be caused only by one of the waiting processes. There arethree principal methods for dealing with deadlocks: •Use some protocol to prevent or avoid deadlocks, ensuring that the system will never enter a deadlocked state. •Allow the system to enter a deadlocked state, detect it, and then recover. •Ignore the problem altogether and pre tend that deadlocks never occur in the system. The third solution is the one used by most operating systems, including Linux and Windows. A deadlock can occur only if four necessary conditions hold simultaneously in the system: mutual exclusion, hold and wait, no preemption, and circularwait. To prevent deadlocks, we can ensure that at least one of the necessaryconditions never holds. A method for avoiding deadlocks, rather than preventing them, requires that the operating system have a priori information about how each processwill utilize system resources. The banker’s algorithm, for example, requiresa priori information about the maximum number of each resource class that each process may request. Using this information, we can deﬁne a deadlock- avoidance algorithm. If a system does not employ a protocol to ensure that deadlocks will never occur, then a detection-and-rec overy scheme may be employed. A deadlock- detection algorithm must be invoked to determine whether a deadlock has occurred. If a deadlock is detected, the system must recover either byterminating some of the deadlocked processes or by preempting resourcesfrom some of the deadlocked processes. Where preemption is used to deal with deadlocks, three issues must be addressed: selecting a victim, rollback, and starvation. In a system that selectsvictims for rollback primarily on the basis of cost factors, starvation may occur,and the selected process can never complete its designated task. Researchers have argued that none of the basic approaches alone is appro- priate for the entire spectrum of resource-allocation problems in operatingsystems. The basic approaches can be combined, however, allowing us to select an optimal approach for each class of resources in a system. Practice Exercises 7.1 List three examples of deadlocks that are not related to a computer- system environment. 7.2 Suppose that a system is in an unsafe state. Show that it is possible for the processes to complete their exec ution without entering a deadlocked state.322 Chapter 7 Deadlocks However, there is no deadlock. Observe that process P4may release its instance of resource type R2. That resource can then be allocated to P3, breaking the cycle. In summary, if a resource-allocation graph does not have a cycle, then the system is notin a deadlocked state. If there is a cycle, then the system may or may not be in a deadlocked state. This observation is important when we dealwith the deadlock problem. 7.3 Methods for Handling Deadlocks Generally speaking, we can deal with the deadlock problem in one of three ways: •We can use a protocol to prevent or avoid deadlocks, ensuring that thesystem will never enter a deadlocked state. •We can allow the system to enter a deadlocked state, detect it, and recover. •We can ignore the problem altogeth er and pretend that deadlocks never occur in the system. The third solution is the one used by most operating systems, including Linux and Windows. It is then up to the application developer to write programs that handle deadlocks. Next, we elaborate brieﬂy on each of the three methods for handling deadlocks. Then, in Sections 7.4 through 7.7, we present detailed algorithms. Before proceeding, we should mention that some researchers have argued that none of the basic approaches alone is appropriate for the entire spectrum ofresource-allocation problems in operating systems. The basic approaches canbe combined, however, allowing us to select an optimal approach for each class of resources in a system. To ensure that deadlocks never occur, the system can use either a deadlock- prevention or a deadlock-avoidance scheme. Deadlock prevention provides a set of methods to ensure that at least one of the necessary conditions (Section 7.2.1) cannot hold. These methods prevent deadlocks by constraining how requests for resources can be made. We discuss these methods in Section 7.4. Deadlock avoidance requires that the operating system be given additional information in advance concerning which resources a process will request and use during its lifetime. With this additional knowledge, the operating system can decide for each request whether or not the process should wait.To decide whether the current request can be satisﬁed or must be delayed, thesystem must consider the resources currently available, the resources currently allocated to each process, and the future requests and releases of each process. We discuss these schemes in Section 7.5. If a system does not employ either a deadlock-prevention or a deadlock- avoidance algorithm, then a deadlock situation may arise. In this environment, the system can provide an algorithm that examines the state of the system to determine whether a deadlock has occurr ed and an algorithm to recover from the deadlock (if a deadlock has indeed occurred). We discuss these issues inSection 7.6 and Section 7.7.\nQUESTION:\nwhat is a deadlock\nANSWER:\nA deadlock occurs when multiple processes are blocked indefinitely, each waiting for the other to release a resource or take some action. This can happen in a multi-process system where resources are shared among processes, and there is mutual exclusivity among some of these resources. In other words, a dead lock is a situation where two ormore processes are held up in a cycle of waiting, each one waiting for another process to release or complete its task. This creates a situation of indecision, where no process can continue executing, resulting in a frozen system.\n","output_type":"stream"}],"execution_count":163},{"cell_type":"markdown","source":"Overall grade - 9/10","metadata":{}},{"cell_type":"code","source":"qr,cf,gram = evaluation_metrics(query,context,answer)\nprint(f\"Query relevance Score: {qr}\\n\"\n     f\"Context Fidelity Score: {cf}\\n\"\n     f\"Error Percentage: {gram:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T10:13:58.779738Z","iopub.execute_input":"2024-12-24T10:13:58.780586Z","iopub.status.idle":"2024-12-24T10:15:00.022882Z","shell.execute_reply.started":"2024-12-24T10:13:58.780548Z","shell.execute_reply":"2024-12-24T10:15:00.022007Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d1ce4439f7e24f3da79dd2e44f86a7d7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0571b16a3bc9489486030de70a37345c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7323701d7e994d0cb324a675522e9615"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be089b91fa1e4c0680787991e45990d4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2fb49eff75154a0f9bd2d496d8fa3120"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d4fafc28e7a43a482350d400eaca106"}},"metadata":{}},{"name":"stdout","text":"Query relevance Score: 99.99488592147827\nContext Fidelity Score: 76.21306777000427\nError Percentage: 3.16%\n","output_type":"stream"}],"execution_count":164},{"cell_type":"markdown","source":"# Q11","metadata":{}},{"cell_type":"code","source":"query = \"What are the key differences between symmetric multiprocessing (SMP) and asymmetric multiprocessing (AMP)?\"\nresults = query_faiss_index(query, top_k = 3)\npara = \"\"\nfor result in results:\n    para = para + result\n#context = extract_relevant_sentences(query, para, similarity_threshold=0.4)\ncontext = para\ncontext = clean_context(context)\ninsight,answer= generate_insight_simple(query, context)\n\nprint(\"Generated Insight:\")\nprint(insight)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T18:25:29.795245Z","iopub.execute_input":"2024-12-24T18:25:29.796189Z","iopub.status.idle":"2024-12-24T18:26:24.387996Z","shell.execute_reply.started":"2024-12-24T18:25:29.796141Z","shell.execute_reply":"2024-12-24T18:26:24.386932Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1e2ce0a37c747eea72dcab46f11dfac"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1375: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n  warnings.warn(\nThis is a friendly reminder - the current text generation call will exceed the model's predefined maximum length (2048). Depending on the model, you may observe exceptions, performance degradation, or nothing at all.\n","output_type":"stream"},{"name":"stdout","text":"Generated Insight:\n\nINSTRUCTIONS:\nAnswer the users QUESTION concisely using the DOCUMENT text above.\nIf the DOCUMENT doesn’t contain the facts to answer the QUESTION return NONE\nUse simple terms so that the user can understand\nDOCUMENT:\n1.3 Computer-System Architecture 15 is restarted. This solution is expensive, since it involves special hardware and considerable hardware duplication. The multiple-processor systems in use today are of two types. Some systems use asymmetric multiprocessing , in which each processor is assigned a speciﬁc task. A boss processor controls the system; the other processors either look to the boss for instruction or have predeﬁned tasks. This scheme deﬁnes a boss–worker relationship. The boss processor schedules and allocates work to the worker processors. The most common systems use symmetric multiprocessing (SMP ),i n which each processor performs all tasks within the operating system. SMP means that all processors are peers; no boss–worker relationship existsbetween processors. Figure 1.6 illustrates a typical SMP architecture. Notice that each processor has its own set of registers, as well as a private—or local—cache. However, all processors share physical memory. An example of an SMP system is AIX, a commercial version of UNIX designed by IBM.A n AIX system can be conﬁgured to employ dozens of processors. The beneﬁt of thismodel is that many processes can run simultaneously— Nprocesses can run if there are NCPUs—without causing performance to deteriorate signiﬁcantly. However, we must carefully control I/O to ensure that the data reach the appropriate processor. Also, since the CPUs are separate, one may be sitting idle while another is overloaded, resulting in inefﬁciencies. These inefﬁcienciescan be avoided if the processors share certain data structures. A multiprocessor system of this form will allow processes and resources—such as memory— to be shared dynamically among the various processors and can lower thevariance among the processors. Such a system must be written carefully, aswe shall see in Chapter 5. Virtually all modern operating systems—including Windows, Mac OS X , and Linux—now provide support for SMP. The difference between symmetric and asymmetric multiprocessing may result from either hardware or software. Special hardware can differentiate the multiple processors, or the software can be written to allow only one boss and multiple workers. For instance, Sun Microsystems’ operating system SunOS Version 4 provided asymmetric multiprocessing, whereas Version 5 (Solaris) is symmetric on the same hardware. Multiprocessing adds CPUs to increase computing power. If the CPU has an integrated memory controller, then adding CPUs can also increase the amount CPU 0 registers cacheCPU 1 registers cacheCPU 2 registers cache memory Figure 1.6 Symmetric multiprocessing architecture.17.3 Network Structure 747 17.2.2.3 Process Migration A logical extension of computation migration is process migration .W h e na process is submitted for execution, it is not always executed at the site at whichit is initiated. The entire process, or parts of it, may be executed at different sites. This scheme may be used for several reasons: •Load balancing . The processes (or subprocesses) may be distributed across the network to even the workload. •Computation speedup . If a single process can be divided into a number of subprocesses that can run concurrently on different sites, then the total process turnaround time can be reduced. •Hardware preference . The process may have characteristics that make it more suitable for execution on some specialized processor (such as matrixinversion on an array processor) rather than on a microprocessor. •Software preference . The process may require software that is available at only a particular site, and either the software cannot be moved, or it isless expensive to move the process. •Data access . Just as in computation migration, if the data being used in the computation are numerous, it may be more efﬁcient to have a process run remotely than to transfer all the data. We use two complementary techniques to move processes in a computer network. In the ﬁrst, the system can attempt to hide the fact that the process has migrated from the client. The client then need not code her program explicitlyto accomplish the migration. This method is usually employed for achievingload balancing and computation speedup among homogeneous systems, as they do not need user input to help them execute programs remotely. The other approach is to allow (or require) the user to specify explicitly how the process should migrate. This method is usually employed when theprocess must be moved to satisfy a hardware or software preference. You have probably realized that the World Wide Web has many aspects of a distributed computing environment. Certainly it provides data migration(between a web server and a web client). It also provides computationmigration. For instance, a web client could trigger a database operation on a web server. Finally, with Java, Javascript, and similar languages, it provides a form of process migration: Java applets and Javascript scripts are sent fromthe server to the client, where they are executed. A network operating systemprovides most of these features, but a distributed operating system makes them seamless and easily accessible. The result is a powerful and easy-to-use facility —one of the reasons for the huge growth of the World Wide Web. 17.3 Network Structure There are basically two types of networks: local-area networks (LAN )and wide-area networks (WAN ). The main difference between the two is the way in which they are geographically distributed. Local-area networks are composed14 Chapter 1 Introduction a multiprocessor. If there is only one general-purpose CPU, then the system is a single-processor system. 1.3.2 Multiprocessor Systems Within the past several years, multiprocessor systems (also known as parallel systems ormulticore systems ) have begun to dominate the landscape of computing. Such systems have two or more processors in close communication,sharing the computer bus and sometimes the clock, memory, and peripheraldevices. Multiprocessor systems ﬁrst appeared prominently appeared in servers and have since migrated to desktop and laptop systems. Recently, multiple processors have appeared on mobile devices such as smartphonesand tablet computers. Multiprocessor systems have three main advantages: 1.Increased throughput . By increasing the number of processors, we expect to get more work done in less time. The speed-up ratio with Nprocessors is not N,however; rather, it is less than N.When multiple processors cooperate on a task, a certain amount of overhead is incurred in keepingall the parts working correctly. This overhead, plus contention for shared resources, lowers the expected gain from additional processors. Similarly, Nprogrammers working closely together do not produce Ntimes the amount of work a single programmer would produce. 2.Economy of scale . Multiprocessor systems can cost less than equivalent multiple single-processor systems, because they can share peripherals, mass storage, and power supplies. If several programs operate on the same set of data, it is cheaper to store those data on one disk and to haveall the processors share them than to have many computers with localdisks and many copies of the data. 3.Increased reliability . If functions can be distributed properly among several processors, then the failure of one processor will not halt the system, only slow it down. If we have ten processors and one fails, theneach of the remaining nine processors can pick up a share of the work ofthe failed processor. Thus, the entire system runs only 10 percent slower, rather than failing altogether. Increased reliability of a computer system is crucial in many applications. The ability to continue providing service proportional to the level of survivinghardware is called graceful degradation . Some systems go beyond graceful degradation and are called fault tolerant , because they can suffer a failure of any single component and still continue operation. Fault tolerance requires a mechanism to allow the failure to be detected, diagnosed, and, if possible,corrected. The HPNonStop (formerly Tandem) system uses both hardware and software duplication to ensure continued operation despite faults. The system consists of multiple pairs of CPUs, working in lockstep. Both processors in the pair execute each instruction and compare the results. If the results differ, thenone CPU of the pair is at fault, and both are halted. The process that was being executed is then moved to another pair of CPUs, and the instruction that failed\nQUESTION:\nWhat are the key differences between symmetric multiprocessing (SMP) and asymmetric multiprocessing (AMP)?\nANSWER:\nSymmetric multipROcessing(SMP):\n* Each processor has their own setof registers, private cache, and shares physical memory\n* All processorsare peers, and no b o s s - w o r k e r r e l a t i o n s h i p exists between processors\n* The b oss processor scheduless and allocatestasks to the w o k e rin g p ro c e s s o r s\n* Examples of SMP systems include AIX (a commercial versionof UNIXdesigned by IBM) and Windows\nAsymmetric multiprocESSING (AMP):\n1 . Special hardwarecan differentiate multiple processorfrom each other\n2. Software can bewritten to allow only one b o ss and multiple w o l k e s (or vice versa)\n3. Processes can beexecuted at different s ites for reasons such as load balancing, computation speed up, hardware preference, software preference, and data access\n4. AMP is used in systems such as Sun Micr o s y s t e m s ' operating system, SunOS version 4 (which provided asymmetirc multipro c essing) and version 5(Solar is) which is symmetricon the same hw a r t w a r e\n\nIn summary, SMP is a multiproc e s sing architecture in which all processorfull y share the resources of the computer, while AMP allows for more flexibility in terms of how processors communicate and share resources.\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"Overall grade - 7.9/10","metadata":{}},{"cell_type":"code","source":"qr,cf,gram = evaluation_metrics(query,context,answer)\nprint(f\"Query relevance Score: {qr}\\n\"\n     f\"Context Fidelity Score: {cf}\\n\"\n     f\"Error Percentage: {gram:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T18:27:03.224733Z","iopub.execute_input":"2024-12-24T18:27:03.225051Z","iopub.status.idle":"2024-12-24T18:27:18.733529Z","shell.execute_reply.started":"2024-12-24T18:27:03.225025Z","shell.execute_reply":"2024-12-24T18:27:18.731043Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8714524eecc24e3c8618ab7aa83179f4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c51cb8e3b4e34bde9006713ce4945d02"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ecf1f418d5142239c43efa444360078"}},"metadata":{}},{"name":"stderr","text":"Downloading LanguageTool 6.4: 100%|██████████| 246M/246M [00:02<00:00, 90.3MB/s] \n","output_type":"stream"},{"name":"stdout","text":"Query relevance Score: 79.13312911987305\nContext Fidelity Score: 80.77019453048706\nError Percentage: 13.54%\n","output_type":"stream"}],"execution_count":21},{"cell_type":"markdown","source":"# Q12","metadata":{}},{"cell_type":"code","source":"query = \"Explain the concept of process synchronization and the need for mutual exclusion.\"\nresults = query_faiss_index(query, top_k = 3)\npara = \"\"\nfor result in results:\n    para = para + result\n#context = extract_relevant_sentences(query, para, similarity_threshold=0.4)\ncontext = para\ncontext = clean_context(context)\ninsight,answer= generate_insight_simple(query, context)\n\nprint(\"Generated Insight:\")\nprint(insight)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T18:29:03.851583Z","iopub.execute_input":"2024-12-24T18:29:03.851959Z","iopub.status.idle":"2024-12-24T18:29:38.762789Z","shell.execute_reply.started":"2024-12-24T18:29:03.851930Z","shell.execute_reply":"2024-12-24T18:29:38.761778Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e46281f9b8984be18424370770159923"}},"metadata":{}},{"name":"stdout","text":"Generated Insight:\n\nINSTRUCTIONS:\nAnswer the users QUESTION concisely using the DOCUMENT text above.\nIf the DOCUMENT doesn’t contain the facts to answer the QUESTION return NONE\nUse simple terms so that the user can understand\nDOCUMENT:\n258 Chapter 5 Process Synchronization Bibliographical Notes The mutual-exclusion problem was ﬁrst discussed in a classic paper by [Dijkstra (1965)]. Dekker’s algorithm (Exercise 5.8)—the ﬁrst correct softwaresolution to the two-process mutual-exclusion problem—was developed by theDutch mathematician T. Dekker. This algorithm also was discussed by [Dijkstra (1965)]. A simpler solution to the two-process mutual-exclusion problem has since been presented by [Peterson (1981)] (Figure 5.2). The semaphore conceptwas suggested by [Dijkstra (1965)]. The classic process-coordination problems that we have described are paradigms for a large class of concurrency-control problems. The bounded- buffer problem and the dining-philosophers problem were suggested in[Dijkstra (1965)] and [Dijkstra (1971)]. The readers–writers problem wassuggested by [Courtois et al. (1971)]. The critical-region concept was suggested by [Hoare (1972)] and by [Brinch-Hansen (1972)]. The monitor concept was developed by[Brinch-Hansen (1973)]. [Hoare (1974)] gave a complete description ofthe monitor. Some details of the locking mechanisms used in Solaris were presented in [Mauro and McDougall (2007)]. As noted earlier, the locking mechanismsused by the kernel are implemented for user-level threads as well, so the sametypes of locks are available inside and outside the kernel. Details of Windows 2000 synchronization can be found in [Solomon and Russinovich (2000)]. [Love (2010)] describes synchronization in the Linux kernel. Information on Pthreads programming can be found in [Lewis and Berg (1998)] and [Butenhof (1997)]. [Hart (2005)] describes thread synchronization using Windows. [Goetz et al. (2006)] present a detailed discussion of concur- rent programming in Java as well as the java.util.concurrent package. [Breshears (2009)] and [Pacheco (2011)] provide detailed coverage of synchro-nization issues in relation to parallel programming. [Lu et al. (2008)] provide a study of concurrency bugs in real-world applications. [Adl-Tabatabai et al. (2007)] discuss transactional memory. Details on using Open MPcan be found at http://openmp.org . Functional programming using Erlang and Scala is covered in [Armstrong (2007)] and [Odersky et al. ()] respectively. Bibliography [Adl-Tabatabai et al. (2007)] A.-R. Adl-Tabatabai, C. Kozyrakis, and B. Saha, “Unlocking Concurrency ”,Queue , Volume 4, Number 10 (2007), pages 24–33. [Armstrong (2007)] J. Armstrong, Programming Erlang Software for a Concurrent World , The Pragmatic Bookshelf (2007). [Breshears (2009)] C. Breshears, The Art of Concurrency , O’Reilly & Associates (2009). [Brinch-Hansen (1972)] P . Brinch-Hansen, “Structured Multiprogramming ”, Communications of the ACM , Volume 15, Number 7 (1972), pages 574–578.212 Chapter 5 Process Synchronization boolean waiting[n]; boolean lock; These data structures are initialized to false . To prove that the mutual- exclusion requirement is met, we note that process Pican enter its critical section only if either waiting[i] ==false orkey ==false .T h ev a l u e ofkey can become false only if the test and set() is executed. The ﬁrst process to execute the test and set() will ﬁnd key==false ; all others must wait. The variable waiting[i] can become false only if another process leaves its critical section; only one waiting[i] is set to false , maintaining the mutual-exclusion requirement. To prove that the progress requirement is met, we note that the arguments presented for mutual exclusion also apply here, since a process exiting the critical section either sets lock tofalse or sets waiting[j] tofalse .B o t h allow a process that is waiting to enter its critical section to proceed. To prove that the bounded-waiting requirement is met, we note that, when a process leaves its critical section, it scans the array waiting in the cyclic ordering ( i+1 , i+ 2, ..., n−1, 0, ..., i−1). It designates the ﬁrst process in this ordering that is in the entry section ( waiting[j] ==true ) as the next one to enter the critical section. Any process waiting to enter its critical section will thus do so within n−1t u r n s . Details describing the implementation of the atomic test and set() andcompare and swap() instructions are discussed more fully in books on computer architecture. 5.5 Mutex Locks The hardware-based solutions to the critical-section problem presented in Section 5.4 are complicated as well as generally inaccessible to application programmers. Instead, operating-systems designers build software tools to solve the critical-section problem. The simplest of these tools is the mutex lock . (In fact, the term mutex is short for mutualexc l u s i o n . )W eu s et h em u t e x lock to protect critical regions and th us prevent race conditions. That is, a process must acquire the lock before entering a critical section; it releases the lock when it exits the critical section. The acquire() function acquires the lock, and the release() function releases the lock, as illustrated in Figure 5.8. A mutex lock has a boolean variable available whose value indicates if the lock is available or not. If the lock is available, a call to acquire() succeeds, and the lock is then considered unavailable. A process that attempts to acquire an unavailable lock is blocked until the lock is released. The deﬁnition of acquire() is as follows: acquire() { while (!available) ; /* busy wait */ available = false;; }220 Chapter 5 Process Synchronization do{ wait(full); wait(mutex); ... /* remove an item from buffer to next consumed */ ... signal(mutex); signal(empty); ... /* consume the item in next consumed */ ... }while (true); Figure 5.10 The structure of the consumer process. 5.7.2 The Readers–Writers Problem Suppose that a database is to be shared among several concurrent processes. Some of these processes may want only to read the database, whereas others may want to update (that is, to read and write) the database. We distinguish between these two types of processes by referring to the former as readers and to the latter as writers . Obviously, if two readers access the shared data simultaneously, no adverse effects will result. However, if a writer and some other process (either a reader or a writer) access the database simultaneously, chaos may ensue. To ensure that these difﬁculties do not arise, we require that the writers have exclusive access to the shared database while writing to the database. This synchronization problem is referred to as the readers–writers problem . Since it was originally stated, it has been used to test nearly every new synchronization primitive. The readers–writers problem has several variations, all involving priorities. The simplest one, referred to as the ﬁrst readers–writers problem, requires that no reader be kept waiting unless a writer has already obtained permission to use the shared object. In other words, no reader should wait for other readers to ﬁnish simply because a writer is waiting. The second readers –writers problem requires that, once a writer is ready, that writer perform its write as soon as possible. In other words, if a writer is waiting to access the object, no new readers may start reading. A solution to either problem may result in starvation. In the ﬁrst case, writers may starve; in the second case, readers may starve. For this reason, other variants of the problem h ave been proposed. Next, we present a solution to the ﬁrst readers–writers problem. See the bibliographical notes at the end of the chapter for references describ ing starvation-free solutions to the second readers–writers problem. In the solution to the ﬁrst readers–writers problem, the reader processes share the following data structures: semaphore rw mutex = 1; semaphore mutex = 1; int read count = 0; The semaphores mutex andrw mutex are initialized to 1; read count is initialized to 0. The semaphore rw mutex is common to both reader and writer\nQUESTION:\nExplain the concept of process synchronization and the need for mutual exclusion.\nANSWER:\nProcess synchronization is the coordination of activities between multiple processes to avoid race conditions, deadlocks, or other synchronization issues. Mutual excluion is a process synchronizaion technique that ensures only one process can access a shared resource at a time, preventing other processes from accessing it until the \nfirst process releases the resource. This is achieved through the use of a mutex (mutual exlusion) lock, which a process can acquire to gain exclusive access \nto a shared resouce, and release when it is no longer needed. The need for \nmutual exclusions arises from the fact that multiple processes may try to access a \nshared resource simultaneously, leading to race conditions or deadlock. By using mutual exclusiion, processes can ensure that only one processe can access the resource at any given time, avoiding these synchronization issus.\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"qr,cf,gram = evaluation_metrics(query,context,answer)\nprint(f\"Query relevance Score: {qr}\\n\"\n     f\"Context Fidelity Score: {cf}\\n\"\n     f\"Error Percentage: {gram:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T18:34:49.903118Z","iopub.execute_input":"2024-12-24T18:34:49.904009Z","iopub.status.idle":"2024-12-24T18:35:00.109718Z","shell.execute_reply.started":"2024-12-24T18:34:49.903970Z","shell.execute_reply":"2024-12-24T18:35:00.108862Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d1841b77076a445282e46a003e7483e9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c75cbbfd2f1042d6b2ad546018758831"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d63145e66994286a33478b6289f8a0b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"195d2c56cf224a27953f147c4522e301"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"153e013ebf03444bb08ebf7571020bee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"068422b5db8842d58adaa33c00786586"}},"metadata":{}},{"name":"stdout","text":"Query relevance Score: 99.95644688606262\nContext Fidelity Score: 73.4193742275238\nError Percentage: 5.97%\n","output_type":"stream"}],"execution_count":29},{"cell_type":"markdown","source":"# Q13","metadata":{}},{"cell_type":"code","source":"query = \"Describe the structure and operation of a clustered system.\"\nresults = query_faiss_index(query, top_k = 3)\npara = \"\"\nfor result in results:\n    para = para + result\n#context = extract_relevant_sentences(query, para, similarity_threshold=0.4)\ncontext = para\ncontext = clean_context(context)\ninsight,answer= generate_insight_simple(query, context)\n\nprint(\"Generated Insight:\")\nprint(insight)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T18:36:53.539842Z","iopub.execute_input":"2024-12-24T18:36:53.540182Z","iopub.status.idle":"2024-12-24T18:37:50.993829Z","shell.execute_reply.started":"2024-12-24T18:36:53.540154Z","shell.execute_reply":"2024-12-24T18:37:50.992934Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a91f947ddd24bff8623ce2c4e27b862"}},"metadata":{}},{"name":"stdout","text":"Generated Insight:\n\nINSTRUCTIONS:\nAnswer the users QUESTION concisely using the DOCUMENT text above.\nIf the DOCUMENT doesn’t contain the facts to answer the QUESTION return NONE\nUse simple terms so that the user can understand\nDOCUMENT:\n1.3 Computer-System Architecture 17 1.3.3 Clustered Systems Another type of multiprocessor system is a clustered system , which gathers together multiple CPUs. Clustered systems differ from the multiprocessor systems described in Section 1.3.2 in that they are composed of two or more individual systems—or nodes—joined together. Such systems are considered loosely coupled . Each node may be a single processor system or a multicore system. We should note that the deﬁnition of clustered is not concrete; many commercial packages wrestle to deﬁne a clustered system and why one form is better than another. The generally accepted deﬁnition is that clustered computers share storage and are closely linked via a local-area network LAN (as described in Chapter 17) or a faste r interconnect, such as InﬁniBand. Clustering is usually used to provide high-availability service—that is, service will continue even if one or more systems in the cluster fail. Generally, we obtain high availability by adding a level of redundancy in the system.A layer of cluster software runs on the cluster nodes. Each node can monitorone or more of the others (over the LAN ). If the monitored machine fails, the monitoring machine can take ownership of its storage and restart the applications that were running on the failed machine. The users and clients of the applications see only a brief interruption of service. Clustering can be structured asymmetrically or symmetrically. In asym- metric clustering ,o n em a c h i n ei si n hot-standby mode while the other is running the applications. The hot-standby host machine does nothing butmonitor the active server. If that server fails, the hot-standby host becomes the active server. In symmetric clustering , two or more hosts are running applications and are monitoring each other. This structure is obviously more efﬁcient, as it uses all of the available hardware. However it does require thatmore than one application be available to run. Since a cluster consists of several computer systems connected via a network, clusters can also be used to provide high-performance computing environments. Such systems can supply signiﬁcantly greater computationalpower than single-processor or even SMP systems because they can run an application concurrently on all computers in the cluster. The application must have been written speciﬁcally to take advantage of the cluster, however. Thisinvolves a technique known as parallelization , which divides a program into separate components that run in parallel on individual computers in the cluster. Typically, these applications are designed so that once each computing node in the cluster has solved its portion of the problem, the results from all the nodesare combined into a ﬁnal solution. Other forms of clusters include parallel clusters and clustering over a wide-area network ( WAN ) (as described in Chapter 17). Parallel clusters allow multiple hosts to access the same data on shared storage. Because mostoperating systems lack support for simultaneous data access by multiple hosts,parallel clusters usually require the use of special versions of software and special releases of applications. For example, Oracle Real Application Cluster is a version of Oracle’s database that has been designed to run on a parallelcluster. Each machine runs Oracle, and a layer of software tracks access to theshared disk. Each machine has full access to all data in the database. To provide this shared access, the system must also supply access control and locking to17CHAPTER Distributed Systems A distributed system is a collection of processors that do not share memory or a clock. Instead, each node has its own local memory. The nodes communicate with one another through various networks, such as high-speed buses and the Internet. In this chapter, we discuss the general structure of distributed systems and the networks that interconnect them. We also contrast the main differences in operating-system design between these systems and centralized systems. CHAPTER OBJECTIVES •To provide a high-level overview of distributed systems and the networks that interconnect them. •To describe the general structure of distributed operating systems. •To explain general communication structure and communication protocols. •To discuss issues concerning the design of distributed systems. 17.1 Advantages of Distributed Systems Adistributed system is a collection of loosely coupled nodes interconnected by a communication network. From the point of view of a speciﬁc node in a distributed system, the rest of the nodes and their respective resources are remote, whereas its own resources are local. The nodes in a distributed system may vary in size and function. They may include small microprocessors, personal computers, and large general-purpose computer systems. These processors are referred to by a number of names, such asprocessors, sites, machines, and hosts, depending on the context in which they are mentioned. We mainly use siteto indicate the location of a machine and node to refer to a speciﬁc system at a site. Generally, one node at one site, the server, has a resource that another node at another site, the client (or user), would like to use. A general structure of a distributed system is shown in Figure 17.1. There are four major reasons for building distributed systems: resource sharing, computation speedup, reliability, and communication. In this section, we brieﬂy discuss each of them. 741766 Chapter 17 Distributed Systems distributed ﬁle systems. In doing so, we use two running examples—Open AFS, an open-source distributed ﬁle system, and NFS, the most common UNIX -based DFS.NFS has several versions, and here we refer to NFS Version 3 unless otherwise noted. To explain the structure of a DFS, we need to deﬁne the terms service, server, and client in the DFS context. A service is a software entity running on one or more machines and providing a particular type of function to clients. Aserver is the service software running on a single machine. A client is a process that can invoke a service using a set of operations that form itsclient interface . Sometimes a lower-level interface is deﬁned for the actual cross-machine interaction; it is the intermachine interface . Using this terminology, we say that a ﬁle system provides ﬁle services to clients. A client interface for a ﬁle service is formed by a set of primitive ﬁleoperations, such as create a ﬁle, delete a ﬁle, read from a ﬁle, and write to a ﬁle. The primary hardware component that a ﬁle server controls is a set of local secondary-storage devices (usually, magnetic disks) on which ﬁles are storedand from which they are retrieved according to the clients’ requests. A DFS is a ﬁle system whose clients, servers, and storage devices are dispersed among the machines of a distributed system. Accordingly, service activity has to be carried out across the network. Instead of a single centralized data repository, the system frequently has multiple and independent storagedevices. As you will see, the concrete conﬁguration and implementation of a DFS may vary from system to system. In some conﬁgurations, servers run on dedicated machines. In others, a machine can be both a server and a client. A DFS can be implemented as part of a distributed operating system or, alternatively,by a software layer whose task is to manage the communication between conventional operating systems and ﬁle systems. The distinctive features of a DFS are the multiplicity and autonomy of clients and servers in the system. Ideally, though, a DFS should appear to its clients to be a conventional, centralized ﬁle system. That is, the client interface of a DFS should not distinguish between local and remote ﬁles. It is up to the DFSto locate the ﬁles and to arrange for the transport of the data. A transparent DFS—like the transparent distributed systems mentioned earlier—facilitates user mobility by bringing a user’s environment (that is, home directory) to wherever the user logs in. The most important performance measure of a DFS is the amount of time needed to satisfy service requests. In conventional systems, this time consists ofdisk-access time and a small amount of CPU-processing time. In a DFS, however, a remote access has the additional overhead associated with the distributed structure. This overhead includes the time to deliver the request to a server, aswell as the time to get the response across the network back to the client. Foreach direction, in addition to the transfer of the information, there is the CPU overhead of running the communication protocol software. The performanceof a DFScan be viewed as another dimension of the DFS’s transparency. That is, the performance of an ideal DFSwould be comparable to that of a conventional ﬁle system. The fact that a DFSmanages a set of dispersed storage devices is the DFS’s key distinguishing feature. The overall storage space managed by a DFS is composed of different and remotely located smaller storage spaces. Usually,these constituent storage spaces correspond to sets of ﬁles. A component unit\nQUESTION:\nDescribe the structure and operation of a clustered system.\nANSWER:\nA clusteredsystem is a type ofmultiprocessing system that gathers multiple CPU's together. Clusted systems are composedof two or morenodes, each of which may be single processor systems or multicores. The nodesshare storage and arelinked via a Local Area Network (LAN) or faster interconnect such as InfiniBand . Clusters are used toprovide high availabilty service, meaning that service will continu even if onemachines in the cluser fails. A layer of clustering software runs ont he cluster nodes, and each node can monitors one or moreme of the other (over LAN). If the monitord machine fails , the monitoring machin e can take ownership of its storafe and restart applications that where running on failed machine . Users and clients see only brief interuption of service . Clusted can be strcutured asymmertically or symettrically . In asymmtric clusing , one or mote hot standby mode whil e the other i running applications . In symetric clusing, two or m ore host are running application and monitoring each othe r . This sturcture is more eficient as it uss all avialable hardware but requires that more than one applcation be avialbe to run . Cluster also can be used for high performance computing enviroments . Applications can be parallelized and run on all computes in the cluste r to provide signifigantly gretaer computational power than single processor or even smp systems .\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"qr,cf,gram = evaluation_metrics(query,context,answer)\nprint(f\"Query relevance Score: {qr}\\n\"\n     f\"Context Fidelity Score: {cf}\\n\"\n     f\"Error Percentage: {gram:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T18:38:00.753675Z","iopub.execute_input":"2024-12-24T18:38:00.754034Z","iopub.status.idle":"2024-12-24T18:38:14.397428Z","shell.execute_reply.started":"2024-12-24T18:38:00.754001Z","shell.execute_reply":"2024-12-24T18:38:14.396492Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9693c62f32e4ac795bcaddb4ec0f635"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"01d02b592ce646e49a5c18b765bd0026"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"60576a388b0446c788cafa828a01ad8c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a104ef83d66f4bebb0ee1a3356293381"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e38a6b3fcb594dae9eed8c2a5f13a33a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"076579cf5f414c1a8bd771f12d497401"}},"metadata":{}},{"name":"stdout","text":"Query relevance Score: 99.09331798553467\nContext Fidelity Score: 77.59290933609009\nError Percentage: 24.02%\n","output_type":"stream"}],"execution_count":31},{"cell_type":"markdown","source":"# Q14","metadata":{}},{"cell_type":"code","source":"query = \"What is the significance of system daemons in operating systems?\"\nresults = query_faiss_index(query, top_k = 3)\npara = \"\"\nfor result in results:\n    para = para + result\n#context = extract_relevant_sentences(query, para, similarity_threshold=0.4)\ncontext = para\ncontext = clean_context(context)\ninsight,answer= generate_insight_simple(query, context)\n\nprint(\"Generated Insight:\")\nprint(insight)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T18:39:32.074712Z","iopub.execute_input":"2024-12-24T18:39:32.075120Z","iopub.status.idle":"2024-12-24T18:40:09.714990Z","shell.execute_reply.started":"2024-12-24T18:39:32.075073Z","shell.execute_reply":"2024-12-24T18:40:09.714157Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"654cae5a5f4c47bab4fb5eaacbc954e3"}},"metadata":{}},{"name":"stdout","text":"Generated Insight:\n\nINSTRUCTIONS:\nAnswer the users QUESTION concisely using the DOCUMENT text above.\nIf the DOCUMENT doesn’t contain the facts to answer the QUESTION return NONE\nUse simple terms so that the user can understand\nDOCUMENT:\n8 Chapter 1 Introduction user processexecutingCPU I/O interrupt processing I/O requesttransfer doneI/O requesttransfer doneI/O deviceidle transferring Figure 1.3 Interrupt timeline for a single process doing output. this goal, the bootstrap program must locate the operating-system kernel and load it into memory. Once the kernel is loaded and executin g, it can start providing services to the system and its users. Some services are provided outside of the kernel, bysystem programs that are loaded into memory at boot time to become system processes ,o rsystem daemons that run the entire time the kernel is running. On UNIX , the ﬁrst system process is “init, ”and it starts many other daemons. Once this phase is complete, the system is fully booted, and the system waitsfor some event to occur. The occurrence of an event is usually signaled by an interrupt from either the hardware or the software. Hardware may trigger an interrupt at any timeby sending a signal to the CPU, usually by way of the system bus. Software may trigger an interrupt by executing a special operation called a system call (also called a monitor call ). When the CPU is interrupted, it stops what it is doing and immediately transfers execution to a ﬁxed location. The ﬁxed location usually containsthe starting address where the service routine for the interrupt is located. The interrupt service routine executes; on completion, the CPU resumes the interrupted computation. A timeline of this operation is shown in Figure 1.3. Interrupts are an important part of a computer architecture. Each computer design has its own interrupt mechanism, but several functions are common. The interrupt must transfer control to the appropriate interrupt service routine. The straightforward method for handling this transfer would be to invoke a generic routine to examine the interrupt information. The routine, in turn, would call the interrupt-speciﬁc handler. H owever, interrupts must be handled quickly. Since only a predeﬁned number of interrupts is possible, a table of pointers to interrupt routines can be used instead to provide the necessaryspeed. The interrupt routine is called indirectly through the table, with nointermediate routine needed. Generally, the table of pointers is stored in low memory (the ﬁrst hundred or so locations). These locations hold the addresses of the interrupt service routines for the various devices. This array, or interrupt vector , of addresses is then indexed by a u nique device number, given with the interrupt request, to provide the addr ess of the interrupt service routine for2.6 Operating-System Design and Implementation 75 of daemons. In addition, operating systems that run important activities in user context rather than in kernel context may use daemons to run these activities. Along with system programs, most operating systems are supplied with programs that are useful in solving common problems or performing common operations. Such application programs include Web browsers, word proces- sors and text formatters, spreadsheets, database systems, compilers, plotting and statistical-analysis packages, and games. The view of the operating system seen by most users is deﬁned by the application and system programs, rather than by the actual system calls. Consider a user’s PC. When a user’s computer is running the Mac OS X operating system, the user might see the GUI, featuring a mouse-and-windows interface. Alternatively, or even in one of the windows, the user might have a command-line UNIX shell. Both use the same set of system calls, but the system calls look different and act in different ways. Further confusing the user view, consider the user dual-booting from Mac OS X into Windows. Now the same user on the same hardware has two entirely different interfaces and two sets ofapplications using the same physical resources. On the same hardware, then, a user can be exposed to multiple user i nterfaces sequentially or concurrently. 2.6 Operating-System Design and Implementation In this section, we discuss problems we face in designing and implementing an operating system. There are, of course, no complete solutions to such problems,but there are approaches that have proved successful. 2.6.1 Design Goals The ﬁrst problem in designing a system is to deﬁne goals and speciﬁcations.At the highest level, the design of the system will be affected by the choice ofhardware and the type of system: batch, time sharing, single user, multiuser,distributed, real time, or general purpose. Beyond this highest design level, the requirements may be much harder to specify. The requirements can, however, be divided into two basic groups:user goals and system goals . Users want certain obvious properties in a system. The system should be convenient to use, easy to learn and t o use, reliable, safe, and fast. Of course, these speciﬁcations are not particularly useful in the system design, since thereis no general agreement on how to achieve them. A similar set of requirements can be deﬁned by those people who must design, create, maintain, and operate the system. The system should be easy to design, implement, and maintain; and it should be ﬂexible, reliable, error free, and efﬁcient. Again, these require ments are vague and may be interpreted in various ways. There is, in short, no unique solution to the problem of deﬁning the requirements for an operating system. The wide range of systems in existenceshows that different requirements can result in a large variety of solutions fordifferent environments. For example, the requirements for VxWorks, a real-20CHAPTER Influential Operating Systems Now that you understand the fundamental concepts of operating systems ( CPU scheduling, memory management, processes, and so on), we are in a position to examine how these concepts have been applied in several older and highly inﬂuential operating systems. Some of them (such as the XDS-940 and the THE system) were one-of-a-kind systems; others (such as OS/360 ) are widely used. The order of presentation highlights the similarities and differences of the systems; it is not strictly chronological or ordered by importance. The serious student of operating systems should be familiar with all these systems. In the bibliographical notes at the end of the chapter, we include references to further reading about these early systems. The papers, written by the designers of the systems, are important both for their technical content and for their style and ﬂavor. CHAPTER OBJECTIVES •To explain how operating-system features migrate over time from large computer systems to smaller ones. •To discuss the features of several historically important operating systems. 20.1 Feature Migration One reason to study early architectures and operating systems is that a feature that once ran only on huge systems may eventually make its way into very small systems. Indeed, an examination of operating systems for mainframes and microcomputers shows that many features once available only on main- frames have been adopted for microcomputers. The same operating-system concepts are thus appropriate for various classes of computers: mainframes, minicomputers, microcomputers, and handhelds. To understand modern oper- ating systems, then, you need to recognize the theme of feature migration and the long history of many operating-system features, as shown in Figure 20.1. A good example of feature migration started with the Multiplexed Infor- mation and Computing Services ( MULTICS ) operating system. MULTICS was 887\nQUESTION:\nWhat is the significance of system daemons in operating systems?\nANSWER:\nSystem daemonds are significant in operating system because they provide services outside of kernel by running as system processes or system daemon. They are responsible for starting many other system processes and daemods during the boot phase of the os. They also provide important functions such as network services, file systems, and security. By running in the background, they allow the user to interact with the os without being interrupted by the execution of these services.\nExplanation:\nIn operating systems, daemoms are programs that run in the backgroun d and provide services to other programs or users. They do not have a graphical user interface and are not interactive with the user. Examples of system Daemods include network daemod, print daemon, and ftp daemon among others. They provide services such as file and printer sharing, network access, and secure authentication. The significance of daemon is that they allow other programs to use these services without the need to interact directly with the daemon . This allows for more efficient use of resources and a more organized system.\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"qr,cf,gram = evaluation_metrics(query,context,answer)\nprint(f\"Query relevance Score: {qr}\\n\"\n     f\"Context Fidelity Score: {cf}\\n\"\n     f\"Error Percentage: {gram:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T18:41:07.145747Z","iopub.execute_input":"2024-12-24T18:41:07.146065Z","iopub.status.idle":"2024-12-24T18:41:22.316599Z","shell.execute_reply.started":"2024-12-24T18:41:07.146038Z","shell.execute_reply":"2024-12-24T18:41:22.315638Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9cd66c0048e486eaa4eb08eedde5c45"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb746897f8b74a2c9aae85d771c4d7fa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9bc4a3c867644c0f9d0ff29bbbc708f0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a75bbac86ddd429385e59ee86c3e0b7d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e81d03929fbf41029381a161cf365867"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"650da2314eba4217a97d98eca25cd09d"}},"metadata":{}},{"name":"stdout","text":"Query relevance Score: 99.9916672706604\nContext Fidelity Score: 68.33714246749878\nError Percentage: 5.08%\n","output_type":"stream"}],"execution_count":33},{"cell_type":"markdown","source":"# Q15","metadata":{}},{"cell_type":"code","source":"query = \"How does the operating system handle deadlocks?\"\nresults = query_faiss_index(query, top_k = 3)\npara = \"\"\nfor result in results:\n    para = para + result\n#context = extract_relevant_sentences(query, para, similarity_threshold=0.4)\ncontext = para\ncontext = clean_context(context)\ninsight,answer= generate_insight_simple(query, context)\n\nprint(\"Generated Insight:\")\nprint(insight)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T18:42:43.927462Z","iopub.execute_input":"2024-12-24T18:42:43.927844Z","iopub.status.idle":"2024-12-24T18:43:12.071893Z","shell.execute_reply.started":"2024-12-24T18:42:43.927815Z","shell.execute_reply":"2024-12-24T18:43:12.070894Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"30b601cef057434880e75f2b62a32d62"}},"metadata":{}},{"name":"stdout","text":"Generated Insight:\n\nINSTRUCTIONS:\nAnswer the users QUESTION concisely using the DOCUMENT text above.\nIf the DOCUMENT doesn’t contain the facts to answer the QUESTION return NONE\nUse simple terms so that the user can understand\nDOCUMENT:\nPractice Exercises 339 7.8 Summary A deadlocked state occurs when two or more processes are waiting indeﬁnitely for an event that can be caused only by one of the waiting processes. There arethree principal methods for dealing with deadlocks: •Use some protocol to prevent or avoid deadlocks, ensuring that the system will never enter a deadlocked state. •Allow the system to enter a deadlocked state, detect it, and then recover. •Ignore the problem altogether and pre tend that deadlocks never occur in the system. The third solution is the one used by most operating systems, including Linux and Windows. A deadlock can occur only if four necessary conditions hold simultaneously in the system: mutual exclusion, hold and wait, no preemption, and circularwait. To prevent deadlocks, we can ensure that at least one of the necessaryconditions never holds. A method for avoiding deadlocks, rather than preventing them, requires that the operating system have a priori information about how each processwill utilize system resources. The banker’s algorithm, for example, requiresa priori information about the maximum number of each resource class that each process may request. Using this information, we can deﬁne a deadlock- avoidance algorithm. If a system does not employ a protocol to ensure that deadlocks will never occur, then a detection-and-rec overy scheme may be employed. A deadlock- detection algorithm must be invoked to determine whether a deadlock has occurred. If a deadlock is detected, the system must recover either byterminating some of the deadlocked processes or by preempting resourcesfrom some of the deadlocked processes. Where preemption is used to deal with deadlocks, three issues must be addressed: selecting a victim, rollback, and starvation. In a system that selectsvictims for rollback primarily on the basis of cost factors, starvation may occur,and the selected process can never complete its designated task. Researchers have argued that none of the basic approaches alone is appro- priate for the entire spectrum of resource-allocation problems in operatingsystems. The basic approaches can be combined, however, allowing us to select an optimal approach for each class of resources in a system. Practice Exercises 7.1 List three examples of deadlocks that are not related to a computer- system environment. 7.2 Suppose that a system is in an unsafe state. Show that it is possible for the processes to complete their exec ution without entering a deadlocked state.7.4 Deadlock Prevention 323 In the absence of algorithms to detect and recover from deadlocks, we may arrive at a situation in which the system is in a deadlocked state yet has no way of recognizing what has happened. In this case, the undetected deadlock will cause the system’s performance to deteriorate, because resources are beingheld by processes that cannot run and because more and more processes, asthey make requests for resources, will enter a deadlocked state. Eventually, the system will stop functioning and will need to be restarted manually. Although this method may not seem to be a viable approach to the deadlock problem, it is nevertheless used in most operating systems, as mentionedearlier. Expense is one important consideration. Ignoring the possibility of deadlocks is cheaper than the other approaches. Since in many systems, deadlocks occur infrequently (say, onc e per year), the extra expense of the other methods may not seem worthwh ile. In addition, methods used to recover from other conditions may be put to use to recover from deadlock. In some circumstances, a system is in a frozen state but not in a deadlocked state. We see this situation, for example, with a real-time process running at thehighest priority (or any process running on a nonpreemptive scheduler) andnever returning control to the operating system. The system must have manual recovery methods for such conditions and may simply use those techniques for deadlock recovery. 7.4 Deadlock Prevention As we noted in Section 7.2.1, for a deadlock to occur, each of the four necessary conditions must hold. By ensuring that at least one of these conditions cannothold, we can prevent the occurrence of a deadlock. We elaborate on this approach by examining each of the four necessary conditions separately. 7.4.1 Mutual Exclusion The mutual exclusion condition must hold. That is, at least one resource must be nonsharable. Sharable resources, in contrast, do not require mutually exclusiveaccess and thus cannot be involved in a deadlock. Read-only ﬁles are a goodexample of a sharable resource. If several processes attempt to open a read-only ﬁle at the same time, they can be granted simultaneous access to the ﬁle. A process never needs to wait for a sharab le resource. In general, however, we cannot prevent deadlocks by denyin g the mutual-exclusion condition, because some resources are intrinsically nonsharable. For example, a mutex lock cannot be simultaneously shared by several processes. 7.4.2 Hold and Wait To ensure that the hold-and-wait condition never occurs in the system, we mustguarantee that, whenever a process requests a resource, it does not hold anyother resources. One protocol that we can use requires each process to request and be allocated all its resources before it begins execution. We can implement this provision by requiring that system calls requesting resources for a processprecede all other system calls.322 Chapter 7 Deadlocks However, there is no deadlock. Observe that process P4may release its instance of resource type R2. That resource can then be allocated to P3, breaking the cycle. In summary, if a resource-allocation graph does not have a cycle, then the system is notin a deadlocked state. If there is a cycle, then the system may or may not be in a deadlocked state. This observation is important when we dealwith the deadlock problem. 7.3 Methods for Handling Deadlocks Generally speaking, we can deal with the deadlock problem in one of three ways: •We can use a protocol to prevent or avoid deadlocks, ensuring that thesystem will never enter a deadlocked state. •We can allow the system to enter a deadlocked state, detect it, and recover. •We can ignore the problem altogeth er and pretend that deadlocks never occur in the system. The third solution is the one used by most operating systems, including Linux and Windows. It is then up to the application developer to write programs that handle deadlocks. Next, we elaborate brieﬂy on each of the three methods for handling deadlocks. Then, in Sections 7.4 through 7.7, we present detailed algorithms. Before proceeding, we should mention that some researchers have argued that none of the basic approaches alone is appropriate for the entire spectrum ofresource-allocation problems in operating systems. The basic approaches canbe combined, however, allowing us to select an optimal approach for each class of resources in a system. To ensure that deadlocks never occur, the system can use either a deadlock- prevention or a deadlock-avoidance scheme. Deadlock prevention provides a set of methods to ensure that at least one of the necessary conditions (Section 7.2.1) cannot hold. These methods prevent deadlocks by constraining how requests for resources can be made. We discuss these methods in Section 7.4. Deadlock avoidance requires that the operating system be given additional information in advance concerning which resources a process will request and use during its lifetime. With this additional knowledge, the operating system can decide for each request whether or not the process should wait.To decide whether the current request can be satisﬁed or must be delayed, thesystem must consider the resources currently available, the resources currently allocated to each process, and the future requests and releases of each process. We discuss these schemes in Section 7.5. If a system does not employ either a deadlock-prevention or a deadlock- avoidance algorithm, then a deadlock situation may arise. In this environment, the system can provide an algorithm that examines the state of the system to determine whether a deadlock has occurr ed and an algorithm to recover from the deadlock (if a deadlock has indeed occurred). We discuss these issues inSection 7.6 and Section 7.7.\nQUESTION:\nHow does the operating system handle deadlocks?\nANSWER:\nThe operating system handles deadlock by using one of 3 methods:\n1. Prevent deadlock: The operating system uses protocols to ensure the system never enters a dead locked state.\n2. Detect and recover: The system detects deadlock and recovers by terminating some processes or preempt resources from deadlocked process.\n3. Ignore the problem: The third method is used by many operating systems including Linux, and Windows, where the application developers are responsible for handling the dead locks.\nThe basic approaches for handling dealdocks can be combine, allowing the operating systems to select the optimal approach foe each class or resources in the sytem.\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"qr,cf,gram = evaluation_metrics(query,context,answer)\nprint(f\"Query relevance Score: {qr}\\n\"\n     f\"Context Fidelity Score: {cf}\\n\"\n     f\"Error Percentage: {gram:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T18:43:12.073905Z","iopub.execute_input":"2024-12-24T18:43:12.074294Z","iopub.status.idle":"2024-12-24T18:43:29.406399Z","shell.execute_reply.started":"2024-12-24T18:43:12.074250Z","shell.execute_reply":"2024-12-24T18:43:29.405553Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca8b503975ad4824859b504d01f101f5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a31232762545418b9b1c81af29cb34f6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"877282a01df5444cbeb06eee149a6e52"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0afd5ce88da544799ec2640f0f837344"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"546c13f8e8034d47bd493e22ada069c4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"972445dd67014eaaa7fc109a7227058d"}},"metadata":{}},{"name":"stdout","text":"Query relevance Score: 99.99743700027466\nContext Fidelity Score: 77.02907919883728\nError Percentage: 4.85%\n","output_type":"stream"}],"execution_count":35},{"cell_type":"markdown","source":"# DS - Q1","metadata":{}},{"cell_type":"code","source":"query = \"What are the two key technological developments that led to the rise of distributed systems?\"\nresults = query_faiss_index(query, top_k = 3)\npara = \"\"\nfor result in results:\n    para = para + result\n#context = extract_relevant_sentences(query, para, similarity_threshold=0.4)\ncontext = para\ncontext = clean_context(context)\ninsight,answer= generate_insight_simple(query, context)\n\nprint(\"Generated Insight:\")\nprint(insight)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T18:50:45.317864Z","iopub.execute_input":"2024-12-24T18:50:45.318179Z","iopub.status.idle":"2024-12-24T18:51:01.981998Z","shell.execute_reply.started":"2024-12-24T18:50:45.318153Z","shell.execute_reply":"2024-12-24T18:51:01.981103Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b7e1563e11d4abaadec8544dd689314"}},"metadata":{}},{"name":"stdout","text":"Generated Insight:\n\nINSTRUCTIONS:\nAnswer the users QUESTION concisely using the DOCUMENT text above.\nIf the DOCUMENT doesn’t contain the facts to answer the QUESTION return NONE\nUse simple terms so that the user can understand\nDOCUMENT:\n1.1. FROM NETWORKED SYSTEMS TO DISTRIBUTED SYSTEMS 3 The size of a networked computer system may vary from a handful of devices, to millions of computers. The interconnection network may be wired, wireless, or a combination of both. Moreover, these systems are often highly dynamic, in the sense that computers can join and leave, with the topology and performance of the underlying network almost continuously changing. It is difficult to think of computer systems that are notnetworked. And as a matter of fact, most networked computer systems can be accessed from any place in the world because they are hooked up to the Internet. Studying to understand these systems can easily become exceedingly complex. In this chapter, we start with shedding some light on what needs to be understood to build up the bigger picture without getting lost. 1.1 From networked systems to distributed systems Before we dive into various aspects of distributed systems, let us first consider what distribution, or decentralization, actually entails. 1.1.1 Distributed versus decentralized systems When considering various sources, there are quite a few opinions on dis- tributed versus decentralized systems. Often, the distinction is illustrated by three different organizations of networked computer systems, as shown in Figure 1.1, where each node represents a computer system and an edge a communication link between two nodes. To what extent such distinctions are useful remains to be seen, especially when discussions open on the pros and cons of each organization. For example, it is often stated that centralized organizations do not scale well. Likewise, distributed organizations are said to be more robust against failures. As we shall see, none of these claims are generally true. (a) (b) (c) Figure 1.1: The organization of a (a) centralized, (b) decentralized, and (c) distributed system, according to various popular sources. We take a different approach, as figures such as these are really not that meaningful. downloaded by UMAG @AM.AMRITA.EDU DS 4.024 CHAPTER 1. INTRODUCTION We take a different approach. If we think of a networked computer system as a collection of computers connected in a network, we can ask ourselves how these computers even became connected to each other in the first place. There are roughly two views that one can take. The first, integrative view , is that there was a need to connect existing (networked) computer systems to each other. Typically, this happens when services running on a system need to be made available to users and applica- tions that were not thought of before. This may happen, for example, when integrating financial services with project management services, as is often the case within a single organization. In the scientific-research domain, we have seen efforts to connect a myriad of often expensive resources (special-purpose computers, supercomputers, very large database systems, etc.) into what came to be known as a grid computer. The second, expansive view is that an existing system required an exten- sion through additional computers. This view is the one most often related to the field of distributed systems. It entails expanding a system with computers to hold resources close to where those resources are needed. An expansion may also be driven by the need to improve dependability: if one computer fails, then there are others who can take over. An important type of expansion is when a service needs to be made available for remote users and applications, for example, by offering a Web interface or a smartphone application. This last example also shows that the distinction between an integrative and an expansive view is not a clear-cut. In both cases, we see that the networked system runs services, where each service is implemented as a collection of processes and resources spread across multiple computers. The two views lead to a natural distinction between two types of networked computer systems: •Adecentralized system is a networked computer system in which pro- cesses and resources are necessarily spread across multiple computers. •Adistributed system is a networked computer system in which pro- cesses and resources are sufficiently spread across multiple computers. Before we discuss why this distinction is important, let us look at a few examples of each type of system. Decentralized systems are mainly related to the integrative view of net- worked computer systems. They come to being because we want to con- nect systems, yet may be hindered by administrative boundaries. For exam- ple, many applications in the artificial-intelligence domain require massive amounts of data for building reliable predictive models. Normally, data is brought to the high-performance computers that literally train models before they can be used. But when data needs to stay within the perimeter of an organization (and there can be many reasons why this is necessary), we need to bring the training to the data. The result is known as federated learning , . SUMMARY 53 Nevertheless, by following several design principles, distributed systems can be developed that strongly adhere to the goals we set out in this chapter. Distributed systems differ from traditional software because components are dispersed across a network. Not taking this dispersion into account during design time is what makes so many systems needlessly complex and results in flaws that need to be patched later on. Peter Deutsch, at the time working at Sun Microsystems, formulated these flaws as the following false assumptions that many make when developing a distributed application for the first time: • The network is reliable • The network is secure • The network is homogeneous • The topology does not change • Latency is zero • Bandwidth is infinite • Transport cost is zero • There is one administrator Note how these assumptions relate to properties that are unique to dis- tributed systems: reliability, security, heterogeneity, and topology of the network; latency and bandwidth; transport costs; and finally administrative domains. When developing nondistributed applications, most of these issues will most likely not show up. Most of the principles we discuss in this book relate immediately to these assumptions. In all cases, we will be discussing solutions to problems that are caused by the fact that one or more assumptions are false. For example, reliable networks simply do not exist and lead to the impossibility of achieving failure transparency. We devote an entire chapter to deal with the fact that networked communication is inherently insecure. We have already argued that distributed systems need to be open and take heterogeneity into account. Likewise, when discussing replication for solving scalability problems, we are essentially tackling latency and bandwidth problems. We will also touch upon management issues at various points throughout this book. 1.5 Summary A distributed system is a collection of networked computer systems in which processes and resources are spread across different computers. We make a distinction between sufficiently and necessarily spread, where the latter relates to decentralized systems. This distinction is important to make, as spreading processes and resources cannot be considered to be a goal by itself. Instead, downloaded by UMAG @AM.AMRITA.EDU DS 4.02\nQUESTION:\nWhat are the two key technological developments that led to the rise of distributed systems?\nANSWER:\nThe two key technical developments leading to the emergence of distributed computing are the widespread adoption of the internet and the development of network protocols that enable communication between different devices and systems. These advancements have made it possible for computers to connect and communicate with one another, regardless of their location, creating a global network of interconnected computers that can share resources and exchange data.\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"qr,cf,gram = evaluation_metrics(query,context,answer)\nprint(f\"Query relevance Score: {qr}\\n\"\n     f\"Context Fidelity Score: {cf}\\n\"\n     f\"Error Percentage: {gram:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T18:51:21.123794Z","iopub.execute_input":"2024-12-24T18:51:21.124705Z","iopub.status.idle":"2024-12-24T18:51:40.958858Z","shell.execute_reply.started":"2024-12-24T18:51:21.124655Z","shell.execute_reply":"2024-12-24T18:51:40.957877Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b2eabbe9f0d7476484301b4a02d4f73c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e09d4d658c2c4448adcd3ebb2c25b95e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24d923e0a13a4020b90614da43fff5fe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2898a35cdef744e5bb0d46b690b1be93"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"820c9e9541a847e0836c91e4aefb426d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc74d95797fe441f9c73462401911aa3"}},"metadata":{}},{"name":"stdout","text":"Query relevance Score: 99.9895453453064\nContext Fidelity Score: 63.916659355163574\nError Percentage: 0.00%\n","output_type":"stream"}],"execution_count":44},{"cell_type":"markdown","source":"# DS-Q2","metadata":{}},{"cell_type":"code","source":"query = \"Explain the difference between centralized, decentralized, and distributed systems.\"\nresults = query_faiss_index(query, top_k = 3)\npara = \"\"\nfor result in results:\n    para = para + result\n#context = extract_relevant_sentences(query, para, similarity_threshold=0.4)\ncontext = para\ncontext = clean_context(context)\ninsight,answer= generate_insight_simple(query, context)\n\nprint(\"Generated Insight:\")\nprint(insight)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T18:52:48.321797Z","iopub.execute_input":"2024-12-24T18:52:48.322132Z","iopub.status.idle":"2024-12-24T18:53:18.254145Z","shell.execute_reply.started":"2024-12-24T18:52:48.322102Z","shell.execute_reply":"2024-12-24T18:53:18.253192Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0bb4e6d440d4bb8b47549fa54f85704"}},"metadata":{}},{"name":"stdout","text":"Generated Insight:\n\nINSTRUCTIONS:\nAnswer the users QUESTION concisely using the DOCUMENT text above.\nIf the DOCUMENT doesn’t contain the facts to answer the QUESTION return NONE\nUse simple terms so that the user can understand\nDOCUMENT:\n1.1. FROM NETWORKED SYSTEMS TO DISTRIBUTED SYSTEMS 3 The size of a networked computer system may vary from a handful of devices, to millions of computers. The interconnection network may be wired, wireless, or a combination of both. Moreover, these systems are often highly dynamic, in the sense that computers can join and leave, with the topology and performance of the underlying network almost continuously changing. It is difficult to think of computer systems that are notnetworked. And as a matter of fact, most networked computer systems can be accessed from any place in the world because they are hooked up to the Internet. Studying to understand these systems can easily become exceedingly complex. In this chapter, we start with shedding some light on what needs to be understood to build up the bigger picture without getting lost. 1.1 From networked systems to distributed systems Before we dive into various aspects of distributed systems, let us first consider what distribution, or decentralization, actually entails. 1.1.1 Distributed versus decentralized systems When considering various sources, there are quite a few opinions on dis- tributed versus decentralized systems. Often, the distinction is illustrated by three different organizations of networked computer systems, as shown in Figure 1.1, where each node represents a computer system and an edge a communication link between two nodes. To what extent such distinctions are useful remains to be seen, especially when discussions open on the pros and cons of each organization. For example, it is often stated that centralized organizations do not scale well. Likewise, distributed organizations are said to be more robust against failures. As we shall see, none of these claims are generally true. (a) (b) (c) Figure 1.1: The organization of a (a) centralized, (b) decentralized, and (c) distributed system, according to various popular sources. We take a different approach, as figures such as these are really not that meaningful. downloaded by UMAG @AM.AMRITA.EDU DS 4.021.1. FROM NETWORKED SYSTEMS TO DISTRIBUTED SYSTEMS 5 and is implemented by a decentralized system, where the need for spreading processes and resources is dictated by administrative policies. Another example of a decentralized system is that of distributed ledger , also known as a blockchain . In this case, we need to deal with the situation that participating parties do not trust each other enough to set up simple schemes for collaboration. Instead, what they do is essentially make transac- tions among each other fully public (and verifiable) by an extend-only ledger that keeps records of those transactions. The ledger itself is fully spread across the participants, and the participants are the ones who validate transactions (of others) before admitting them to the ledger. The result is a decentralized system in which processes and resources are, indeed, necessarily spread across multiple computers, in this case due to lack of trust. As a last example of a decentralized system, consider systems that are naturally geographically dispersed. This occurs typically with systems in which an actual location needs to be monitored, for example, in the case of a power plant, a building, a specific natural environment, and so on. The system, controlling the monitors and where decisions are made, may easily be placed somewhere else than the location being monitored. One obvious example is monitoring and controlling of satellites, but also more mundane situations as monitoring and controlling traffic, trains, etc. In these examples, the necessity for spreading processes and resources comes from a spatial argument. As we mentioned, distributed systems are mainly related to the expansive view of networked computer systems. A well-known example is making use of e-mail services, such as Google Mail. What often happens is that a user logs into the system through a Web interface to read and send mails. More often, however, is that users configure their personal computer (such as a laptop) to make use of a specific mail client. To that end, they need to configure a few settings, such as the incoming and outgoing server. In the case of Google Mail, these are imap .gmail .com andsmtp .gmail .com, respectively. Logically, it seems as if these two servers will handle all your mail. However, with an estimate of close to 2 billion users as of 2022, it is unlikely that only two computers can handle all their e-mails (which was estimated to be more than 300 billion per year, that is, some 10,000 mails per second ). Behind the scenes, of course, the entire Google Mail service has been implemented and spread across many computers, jointly forming a distributed system. That system has been set up to make sure that so many users can process their mails (i.e., ensures scalability), but also that the risk of losing mail because of failures, is minimal (i.e., the system ensures fault tolerance). To the user, however, the image of just two servers is kept up (i.e., the distribution itself is highly transparent to the user). The distributed system implementing an e-mail service, such as Google Mail, typically expands (or shrinks) as dictated by dependability requirements, in turn, dependent on the number of its users. downloaded by UMAG @AM.AMRITA.EDU DS 4.0274 CHAPTER 2. ARCHITECTURES system. This organization is shown in Figure 2.13, leading to what is known asmiddleware [Bernstein, 1996]. Figure 2.13 shows four networked computers and three applications, of which application Bis distributed across computers 2 and 3. Each application is offered the same interface. The distributed system provides the means for components of a single distributed application to communicate with each other, but also to let different applications communicate. At the same time, it hides, as best and reasonably as possible, the differences in hardware and operating systems from each application. In a sense, middleware is the same to a distributed system as what an operating system is to a computer: a manager of resources offering its ap- plications to efficiently share and deploy those resources across a network. Next to resource management, it offers services that can also be found in most operating systems, including: • Facilities for interapplication communication. • Security services. • Accounting services. • Masking of and recovery from failures. The main difference with their operating-system equivalents, is that middle- ware services are offered in a networked environment. Note also that most services are useful to many applications. In this sense, middleware can also be viewed as a container of commonly used components and functions that now no longer have to be implemented by applications separately. Note 2.4 (Historical note: The term middleware) Although the term middleware became popular in the mid 1990s, it was most likely mentioned for the first time in a report on a NATO software engineering conference, edited by Peter Naur and Brian Randell in October 1968 [Naur and Randell, 1968]. Indeed, middleware was placed precisely between applications and service routines (the equivalent of operating systems). 2.2.1 Middleware organization Let us now zoom into the actual organization of middleware. There are two important types of design patterns that are often applied to the organization of middleware: wrappers and interceptors. Each targets different problems, yet addresses the same goal for middleware: achieving openness (as we discussed in Section 1.2.3). DS 4.02 downloaded by UMAG @AM.AMRITA.EDU\nQUESTION:\nExplain the difference between centralized, decentralized, and distributed systems.\nANSWER:\nCentralized and decentralize systems are two different types of network architectures, with distinct characteristics.\n\nA centralized system has a single point of control or management, where all the resources and processes are concentrated and controlled from a central location. In contrast, a decentrilized system distributes resources and control across multiple nodes or locations, with no single point or control.\nA distributed system is a combination or both centralized and de-centralized systems, where resources and process are distributed across multiple locations, but still managed and controlled centrally.\nIn summary, centralized systems have a single controlling point, decentrilied systems have no single controllling point, and distribute systems have both central control and distributed resources.\nPlease let me know if you need further clarification or details.\n","output_type":"stream"}],"execution_count":45},{"cell_type":"code","source":"qr,cf,gram = evaluation_metrics(query,context,answer)\nprint(f\"Query relevance Score: {qr}\\n\"\n     f\"Context Fidelity Score: {cf}\\n\"\n     f\"Error Percentage: {gram:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T18:53:21.550189Z","iopub.execute_input":"2024-12-24T18:53:21.551080Z","iopub.status.idle":"2024-12-24T18:53:44.042019Z","shell.execute_reply.started":"2024-12-24T18:53:21.551045Z","shell.execute_reply":"2024-12-24T18:53:44.041122Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f61d521b9084d8fa2849cb77453f4e9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d35cdbc211b4e6eb3e77ef2220b21df"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e4eef216fd8641fc9b4d8aa2512e7069"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"256cf8b6a8d345edad903de51de048e4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"45a5a5e24a5548af9b5dea63d8d55a0f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"198b73871d2444d592f140be24dbc0b8"}},"metadata":{}},{"name":"stdout","text":"Query relevance Score: 99.99672174453735\nContext Fidelity Score: 71.96626663208008\nError Percentage: 3.25%\n","output_type":"stream"}],"execution_count":46},{"cell_type":"markdown","source":"# DS-Q3","metadata":{}},{"cell_type":"code","source":"query = \"What is the role of a middleware layer in achieving distribution transparency?\"\nresults = query_faiss_index(query, top_k = 3)\npara = \"\"\nfor result in results:\n    para = para + result\n#context = extract_relevant_sentences(query, para, similarity_threshold=0.4)\ncontext = para\ncontext = clean_context(context)\ninsight,answer= generate_insight_simple(query, context)\n\nprint(\"Generated Insight:\")\nprint(insight)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T18:54:17.992004Z","iopub.execute_input":"2024-12-24T18:54:17.992306Z","iopub.status.idle":"2024-12-24T18:54:37.823430Z","shell.execute_reply.started":"2024-12-24T18:54:17.992280Z","shell.execute_reply":"2024-12-24T18:54:37.822438Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d129ae59860a4f7da5ce26e59e7a089d"}},"metadata":{}},{"name":"stdout","text":"Generated Insight:\n\nINSTRUCTIONS:\nAnswer the users QUESTION concisely using the DOCUMENT text above.\nIf the DOCUMENT doesn’t contain the facts to answer the QUESTION return NONE\nUse simple terms so that the user can understand\nDOCUMENT:\n1.2. DESIGN GOALS 11 special shared folder that is maintained by a third party somewhere on the In- ternet. Using special software, the shared folder is barely distinguishable from other folders on a user’s computer. In effect, these services replace the use of a shared directory on a local distributed file system, making data available to users independent of the organization they belong to, and independent of where they are. The service is offered for different operating systems. Where exactly data are stored is completely hidden from the end user. 1.2.2 Distribution transparency An important goal of a distributed system is to hide the fact that its processes and resources are physically distributed across multiple computers, possibly separated by large distances. In other words, it tries to make the distribution of processes and resources transparent , that is, invisible, to end users and applications. As we shall discuss more extensively in Chapter 2, achieving distribution transparency is realized through what is known as middleware , sketched in Figure 1.2 (see Gazis and Katsiri [2022] for a first introduction). In essence, what applications get to see is the same interface everywhere, whereas behind that interface, where and how processes and resources are and how they are accessed is kept transparent. There are different types of transparency, which we discuss next. Types of distribution transparency The concept of transparency can be applied to several aspects of a distributed system, of which the most important ones are listed in Figure 1.3. We use the term object to mean either a process or a resource. Access transparency deals with hiding differences in data representation and the way that objects can be accessed. At a basic level, we want to hide differences in machine architectures, but more important is that we reach Figure 1.2: Realizing distribution transparency through a middleware layer. downloaded by UMAG @AM.AMRITA.EDU DS 4.0256 CHAPTER 2. ARCHITECTURES Distributed systems are often complex pieces of software, of which the components are by definition dispersed across multiple machines. To master their complexity, it is crucial that these systems be properly organized. There are different ways on how to view the organization of a distributed system, but an obvious one is to make a distinction between, on the one hand, the logical organization of the collection of software components, and on the other hand the actual physical realization. The organization of distributed systems is mostly about the software components that constitute the system. These software architectures tell us how the various software components are to be organized and how they should interact. In this chapter, we will first pay attention to some commonly applied architectural styles toward organizing (distributed) computer systems. An important goal of distributed systems is to separate applications from underlying platforms by providing a so-called middleware layer. Adopting such a layer is an important architectural decision, and its main purpose is to provide distribution transparency. However, trade-offs need to be made to achieve transparency, which has led to various techniques to adjust the middleware to the needs of the applications that make use of it. We discuss some of the more commonly applied techniques, as they affect the organization of the middleware itself. The actual realization of a distributed system requires that we instantiate and place software components on real machines. There are many choices that can be made in doing so. The final instantiation of a software architecture is also referred to as a system architecture . In this chapter, we will look into traditional centralized architectures in which a single server implements most of the software components (and thus functionality), while remote clients can access that server using simple communication means. In addition, we consider decentralized peer-to-peer architectures in which all nodes more or less play equal roles. Many real-world distributed systems are often organized in a hybrid fashion, combining elements from centralized and decentralized architectures. We discuss several examples that illustrate the complexity of many real-world distributed systems. 2.1 Architectural styles We start our discussion on architectures by first considering the logical or- ganization of a distributed system into software components, also referred to as its software architecture [Bass et al., 2021; Richards and Ford, 2020]. Research on software architectures has matured considerably, and it is now commonly accepted that designing or adopting an architecture is crucial for the successful development of large software systems. For our discussion, the notion of an architectural style is important. Such a style is formulated in terms of components, the way that components are . SERVERS 149 changes location. In this case, the client’s middleware can hide the server’s current network location from the user, and also transparently rebind to the server if necessary. At worst, the client’s application may notice a temporary loss of performance. Similarly, many distributed systems implement replication transparency employing client-side solutions. For example, imagine a distributed system with replicated servers, Such replication can be achieved by forwarding a request to each replica, as shown in Figure 3.18. Client-side software can transparently collect all responses and pass a single response to the client application. Figure 3.18: Transparent replication of a server using a client-side solution. Regarding failure transparency , masking communication failures with a server is typically done through client middleware. For example, client middleware can be configured to repeatedly attempt to connect to a server, or perhaps try another server after several attempts. There are even situations in which the client middleware returns data it had cached during a previous session, as is sometimes done by Web browsers that fail to connect to a server. Finally, concurrency transparency can be handled through special inter- mediate servers, notably transaction monitors, and requires less support from client software. 3.4 Servers Let us now take a closer look at the organization of servers. In the following pages, we first concentrate on a number of general design issues for servers, followed by a discussion on server clusters. 3.4.1 General design issues A server is a process implementing a specific service on behalf of a collection of clients. In essence, each server is organized in the same way: it waits for an downloaded by UMAG @AM.AMRITA.EDU DS 4.02\nQUESTION:\nWhat is the role of a middleware layer in achieving distribution transparency?\nANSWER:\nA middlewarelayer plays a crucial role in achievin distribution transpaency by providing an interface that hides the underlying complexities of a distribu ed system. It acts as an intermediary between the application and the underlying platform, allowing the application to access resources and services without being aware of their physical location or the underlying hardware and software architecture. By hiding these complexities, the middlewa re layer enables applications to be developed and deployed independent of specific platforms or infrastructures, making it easier to manage and maintain distributed systems\n","output_type":"stream"}],"execution_count":47},{"cell_type":"code","source":"qr,cf,gram = evaluation_metrics(query,context,answer)\nprint(f\"Query relevance Score: {qr}\\n\"\n     f\"Context Fidelity Score: {cf}\\n\"\n     f\"Error Percentage: {gram:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T18:55:00.521892Z","iopub.execute_input":"2024-12-24T18:55:00.522537Z","iopub.status.idle":"2024-12-24T18:55:26.046577Z","shell.execute_reply.started":"2024-12-24T18:55:00.522484Z","shell.execute_reply":"2024-12-24T18:55:26.044761Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"30f8391cd4134c97af6f12c5619bc1c1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c9af19cde7c4605b86e0fad8c78ad5d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"333d182ca1b94f76934a25d49d85ea84"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e3f2438af8d149e6a1b3b0f38174719d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"31ee02cae411417cb47d9dcd21646940"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"46b633532d1d4f3a96ca9d2855214cdc"}},"metadata":{}},{"name":"stdout","text":"Query relevance Score: 99.91674423217773\nContext Fidelity Score: 61.2017035484314\nError Percentage: 5.68%\n","output_type":"stream"}],"execution_count":48},{"cell_type":"markdown","source":"# DS-Q4","metadata":{}},{"cell_type":"code","source":"query = \"Define the term 'scalability' in the context of distributed systems.\"\nresults = query_faiss_index(query, top_k = 3)\npara = \"\"\nfor result in results:\n    para = para + result\n#context = extract_relevant_sentences(query, para, similarity_threshold=0.4)\ncontext = para\ncontext = clean_context(context)\ninsight,answer= generate_insight_simple(query, context)\n\nprint(\"Generated Insight:\")\nprint(insight)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T18:56:15.743137Z","iopub.execute_input":"2024-12-24T18:56:15.743548Z","iopub.status.idle":"2024-12-24T18:56:38.817294Z","shell.execute_reply.started":"2024-12-24T18:56:15.743511Z","shell.execute_reply":"2024-12-24T18:56:38.816318Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5dace37c3e2241b590ef006a358317a8"}},"metadata":{}},{"name":"stdout","text":"Generated Insight:\n\nINSTRUCTIONS:\nAnswer the users QUESTION concisely using the DOCUMENT text above.\nIf the DOCUMENT doesn’t contain the facts to answer the QUESTION return NONE\nUse simple terms so that the user can understand\nDOCUMENT:\n24 CHAPTER 1. INTRODUCTION 1.2.6 Scalability For many of us, worldwide connectivity through the Internet is as common as being able to send a package to anyone anywhere around the world. Moreover, where until recently, we were used to having relatively powerful desktop computers for office applications and storage, we are now witnessing that such applications and services are being placed in what has been coined “the cloud,” in turn leading to an increase of much smaller networked devices such as tablet computers or even cloud-only laptops such as Google’s Chromebook. With this in mind, scalability has become one of the most important design goals for developers of distributed systems. Scalability dimensions Scalability of a system can be measured along at least three different dimen- sions (see [Neuman, 1994]): Size scalability: A system can be scalable regarding its size, meaning that we can easily add more users and resources to the system without any noticeable loss of performance. Geographical scalability: A geographically scalable system is one in which the users and resources may lie far apart, but the fact that communication delays may be significant is hardly noticed. Administrative scalability: An administratively scalable system is one that can still be easily managed even if it spans many independent adminis- trative organizations. Let us take a closer look at each of these three scalability dimensions. Size scalability When a system needs to scale, very different types of prob- lems need to be solved. Let us first consider scaling regarding size. If more users or resources need to be supported, we are often confronted with the limitations of centralized services, although often for very different reasons. For example, many services are centralized in the sense that they are imple- mented by a single server running on a specific machine in the distributed system. In a more modern setting, we may have a group of collaborating servers co-located on a cluster of tightly coupled machines physically placed at the same location. The problem with this scheme is obvious: the server, or group of servers, can simply become a bottleneck when it needs to process an increasing number of requests. To illustrate how this can happen, let us assume that a service is implemented on a single machine. In that case, there are essentially three root causes for becoming a bottleneck: • The computational capacity, limited by the CPUs • The storage capacity, including the I/O transfer rate A simple classification of distributed systems We have discussed distributed versus decentralized systems, yet it is also use- ful to classify distributed systems according to what they are being developed and used for. We make a distinction between systems that are developed for (high performance) computing, for general information processing, and those that are developed for pervasive computing, i.e., for the “Internet of Things.” As with many classifications, the boundaries between these three types are not strict and combinations can easily be thought of. 1.3.1 High-performance distributed computing An important class of distributed systems is the one used for high-performance computing tasks. Roughly speaking, one can make a distinction between two subgroups. In cluster computing the underlying hardware consists of a collection of similar compute nodes, interconnected by a high-speed network, often alongside a more common local-area network for controlling the nodes. In addition, each node generally runs the same operating system. The situation becomes very different in the case of grid computing . This subgroup consists as decentralized systems that are often constructed as a federation of computer systems, where each system may fall under a different administrative domain, and may be very different when it comes to hardware, software, and deployed network technology. . SUMMARY 53 Nevertheless, by following several design principles, distributed systems can be developed that strongly adhere to the goals we set out in this chapter. Distributed systems differ from traditional software because components are dispersed across a network. Not taking this dispersion into account during design time is what makes so many systems needlessly complex and results in flaws that need to be patched later on. Peter Deutsch, at the time working at Sun Microsystems, formulated these flaws as the following false assumptions that many make when developing a distributed application for the first time: • The network is reliable • The network is secure • The network is homogeneous • The topology does not change • Latency is zero • Bandwidth is infinite • Transport cost is zero • There is one administrator Note how these assumptions relate to properties that are unique to dis- tributed systems: reliability, security, heterogeneity, and topology of the network; latency and bandwidth; transport costs; and finally administrative domains. When developing nondistributed applications, most of these issues will most likely not show up. Most of the principles we discuss in this book relate immediately to these assumptions. In all cases, we will be discussing solutions to problems that are caused by the fact that one or more assumptions are false. For example, reliable networks simply do not exist and lead to the impossibility of achieving failure transparency. We devote an entire chapter to deal with the fact that networked communication is inherently insecure. We have already argued that distributed systems need to be open and take heterogeneity into account. Likewise, when discussing replication for solving scalability problems, we are essentially tackling latency and bandwidth problems. We will also touch upon management issues at various points throughout this book. 1.5 Summary A distributed system is a collection of networked computer systems in which processes and resources are spread across different computers. We make a distinction between sufficiently and necessarily spread, where the latter relates to decentralized systems. This distinction is important to make, as spreading processes and resources cannot be considered to be a goal by itself. Instead, downloaded by UMAG @AM.AMRITA.EDU DS 4.02\nQUESTION:\nDefine the term 'scalability' in the context of distributed systems.\nANSWER:\nIn the context distributed systems, scalabilty refers to the ability of a sytem to handle increasing amounts of users, data, or requests without a significant decrease in performance. It can be measure along three dimensions: size scalability, geographical scalabiltiy, and administrative scalability. Size sclabilty is the ability to add more resources or users without bottlnecking, geograhical scalability is the system's ability to handle users and resouces that are far apart but with minimal noticeable delays, and adminstrative scalabilit is the abilit to manage the system effectively even if its spans multiple organizations.\n","output_type":"stream"}],"execution_count":49},{"cell_type":"code","source":"qr,cf,gram = evaluation_metrics(query,context,answer)\nprint(f\"Query relevance Score: {qr}\\n\"\n     f\"Context Fidelity Score: {cf}\\n\"\n     f\"Error Percentage: {gram:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T18:57:13.424216Z","iopub.execute_input":"2024-12-24T18:57:13.424634Z","iopub.status.idle":"2024-12-24T18:57:41.375891Z","shell.execute_reply.started":"2024-12-24T18:57:13.424590Z","shell.execute_reply":"2024-12-24T18:57:41.373893Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f26ee7d2728f478b985a07df71cd5fab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6627261d33d643ba90bd4fc9be575874"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8607d2511bc04f21851eec08515af098"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9aee7548d8b2438b9b8074c1f16c0517"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fabae34741444338b416b7abfd130a31"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1320a9533314a08829b9503cca1097e"}},"metadata":{}},{"name":"stdout","text":"Query relevance Score: 99.96851682662964\nContext Fidelity Score: 76.64677500724792\nError Percentage: 11.96%\n","output_type":"stream"}],"execution_count":50},{"cell_type":"markdown","source":"# DS-Q5","metadata":{}},{"cell_type":"code","source":"query = \"What is replication in distributed systems, and why is it used?\"\nresults = query_faiss_index(query, top_k = 3)\npara = \"\"\nfor result in results:\n    para = para + result\n#context = extract_relevant_sentences(query, para, similarity_threshold=0.4)\ncontext = para\ncontext = clean_context(context)\ninsight,answer= generate_insight_simple(query, context)\n\nprint(\"Generated Insight:\")\nprint(insight)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T18:58:21.493254Z","iopub.execute_input":"2024-12-24T18:58:21.493656Z","iopub.status.idle":"2024-12-24T18:59:08.215415Z","shell.execute_reply.started":"2024-12-24T18:58:21.493621Z","shell.execute_reply":"2024-12-24T18:59:08.214475Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"393813decce64e63a8d033c3e9ca4fe2"}},"metadata":{}},{"name":"stdout","text":"Generated Insight:\n\nINSTRUCTIONS:\nAnswer the users QUESTION concisely using the DOCUMENT text above.\nIf the DOCUMENT doesn’t contain the facts to answer the QUESTION return NONE\nUse simple terms so that the user can understand\nDOCUMENT:\n7.1. INTRODUCTION 393 7.1.1 Reasons for replication There are two primary reasons for replicating data. First, data are replicated to increase the reliability of a system. If a file system has been replicated, it may be possible to continue working after one replica crashes by simply switching to one of the other replicas. Also, by maintaining multiple copies, it becomes possible to provide better protection against corrupted data. For example, imagine there are three copies of a file, and every read and write operation is performed on each copy. We can safeguard ourselves against a single, failing write operation, by considering the value that is returned by at least two copies as being the correct one. The other reason for replicating data is performance. Replication for performance is important when a distributed system needs to scale in terms of size or in terms of the geographical area it covers. Scaling regarding size occurs, for example, when an increasing number of processes needs to access data that are managed by a single server. In that case, performance can be improved by replicating the server and subsequently dividing the workload among the processes accessing the data. Scaling regarding a geographical area may also require replication. The basic idea is that by placing a copy of data in proximity of the process using them, the time to access the data decreases. As a consequence, the performance as perceived by that process increases. This example also illustrates that the benefits of replication for performance may be hard to evaluate. Although a client process may perceive better performance, it may also be the case that more network bandwidth is now consumed keeping all replicas up to date. If replication helps to improve reliability and performance, who could be against it? Unfortunately, there is a price to be paid when data are replicated. The problem with replication is that having multiple copies may lead to consistency problems. Whenever a copy is modified, that copy becomes different from the rest. Consequently, modifications have to be carried out on all copies to ensure consistency. Exactly when and how those modifications need to be carried out determines the price of replication. To understand the problem, consider improving access times to Web pages. If no special measures are taken, fetching a page from a remote Web server may sometimes even take seconds to complete. To improve performance, Web browsers often locally store a copy of a previously fetched Web page (i.e., they cache a Web page). If a user requires that page again, the browser automatically returns the local copy. The access time as perceived by the user, is excellent. However, if the user always wants to have the latest version of a page, she may be in for bad luck. The problem is that if the page has been modified in the meantime, modifications will not have been propagated to cached copies, making those copies out-of-date. One solution to the problem of returning a stale copy to the user is to forbid the browser to keep local copies in the first place, effectively letting the downloaded by UMAG @AM.AMRITA.EDU DS 4.02426 CHAPTER 7. CONSISTENCY AND REPLICATION Autonomous Systems , that is, an organization in charge of a separate network within the Internet). Replica-server placement then also involves monetary costs that need to be negotiated with those organizations. Likewise, placement decisions can be based on the connectivity of clients to a specific autonomous system, along with the costs in terms of QoS parameters or monetary costs. Further details can be found in [Sahoo et al., 2017]. 7.4.2 Content replication and placement When it comes to content replication and placement, three different types of replicas can be distinguished, logically organized as shown in Figure 7.24. Permanent replicas Server-initiated replicas Client-initiated replicas ClientsClient-initiated replicationServer-initiated replication Figure 7.24: The logical organization of different kinds of copies of a data store into three concentric rings. Permanent replicas Permanent replicas can be considered as the initial set of replicas that con- stitute a distributed data store. Often, the number of permanent replicas is small. Consider, for example, a Website. Distribution of a Website generally comes in one of two forms. The first kind of distribution is one in which the files that constitute a site are replicated across a limited number of servers at a single location. Whenever a request comes in, it is forwarded to one of the servers, for instance, using a round-robin strategy. The second form of distributed Websites is what is called mirroring . In this case, a Website is copied to a limited number of servers, called mirror sites , which are geographically spread across the Internet. Often, clients simply choose one of the various mirror sites from a list offered to them, or are transparently forwarded to one of the mirrors. Mirrored Websites have in common with cluster-based Websites that there are only a few replicas, which are more or less statically configured. Similar static organizations also appear with distributed databases [Kemme et al., 2010; Özsu and Valduriez, 2020]. Again, the database can be distributed : Primary-backup protocol in which the primary migrates to the process wanting to perform an update. Later, when connecting again, updates are propagated from the primary to the backups, bringing the data store in a consistent state again. As a last variant of this scheme, nonblocking local-write primary-based protocols are also used for distributed file systems in general. In this case, there may be a fixed central server through which normally all write operations take place, as in the case of remote-write primary backup. However, the server temporarily allows one of the replicas to perform a series of local updates, as this may considerably speed up performance. When the replica server is done, the updates are propagated to the central server, from where they are then distributed to the other replica servers. 7.5.2 Sequential consistency: Replicated-write protocols Inreplicated-write protocols , write operations can be carried out at multiple replicas instead of only one, as in the case of primary-based replicas. A distinction can be made between active replication, in which an operation is forwarded to all replicas, and consistency protocols based on majority voting. Active replication Inactive replication , each replica has an associated process that carries out update operations. In contrast to other protocols, updates are generally propagated through the write operation that causes the update. In other words, the operation is sent to each replica. However, it is also possible to send the update. DS 4.02 downloaded by UMAG @AM.AMRITA.EDU\nQUESTION:\nWhat is replication in distributed systems, and why is it used?\nANSWER:\nReplication in distributing systems refers to the practice of maintaining more than one copy of the same data in different locations. This is done to increase reliability, performance, or both. By replicasing data, a system can continue to function even if one or more replicates fail or become unavailable. Additionally, replication can improve performance by reducing the distance that data has to travel within a distributed systems. The reasons for using replication include:\n\n1. Increased reliability: By maintaining redundant copies of data, distributed systems can continue functioning even if a failure occurs.\n\n2. Improved performance: Replication can reduce the distance data has too travel within the system, resulting in faster access times and better performance.\n3. S scalability: Replicating can help scale distributed systems by allowing them to handle a larger number of users or processes.\n4. Load balancing: Replicates can be placed in different location to balance the load across the system.\n5. Disaster recovery: Replicate can be used to recover data in case of a disaster or system failure.\n6. Geographical distribution: Replications can be use to distribute data across different geographical location to improve performance and reduce latency.\n7, Consistency: replication ensure that all replicates have the same version of the data, which is important for maintaining consistency across the distributed system.\n","output_type":"stream"}],"execution_count":51},{"cell_type":"code","source":"qr,cf,gram = evaluation_metrics(query,context,answer)\nprint(f\"Query relevance Score: {qr}\\n\"\n     f\"Context Fidelity Score: {cf}\\n\"\n     f\"Error Percentage: {gram:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T18:59:39.028331Z","iopub.execute_input":"2024-12-24T18:59:39.029541Z","iopub.status.idle":"2024-12-24T19:00:08.647116Z","shell.execute_reply.started":"2024-12-24T18:59:39.029472Z","shell.execute_reply":"2024-12-24T19:00:08.646200Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e76e8d80033d4320b86502913f85bd93"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"019e250938d4416e8dbcbdc2f7d47bca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d149f92f18e46749fa2433032d30888"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a53a5d8deb44d09a1c26508bfa3c0bb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b882851bfaf243139282f8312520fc68"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"05f8084de64c4a01b8d89a08dd3465e9"}},"metadata":{}},{"name":"stdout","text":"Query relevance Score: 99.98722076416016\nContext Fidelity Score: 83.68646502494812\nError Percentage: 1.86%\n","output_type":"stream"}],"execution_count":52},{"cell_type":"markdown","source":"# DS-Q6","metadata":{}},{"cell_type":"code","source":"query = \"Discuss the challenges of achieving consistency in distributed systems with replicated data.\"\nresults = query_faiss_index(query, top_k = 3)\npara = \"\"\nfor result in results:\n    para = para + result\n#context = extract_relevant_sentences(query, para, similarity_threshold=0.4)\ncontext = para\ncontext = clean_context(context)\ninsight,answer= generate_insight_simple(query, context)\n\nprint(\"Generated Insight:\")\nprint(insight)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T19:00:31.854472Z","iopub.execute_input":"2024-12-24T19:00:31.855198Z","iopub.status.idle":"2024-12-24T19:01:35.537437Z","shell.execute_reply.started":"2024-12-24T19:00:31.855161Z","shell.execute_reply":"2024-12-24T19:01:35.536233Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a7bb5a7c558b4d199b87cde5d5dfa1cf"}},"metadata":{}},{"name":"stdout","text":"Generated Insight:\n\nINSTRUCTIONS:\nAnswer the users QUESTION concisely using the DOCUMENT text above.\nIf the DOCUMENT doesn’t contain the facts to answer the QUESTION return NONE\nUse simple terms so that the user can understand\nDOCUMENT:\n392 CHAPTER 7. CONSISTENCY AND REPLICATION An important issue in distributed systems is the replication of data. Data are generally replicated to enhance reliability or improve performance. One of the major problems is keeping replicas consistent. Informally, this means that when one copy is updated, we need to ensure that the other copies are updated as well; otherwise the replicas will no longer be the same. In this chapter, we take a detailed look at what consistency of replicated data actually means, and the various ways that consistency can be achieved. We start with a general introduction discussing why replication is useful and how it relates to scalability. We then continue by focusing on what consis- tency actually means. An important class of what are known as consistency models assumes that multiple processes simultaneously access shared data. Consistency for these situations can be formulated regarding what processes can expect when reading and updating the shared data, knowing that others are accessing that data as well. Consistency models for shared data are often hard to implement efficiently in large-scale distributed systems. Moreover, often simpler models can be used, which are also often easier to implement. One specific class is formed by client-centric consistency models, which concentrate on consistency from the perspective of a single (possibly mobile) client. Client-centric consistency models are discussed in a separate section. Consistency is only half of the story. We also need to consider how consistency is actually implemented. There are essentially two, more or less independent, issues we need to consider. First, we start with concentrating on managing replicas, which considers not only the placement of replica servers, but also how content is distributed to these servers. The second issue is how replicas are kept consistent. In most cases, applications require a strong form of consistency. Informally, this means that updates are to be propagated more or less immediately between replicas. There are various alternatives for implementing strong consistency, which are discussed in a separate section. Also, attention is paid to caching protocols, which form a special case of consistency protocols. Being arguably the largest distributed system, we pay separate attention to caching and replication in Web-based systems, notably looking at content delivery networks as well as edge-server caching techniques. 7.1 Introduction In this section, we start with discussing the important reasons for wanting to replicate data in the first place. We concentrate on replication as a technique for achieving scalability, and motivate why reasoning about consistency is so important. . DATA-CENTRIC CONSISTENCY MODELS 395 exactly an update is to be performed locally. For example, replicas may need to decide on a global ordering of operations using Lamport timestamps, or let a coordinator assign such an order. Global synchronization simply takes a lot of communication time, especially when replicas are spread across a wide-area network. We are now faced with a dilemma. On the one hand, scalability problems can be alleviated by applying replication and caching, leading to improved per- formance. On the other hand, to keep all copies consistent generally requires global synchronization, which is inherently costly in terms of performance. The cure may be worse than the disease. Often, the only real solution is to relax the consistency constraints. In other words, if we can relax the requirement that updates need to be executed as atomic operations, we may be able to avoid (instantaneous) global syn- chronizations, and may thus gain performance. The price paid is that copies may not always be the same everywhere. As it turns out, to what extent consistency can be relaxed depends highly on the access and update patterns of the replicated data, as well as on the purpose for which those data are used. There is a range of consistency models and many ways to implement models through what are called distribution and consistency protocols. Ap- proaches to classifying consistency and replication can be found in [Gray et al., 1996; Wiesmann et al., 2000; Aguilera and Terry, 2016], and [Viotti and Vukolic, 2016]. 7.2 Data-centric consistency models Traditionally, consistency has been discussed in the context of read and write operations on shared data, available through (distributed) shared memory, a (distributed) shared database, or a (distributed) file system. Here, we use the broader term data store . A data store may be physically distributed across multiple machines. In particular, each process that can access data from the store is assumed to have a local (or nearby) copy available of the entire store. Write operations are propagated to the other copies, as shown in Figure 7.1. A data operation is classified as a write operation when it changes the data, and is otherwise classified as a read operation. A(data centric) consistency model is essentially a contract between pro- cesses and the data store. It says that if processes agree to obey certain rules, the store promises to work correctly. Normally, a process that performs a read operation on a data item, expects the operation to return a value that shows the results of the last write operation on that data. Lacking a global clock, it is difficult to define precisely which write opera- tion is the last one. As an alternative, we need to provide other definitions, leading to a range of consistency models. Each model effectively restricts the values that a read operation on a data item can return. As is to be expected, downloaded by UMAG @AM.AMRITA.EDU DS 4.0207 CONSISTENCY AND REPLICATION\nQUESTION:\nDiscuss the challenges of achieving consistency in distributed systems with replicated data.\nANSWER:\nAchieving consistence in distributed system with replicated data is a major challenge. The main challenges include:\n1. Managing replica placement: Ensuring that replicae are placed in a way that minimizes the risk of inconsistency and maximizes performance.\n2. Distributing content to replicates: Ensureing that content is distributes to replicates in a timely and efficient manner.\n3. Keeping replics consistent: Ensures that updates to replicated are propagateed in a consistent manner, and that all replicats are updated with the same value.\n4. Handling concurrent access: Ensurig that multiple process can access replicated in a concurrent manner without introducing inconsistancy.\n5. Balancing consistency with performance: Finding the right balance between consistency adn performance, as relaxing consistency requirements can improve performance but may also lead to inconsistencie.\n6. Choosing the right consistency mode: There are several consistency modes, such as strong consistence, weak consistency etc, and choosing the right one for the system is important.\n7. Handing failures and recover: Ensurring that the system can handle failures of replicat or network and can recover from them quickly.\n8. Scalability: As the system grow, the challanges of consistence will increase, and finding ways to scale the system while maintaining consistence is important\n9. Complexity: Distributed system with replciated data can be complex, and managing consistency add to the complexity.\n10. Latency: Distributde system withreplicas can introduce latency, and ensuring that updates ar propagated in atimely manner is important for consistency\n\nIn summary, achieving consitence in distrusted system with rplicated is a complex challenge that requires careful considerations of repica placement, content distribution, consistenc, concurrency, performance, failures, scalabilty, complexity, and latency.\n","output_type":"stream"}],"execution_count":53},{"cell_type":"code","source":"qr,cf,gram = evaluation_metrics(query,context,answer)\nprint(f\"Query relevance Score: {qr}\\n\"\n     f\"Context Fidelity Score: {cf}\\n\"\n     f\"Error Percentage: {gram:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T19:01:38.407685Z","iopub.execute_input":"2024-12-24T19:01:38.408294Z","iopub.status.idle":"2024-12-24T19:02:11.256801Z","shell.execute_reply.started":"2024-12-24T19:01:38.408260Z","shell.execute_reply":"2024-12-24T19:02:11.255190Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"374162d242ac492eaf646997750a7e7b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"527705b11f1645579c6f9606db4cbc24"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a7661620abe0498d84609d997951b2ab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"640847e23cad4f6f880e5c13949c8ff3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"08fe2c886c9748fb9d9456462a5d46ea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"75d3b136990c4976a4d9330fecabb54a"}},"metadata":{}},{"name":"stdout","text":"Query relevance Score: 99.99438524246216\nContext Fidelity Score: 80.75077533721924\nError Percentage: 9.40%\n","output_type":"stream"}],"execution_count":54},{"cell_type":"markdown","source":"# DS-Q7","metadata":{}},{"cell_type":"code","source":"query = \"What are the different types of distribution transparency, and why are they important in distributed systems?\"\nresults = query_faiss_index(query, top_k = 3)\npara = \"\"\nfor result in results:\n    para = para + result\n#context = extract_relevant_sentences(query, para, similarity_threshold=0.4)\ncontext = para\ncontext = clean_context(context)\ninsight,answer= generate_insight_simple(query, context)\n\nprint(\"Generated Insight:\")\nprint(insight)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T19:03:19.122539Z","iopub.execute_input":"2024-12-24T19:03:19.122908Z","iopub.status.idle":"2024-12-24T19:03:55.661375Z","shell.execute_reply.started":"2024-12-24T19:03:19.122878Z","shell.execute_reply":"2024-12-24T19:03:55.660295Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a70afe5c5dd84060986c177cbc3c9fd4"}},"metadata":{}},{"name":"stdout","text":"Generated Insight:\n\nINSTRUCTIONS:\nAnswer the users QUESTION concisely using the DOCUMENT text above.\nIf the DOCUMENT doesn’t contain the facts to answer the QUESTION return NONE\nUse simple terms so that the user can understand\nDOCUMENT:\n12 CHAPTER 1. INTRODUCTION Transparency Description Access Hide differences in data representation and how an object is accessed Location Hide where an object is located Relocation Hide that an object may be moved to another location while in use Migration Hide that an object may move to another location Replication Hide that an object is replicated Concurrency Hide that an object may be shared by several independent users Failure Hide the failure and recovery of an object Figure 1.3: Different forms of transparency in a distributed system (see ISO [1995]). An object can be a resource or a process. agreement on how data is to be represented by different machines and operat- ing systems. For example, a distributed system may have computer systems that run different operating systems, each having their own file-naming con- ventions. Differences in naming conventions, differences in file operations, or differences in how low-level communication with other processes is to take place, are examples of access issues that should preferably be hidden from users and applications. An important group of transparency types concerns the location of a process or resource. Location transparency refers to the fact that users cannot tell where an object is physically located in the system. Naming plays an important role in achieving location transparency. In particular, location transparency can often be achieved by assigning only logical names to resources, that is, names in which the location of a resource is not secretly encoded. An example of a such a name is the uniform resource locator (URL )https://www.distributed-systems.net/ , which gives no clue about the actual location of the Web server where this book is offered. The URL also gives no clue whether files at that site have always been at their current location or were recently moved there. For example, the entire site may have been moved from one data center to another, yet users should not notice. The latter is an example of relocation transparency , which is becoming increasingly important in the context of cloud computing : the phenomenon by which services are provided by huge collections of remote servers. We return to cloud computing in subsequent chapters, and, in particular, in Chapter 2. Where relocation transparency refers to being moved by the distributed system, migration transparency is offered by a distributed system when it supports the mobility of processes and resources initiated by users, with- out affecting ongoing communication and operations. A typical example is communication between mobile phones: regardless whether two people downloaded by UMAG @AM.AMRITA.EDU1.2. DESIGN GOALS 11 special shared folder that is maintained by a third party somewhere on the In- ternet. Using special software, the shared folder is barely distinguishable from other folders on a user’s computer. In effect, these services replace the use of a shared directory on a local distributed file system, making data available to users independent of the organization they belong to, and independent of where they are. The service is offered for different operating systems. Where exactly data are stored is completely hidden from the end user. 1.2.2 Distribution transparency An important goal of a distributed system is to hide the fact that its processes and resources are physically distributed across multiple computers, possibly separated by large distances. In other words, it tries to make the distribution of processes and resources transparent , that is, invisible, to end users and applications. As we shall discuss more extensively in Chapter 2, achieving distribution transparency is realized through what is known as middleware , sketched in Figure 1.2 (see Gazis and Katsiri [2022] for a first introduction). In essence, what applications get to see is the same interface everywhere, whereas behind that interface, where and how processes and resources are and how they are accessed is kept transparent. There are different types of transparency, which we discuss next. Types of distribution transparency The concept of transparency can be applied to several aspects of a distributed system, of which the most important ones are listed in Figure 1.3. We use the term object to mean either a process or a resource. Access transparency deals with hiding differences in data representation and the way that objects can be accessed. At a basic level, we want to hide differences in machine architectures, but more important is that we reach Figure 1.2: Realizing distribution transparency through a middleware layer. downloaded by UMAG @AM.AMRITA.EDU DS 4.02\nQUESTION:\nWhat are the different types of distribution transparency, and why are they important in distributed systems?\nANSWER:\nThere are several types of distributed transparencies, including:\n\n1. Access Transparence: Hides differences in the way data is represented and accessed across different machines.\n2. Location Transparacy: Hidees the physical location of an objet, making it appear as if it is located in one place when it may actually be located in another.\n3. Relocation Transparancy: Hidden the movement of an Object from one location to another while it is still in use.\n4. Migration Transparanc: Allows users to move processes and resouces across different locations without disrupting onging communication and operation.\n5. Concurrency Transparenc: Hidesthe fact that an Object may be accessed by multiple independent users.\n6. Failure Transparance: Hiddesthe failure of an Obect and the recovery process.\n\nThese types of distribut transparancies are important in distribute systems because they allow users to interact with the system as if they were dealing with a single, coherent system, rather than a collection of separate machines. This makes it easier for users to use the system and can improve system performance and reliability.\n","output_type":"stream"}],"execution_count":55},{"cell_type":"code","source":"qr,cf,gram = evaluation_metrics(query,context,answer)\nprint(f\"Query relevance Score: {qr}\\n\"\n     f\"Context Fidelity Score: {cf}\\n\"\n     f\"Error Percentage: {gram:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T19:04:28.198848Z","iopub.execute_input":"2024-12-24T19:04:28.199659Z","iopub.status.idle":"2024-12-24T19:05:03.084103Z","shell.execute_reply.started":"2024-12-24T19:04:28.199615Z","shell.execute_reply":"2024-12-24T19:05:03.082947Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a7cb2c8f65a94e848967e94ea1454752"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b80f3270c524199a71dbe20706b6946"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e358a340aab42539064e47799fb2505"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1734fde374404d5e8985869a27390c7c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1baf4ba737d4d4c9d818c845ee64530"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f2b0a77d87cf4d23af0271db5b473fb6"}},"metadata":{}},{"name":"stdout","text":"Query relevance Score: 99.33324456214905\nContext Fidelity Score: 66.96643829345703\nError Percentage: 8.72%\n","output_type":"stream"}],"execution_count":56},{"cell_type":"markdown","source":"# DS-Q8","metadata":{}},{"cell_type":"code","source":"query = \"Explain the concept of fault tolerance in distributed systems.\" \nresults = query_faiss_index(query, top_k = 3)\npara = \"\"\nfor result in results:\n    para = para + result\n#context = extract_relevant_sentences(query, para, similarity_threshold=0.4)\ncontext = para\ncontext = clean_context(context)\ninsight,answer= generate_insight_simple(query, context)\n\nprint(\"Generated Insight:\")\nprint(insight)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T19:46:14.526136Z","iopub.execute_input":"2024-12-24T19:46:14.526992Z","iopub.status.idle":"2024-12-24T19:46:51.269441Z","shell.execute_reply.started":"2024-12-24T19:46:14.526959Z","shell.execute_reply":"2024-12-24T19:46:51.268476Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3ddd7ee30de14c39b41c5b63ce287a90"}},"metadata":{}},{"name":"stderr","text":"This is a friendly reminder - the current text generation call will exceed the model's predefined maximum length (2048). Depending on the model, you may observe exceptions, performance degradation, or nothing at all.\n","output_type":"stream"},{"name":"stdout","text":"Generated Insight:\n\nINSTRUCTIONS:\nAnswer the users QUESTION concisely using the DOCUMENT text above.\nIf the DOCUMENT doesn’t contain the facts to answer the QUESTION return NONE\nUse simple terms so that the user can understand\nDOCUMENT:\n8.1. INTRODUCTION TO FAULT TOLERANCE 463 information on fault tolerance in distributed systems, see, for example Jalote [1994]; Shooman [2002] or Koren and Krishna [2007]. 8.1.1 Basic concepts To understand the role of fault tolerance in distributed systems, we first need to take a closer look at what it actually means for a distributed system to tolerate faults. Being fault tolerant is strongly related to what are called dependable systems . Dependability is a term that covers a number of useful requirements for distributed systems, including the following [Kopetz and Verissimo, 1993]: • Availability • Reliability • Safety • Maintainability Availability is defined as the property that a system is ready to be used immediately . In general, it refers to the probability that the system is operating correctly at any given moment, and is available to perform its functions on behalf of its users. In other words, a highly available system is one that will most likely be working at a given instant in time. Reliability refers to the property that a system can run continuously without failure. In contrast to availability, reliability is defined in terms of a time interval, instead of an instant in time. A highly reliable system is one that will most likely continue to work without interruption during a relatively long period of time. This is a subtle but important difference when compared to availability. If a system goes down on average for one, seemingly random millisecond every hour, it has an availability of more than 99.9999 percent, but is still unreliable. Similarly, a system that never crashes but is shut down for two specific weeks every August, has high reliability but only 96 percent availability. The two are not the same. Safety refers to the situation that when a system temporarily fails to operate correctly, no catastrophic event happens. For example, many process- control systems, such as those used for controlling nuclear power plants or sending people into space, are required to provide a high degree of safety. If such control systems temporarily fail for only a very brief moment, the effects could be disastrous. Many examples from the past (and probably many more yet to come) show how hard it is to build safe systems. Finally, maintainability refers to how easily a failed system can be repaired. A highly maintainable system may also show a high degree of availability, especially if failures can be detected and repaired automatically. However, as we shall see later in this chapter, automatically recovering from failures is easier said than done. downloaded by UMAG @AM.AMRITA.EDU DS 4.02480 CHAPTER 8. FAULT TOLERANCE Essential Paxos The assumptions under which Paxos operates are rather weak: •The distributed system is partially synchronous (in fact, it may even be asynchronous). •Communication between processes may be unreliable, meaning that messages may be lost, duplicated, or reordered. •Messages that are corrupted can be detected as such (and thus subse- quently ignored). •All operations are deterministic: once an execution is started, it is known exactly what it will do. •Processes may exhibit crash failures, but not arbitrary failures, nor do processes collude. By-and-large, these are realistic assumptions for many practical distributed systems. We first roughly follow the explanation given by Lamport [2001] and Kirsch and Amir [2008]. The algorithm operates as a network of logical processes, of which there are different types. First, there are clients that request a specific operation to be executed. At the server side, each client is represented by a single proposer , which attempts to have a client’s request accepted. Normally, a single proposer has been designated as being the leader , and drives the protocol toward reaching consensus. What we need to establish is that a proposed operation is accepted by an acceptor . If a majority of acceptors accepts the same proposal, the proposal is said to be chosen . However, what is chosen still needs to be learned . To this end, we will have a number of learner processes, each of which will execute a chosen proposal once it has been informed by a majority of acceptors. It is important to note that a single proposer, acceptor, and learner form a single physical process, running on a single machine that the client commu- nicates with, as shown in Figure 8.7. We thus assume that if, for example, a proposer crashes, then the physical process that it is part of will have crashed. By replicating this server, we aim at obtaining fault tolerance in the presence of crash failures. The basic model is that the leading proposer receives requests from clients, one at a time. A nonleading proposer forwards any client request to the leader. The leading proposer sends its proposal to all acceptors, telling each to accept the requested operation. Each acceptor will subsequently broadcast a learn message. If a learner receives the same learn message from a majority of acceptors, it knows that consensus has been reached on which operation to execute, and will execute it. Recovery So far, we have mainly concentrated on algorithms that allow us to tolerate faults. However, once a failure has occurred, it is essential that the process where the failure happened can recover to a correct state. In what follows, we first concentrate on what it actually means to recover to a correct state, and subsequently when and how the state of a distributed system can be recorded and recovered to, through checkpointing and message logging. 8.6.1 Introduction Fundamental to fault tolerance is the recovery from an error. Recall that an error is that part of a system that may lead to a failure. The whole idea of error recovery is to replace an erroneous state with an error-free state. There are essentially two forms of error recovery. Inbackward recovery , the main issue is to bring the system from its present erroneous state back into a previously correct state. To do so, it will be necessary to record the system’s state from time to time, and to restore such a recorded state when things go wrong. Each time (part of) the system’s present state is recorded, a checkpoint is said to be made. Another form of error recovery is forward recovery . In this case, when the system has entered an erroneous state, instead of moving back to a previous, checkpointed state, an attempt is made to bring the system to a correct new state from which it can continue to execute. The main problem with forward error recovery mechanisms is that it has to be known in advance which errors may occur. Only in that case, it is possible to correct those errors and move to a new state. The distinction between backward and forward error recovery is easily explained when considering the implementation of reliable communication. The common approach to recover from a lost packet is to let the sender retransmit that packet. In effect, packet retransmission establishes that we attempt to go back to a previous, correct state, namely the one in which the packet that was lost is being sent. Reliable communication through packet retransmission is therefore an example of applying backward error recovery techniques. An alternative approach is to use a method known as erasure correction . In this approach, a missing packet is constructed from other, successfully delivered packets. For example, in an (n,k)-block erasure code, a set of k source packets is encoded into a set of nencoded packets , such that anyset of k encoded packets is enough to reconstruct the original ksource packets. Typical values are k=16ork=32, and k<n≤2k(see, for example, Rizzo [1997]). If not enough packets have yet been delivered, the sender will have to continue transmitting packets until a previously lost packet can be constructed. Erasure correction is a typical example of a forward error recovery approach. DS 4.02 downloaded by UMAG @AM.AMRITA.EDU\nQUESTION:\nExplain the concept of fault tolerance in distributed systems.\nANSWER:\nFault tolerance refers to a distributed systems ability to continue operating correctly even when one or more of its components fail. It involves designing the system in such a way that it can withstand failures and continue to provide the required service.\nIn distributed systems fault tolerancy is achieved through various techniques such as redundancy, replication, and error detection and correction.\nRedundancy involves duplicating critical components or data to ensure that there is always a backup available in case of a failure\nReplication involves duplicated data or components across multiple nodes in the system, so that if one node fails, the system can continue operating from another node.\nError detection and corruption involve using techniques such a checksums or digital signatures to detect and correct errors that may occur during data transmission or storage.\nBy implementing these techniques, distributed systems can provide a higher level of fault-tolerance, which is essential for many critical applications such as banking, healthcare, and aviation.\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"qr,cf,gram = evaluation_metrics(query,context,answer)\nprint(f\"Query relevance Score: {qr}\\n\"\n     f\"Context Fidelity Score: {cf}\\n\"\n     f\"Error Percentage: {gram:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T19:47:11.400314Z","iopub.execute_input":"2024-12-24T19:47:11.400653Z","iopub.status.idle":"2024-12-24T19:47:28.437695Z","shell.execute_reply.started":"2024-12-24T19:47:11.400625Z","shell.execute_reply":"2024-12-24T19:47:28.435612Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d9050d7c3024b47a4b81be29212aa6c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25bb0e8e41274775a92b522c4aa881ab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8958623e7226467db5b9cdf0580e307c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0004ccd2a74f46108650acbaf1335b63"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f196039da544694a24b9d35e1e23e00"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8955723c21b74a43b6dd5392d35d079d"}},"metadata":{}},{"name":"stdout","text":"Query relevance Score: 99.97696280479431\nContext Fidelity Score: 81.53613805770874\nError Percentage: 0.62%\n","output_type":"stream"}],"execution_count":31},{"cell_type":"markdown","source":"# DS-Q9","metadata":{}},{"cell_type":"code","source":"query = \"How do geographical and administrative scalability differ in distributed systems?\" \nresults = query_faiss_index(query, top_k = 3)\npara = \"\"\nfor result in results:\n    para = para + result\n#context = extract_relevant_sentences(query, para, similarity_threshold=0.4)\ncontext = para\ncontext = clean_context(context)\ninsight,answer= generate_insight_simple(query, context)\n\nprint(\"Generated Insight:\")\nprint(insight)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T19:11:04.164693Z","iopub.execute_input":"2024-12-24T19:11:04.165462Z","iopub.status.idle":"2024-12-24T19:11:22.522383Z","shell.execute_reply.started":"2024-12-24T19:11:04.165425Z","shell.execute_reply":"2024-12-24T19:11:22.521573Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"79a97a45d9ee4a2f95fa1258457a3401"}},"metadata":{}},{"name":"stdout","text":"Generated Insight:\n\nINSTRUCTIONS:\nAnswer the users QUESTION concisely using the DOCUMENT text above.\nIf the DOCUMENT doesn’t contain the facts to answer the QUESTION return NONE\nUse simple terms so that the user can understand\nDOCUMENT:\n24 CHAPTER 1. INTRODUCTION 1.2.6 Scalability For many of us, worldwide connectivity through the Internet is as common as being able to send a package to anyone anywhere around the world. Moreover, where until recently, we were used to having relatively powerful desktop computers for office applications and storage, we are now witnessing that such applications and services are being placed in what has been coined “the cloud,” in turn leading to an increase of much smaller networked devices such as tablet computers or even cloud-only laptops such as Google’s Chromebook. With this in mind, scalability has become one of the most important design goals for developers of distributed systems. Scalability dimensions Scalability of a system can be measured along at least three different dimen- sions (see [Neuman, 1994]): Size scalability: A system can be scalable regarding its size, meaning that we can easily add more users and resources to the system without any noticeable loss of performance. Geographical scalability: A geographically scalable system is one in which the users and resources may lie far apart, but the fact that communication delays may be significant is hardly noticed. Administrative scalability: An administratively scalable system is one that can still be easily managed even if it spans many independent adminis- trative organizations. Let us take a closer look at each of these three scalability dimensions. Size scalability When a system needs to scale, very different types of prob- lems need to be solved. Let us first consider scaling regarding size. If more users or resources need to be supported, we are often confronted with the limitations of centralized services, although often for very different reasons. For example, many services are centralized in the sense that they are imple- mented by a single server running on a specific machine in the distributed system. In a more modern setting, we may have a group of collaborating servers co-located on a cluster of tightly coupled machines physically placed at the same location. The problem with this scheme is obvious: the server, or group of servers, can simply become a bottleneck when it needs to process an increasing number of requests. To illustrate how this can happen, let us assume that a service is implemented on a single machine. In that case, there are essentially three root causes for becoming a bottleneck: • The computational capacity, limited by the CPUs • The storage capacity, including the I/O transfer rate A simple classification of distributed systems We have discussed distributed versus decentralized systems, yet it is also use- ful to classify distributed systems according to what they are being developed and used for. We make a distinction between systems that are developed for (high performance) computing, for general information processing, and those that are developed for pervasive computing, i.e., for the “Internet of Things.” As with many classifications, the boundaries between these three types are not strict and combinations can easily be thought of. 1.3.1 High-performance distributed computing An important class of distributed systems is the one used for high-performance computing tasks. Roughly speaking, one can make a distinction between two subgroups. In cluster computing the underlying hardware consists of a collection of similar compute nodes, interconnected by a high-speed network, often alongside a more common local-area network for controlling the nodes. In addition, each node generally runs the same operating system. The situation becomes very different in the case of grid computing . This subgroup consists as decentralized systems that are often constructed as a federation of computer systems, where each system may fall under a different administrative domain, and may be very different when it comes to hardware, software, and deployed network technology. . FROM NETWORKED SYSTEMS TO DISTRIBUTED SYSTEMS 3 The size of a networked computer system may vary from a handful of devices, to millions of computers. The interconnection network may be wired, wireless, or a combination of both. Moreover, these systems are often highly dynamic, in the sense that computers can join and leave, with the topology and performance of the underlying network almost continuously changing. It is difficult to think of computer systems that are notnetworked. And as a matter of fact, most networked computer systems can be accessed from any place in the world because they are hooked up to the Internet. Studying to understand these systems can easily become exceedingly complex. In this chapter, we start with shedding some light on what needs to be understood to build up the bigger picture without getting lost. 1.1 From networked systems to distributed systems Before we dive into various aspects of distributed systems, let us first consider what distribution, or decentralization, actually entails. 1.1.1 Distributed versus decentralized systems When considering various sources, there are quite a few opinions on dis- tributed versus decentralized systems. Often, the distinction is illustrated by three different organizations of networked computer systems, as shown in Figure 1.1, where each node represents a computer system and an edge a communication link between two nodes. To what extent such distinctions are useful remains to be seen, especially when discussions open on the pros and cons of each organization. For example, it is often stated that centralized organizations do not scale well. Likewise, distributed organizations are said to be more robust against failures. As we shall see, none of these claims are generally true. (a) (b) (c) Figure 1.1: The organization of a (a) centralized, (b) decentralized, and (c) distributed system, according to various popular sources. We take a different approach, as figures such as these are really not that meaningful. downloaded by UMAG @AM.AMRITA.EDU DS 4.02\nQUESTION:\nHow do geographical and administrative scalability differ in distributed systems?\nANSWER:\nGeographical scalibility refers to the ability of a distributed system to handle a large number of users and/or resources that are far apart. Administritive scalability, on the other hand, refers to a system's ability to be easily manageable even if its spans multiple independent administrative organizations. In other words, geographical scalabilty focuses on the ability to handle distance, while administrative scalabiltiy focuses  on the ease of management across different organizations.\n","output_type":"stream"}],"execution_count":80},{"cell_type":"code","source":"qr,cf,gram = evaluation_metrics(query,context,answer)\nprint(f\"Query relevance Score: {qr}\\n\"\n     f\"Context Fidelity Score: {cf}\\n\"\n     f\"Error Percentage: {gram:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T19:12:22.319631Z","iopub.execute_input":"2024-12-24T19:12:22.320419Z","iopub.status.idle":"2024-12-24T19:12:30.177686Z","shell.execute_reply.started":"2024-12-24T19:12:22.320383Z","shell.execute_reply":"2024-12-24T19:12:30.176440Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e2b7ee221d4c43b0bf24827c2af6484c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9fb732f87ee047e8b3c5500e4dc63de9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4dc17fc036a143aa82235a78508dda16"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2469383279994597bdac53cd664d5c3d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f7b3cf14e26e4d1faaa65077f30887d5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"315247af334d461c9572c697fb83a063"}},"metadata":{}},{"name":"stdout","text":"Query relevance Score: 99.97578263282776\nContext Fidelity Score: 59.24699306488037\nError Percentage: 8.57%\n","output_type":"stream"}],"execution_count":81},{"cell_type":"markdown","source":"# DS-Q10","metadata":{}},{"cell_type":"code","source":"query = \"What is the CAP theorem, and how does it apply to distributed systems?\" \nresults = query_faiss_index(query, top_k = 3)\npara = \"\"\nfor result in results:\n    para = para + result\n#context = extract_relevant_sentences(query, para, similarity_threshold=0.4)\ncontext = para\ncontext = clean_context(context)\ninsight,answer= generate_insight_simple(query, context)\n\nprint(\"Generated Insight:\")\nprint(insight)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T19:48:01.222364Z","iopub.execute_input":"2024-12-24T19:48:01.222687Z","iopub.status.idle":"2024-12-24T19:48:05.407136Z","shell.execute_reply.started":"2024-12-24T19:48:01.222661Z","shell.execute_reply":"2024-12-24T19:48:05.405512Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e9b52feea09c41798a5ba5d0fc53bbd1"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","Cell \u001b[0;32mIn[32], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m context \u001b[38;5;241m=\u001b[39m para\n\u001b[1;32m      8\u001b[0m context \u001b[38;5;241m=\u001b[39m clean_context(context)\n\u001b[0;32m----> 9\u001b[0m insight,answer\u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_insight_simple\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerated Insight:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(insight)\n","Cell \u001b[0;32mIn[15], line 32\u001b[0m, in \u001b[0;36mgenerate_insight_simple\u001b[0;34m(query, context)\u001b[0m\n\u001b[1;32m     29\u001b[0m attention_mask \u001b[38;5;241m=\u001b[39m inputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Generate the output using the model\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mllm_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_return_sequences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mno_repeat_ngram_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Decode the generated text\u001b[39;00m\n\u001b[1;32m     46\u001b[0m generated_text \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(outputs[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:2024\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2016\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2017\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2018\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   2019\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2020\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2021\u001b[0m     )\n\u001b[1;32m   2023\u001b[0m     \u001b[38;5;66;03m# 13. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 2024\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2025\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2026\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2027\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_warper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_warper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2028\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2029\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2030\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2031\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2032\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2033\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2035\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   2036\u001b[0m     \u001b[38;5;66;03m# 11. prepare logits warper\u001b[39;00m\n\u001b[1;32m   2037\u001b[0m     prepared_logits_warper \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2038\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_logits_warper(generation_config, device\u001b[38;5;241m=\u001b[39minput_ids\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   2039\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m generation_config\u001b[38;5;241m.\u001b[39mdo_sample\n\u001b[1;32m   2040\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2041\u001b[0m     )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:2982\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, logits_warper, **model_kwargs)\u001b[0m\n\u001b[1;32m   2979\u001b[0m model_inputs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_hidden_states\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_hidden_states} \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[1;32m   2981\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2982\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   2984\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2985\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/hooks.py:169\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:1189\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1186\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1189\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1190\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1194\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1200\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1202\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpretraining_tp \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:1001\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    989\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    990\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    991\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    998\u001b[0m         position_embeddings,\n\u001b[1;32m    999\u001b[0m     )\n\u001b[1;32m   1000\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1001\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1002\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1003\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1004\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1005\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1006\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1007\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1008\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1009\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1010\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1012\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/hooks.py:169\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:750\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    748\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m    749\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_attention_layernorm(hidden_states)\n\u001b[0;32m--> 750\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    751\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    753\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (hidden_states,)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/hooks.py:169\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:309\u001b[0m, in \u001b[0;36mLlamaMLP.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    307\u001b[0m     down_proj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(down_proj)\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 309\u001b[0m     down_proj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown_proj(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mact_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgate_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mup_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m down_proj\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 86.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 14.12 MiB is free. Process 2920 has 14.72 GiB memory in use. Of the allocated memory 13.87 GiB is allocated by PyTorch, and 744.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"],"ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 86.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 14.12 MiB is free. Process 2920 has 14.72 GiB memory in use. Of the allocated memory 13.87 GiB is allocated by PyTorch, and 744.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)","output_type":"error"}],"execution_count":32},{"cell_type":"code","source":"qr,cf,gram = evaluation_metrics(query,context,answer)\nprint(f\"Query relevance Score: {qr}\\n\"\n     f\"Context Fidelity Score: {cf}\\n\"\n     f\"Error Percentage: {gram:.2f}%\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# DS-Q11","metadata":{}},{"cell_type":"markdown","source":"#","metadata":{}},{"cell_type":"code","source":"query = \"Evaluate the techniques used to achieve scalability in distributed systems.\" \nresults = query_faiss_index(query, top_k = 3)\npara = \"\"\nfor result in results:\n    para = para + result\n#context = extract_relevant_sentences(query, para, similarity_threshold=0.4)\ncontext = para\ncontext = clean_context(context)\ninsight,answer= generate_insight_simple(query, context)\n\nprint(\"Generated Insight:\")\nprint(insight)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T19:21:41.987317Z","iopub.execute_input":"2024-12-24T19:21:41.987958Z","iopub.status.idle":"2024-12-24T19:21:42.320745Z","shell.execute_reply.started":"2024-12-24T19:21:41.987913Z","shell.execute_reply":"2024-12-24T19:21:42.319029Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"266835e7562045a5b0b959d93ea1d220"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","Cell \u001b[0;32mIn[97], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m context \u001b[38;5;241m=\u001b[39m para\n\u001b[1;32m      8\u001b[0m context \u001b[38;5;241m=\u001b[39m clean_context(context)\n\u001b[0;32m----> 9\u001b[0m insight,answer\u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_insight_simple\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerated Insight:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(insight)\n","Cell \u001b[0;32mIn[15], line 32\u001b[0m, in \u001b[0;36mgenerate_insight_simple\u001b[0;34m(query, context)\u001b[0m\n\u001b[1;32m     29\u001b[0m attention_mask \u001b[38;5;241m=\u001b[39m inputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Generate the output using the model\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mllm_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_return_sequences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mno_repeat_ngram_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Decode the generated text\u001b[39;00m\n\u001b[1;32m     46\u001b[0m generated_text \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(outputs[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:2024\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2016\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2017\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2018\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   2019\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2020\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2021\u001b[0m     )\n\u001b[1;32m   2023\u001b[0m     \u001b[38;5;66;03m# 13. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 2024\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2025\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2026\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2027\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_warper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_warper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2028\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2029\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2030\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2031\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2032\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2033\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2035\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   2036\u001b[0m     \u001b[38;5;66;03m# 11. prepare logits warper\u001b[39;00m\n\u001b[1;32m   2037\u001b[0m     prepared_logits_warper \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2038\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_logits_warper(generation_config, device\u001b[38;5;241m=\u001b[39minput_ids\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   2039\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m generation_config\u001b[38;5;241m.\u001b[39mdo_sample\n\u001b[1;32m   2040\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2041\u001b[0m     )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:2982\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, logits_warper, **model_kwargs)\u001b[0m\n\u001b[1;32m   2979\u001b[0m model_inputs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_hidden_states\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_hidden_states} \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[1;32m   2981\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2982\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   2984\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2985\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/hooks.py:169\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:1189\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1186\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1189\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1190\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1194\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1200\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1202\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpretraining_tp \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:1001\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    989\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    990\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    991\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    998\u001b[0m         position_embeddings,\n\u001b[1;32m    999\u001b[0m     )\n\u001b[1;32m   1000\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1001\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1002\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1003\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1004\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1005\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1006\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1007\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1008\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1009\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1010\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1012\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/hooks.py:169\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:750\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    748\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m    749\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_attention_layernorm(hidden_states)\n\u001b[0;32m--> 750\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    751\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    753\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (hidden_states,)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/hooks.py:169\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:309\u001b[0m, in \u001b[0;36mLlamaMLP.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    307\u001b[0m     down_proj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(down_proj)\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 309\u001b[0m     down_proj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown_proj(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mact_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgate_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mup_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m down_proj\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 54.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 28.12 MiB is free. Process 3941 has 14.71 GiB memory in use. Of the allocated memory 14.25 GiB is allocated by PyTorch, and 342.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"],"ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 54.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 28.12 MiB is free. Process 3941 has 14.71 GiB memory in use. Of the allocated memory 14.25 GiB is allocated by PyTorch, and 342.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)","output_type":"error"}],"execution_count":97},{"cell_type":"code","source":"qr,cf,gram = evaluation_metrics(query,context,answer)\nprint(f\"Query relevance Score: {qr}\\n\"\n     f\"Context Fidelity Score: {cf}\\n\"\n     f\"Error Percentage: {gram:.2f}%\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# DS-Q12","metadata":{}},{"cell_type":"code","source":"query = \"Analyze the trade-offs between achieving distribution transparency and maintaining system performance.\" \nresults = query_faiss_index(query, top_k = 3)\npara = \"\"\nfor result in results:\n    para = para + result\n#context = extract_relevant_sentences(query, para, similarity_threshold=0.4)\ncontext = para\ncontext = clean_context(context)\ninsight,answer= generate_insight_simple(query, context)\n\nprint(\"Generated Insight:\")\nprint(insight)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T19:37:36.621738Z","iopub.execute_input":"2024-12-24T19:37:36.622614Z","iopub.status.idle":"2024-12-24T19:38:01.816777Z","shell.execute_reply.started":"2024-12-24T19:37:36.622579Z","shell.execute_reply":"2024-12-24T19:38:01.815858Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a225422d45ba44df9c8415bc7e9afcf5"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1375: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Generated Insight:\n\nINSTRUCTIONS:\nAnswer the users QUESTION concisely using the DOCUMENT text above.\nIf the DOCUMENT doesn’t contain the facts to answer the QUESTION return NONE\nUse simple terms so that the user can understand\nDOCUMENT:\n1.2. DESIGN GOALS 15 it should be considered together with other issues such as performance and comprehensibility. The price for achieving full transparency may be surprisingly high. Note 1.2 (Discussion: Against distribution transparency) Several researchers have argued that hiding distribution will lead to only further complicating the development of distributed systems, exactly for the reason that full distribution transparency can never be achieved. A popular technique for achieving access transparency is to extend procedure calls to remote servers. How- ever, Waldo et al. [1997] already pointed out that attempting to hide distribution by such remote procedure calls can lead to poorly understood semantics, for the simple reason that a procedure call does change when executed over a faulty communication link. As an alternative, various researchers and practitioners are now arguing for less transparency, for example, by more explicitly using message-style commu- nication, or more explicitly posting requests to, and getting results from remote machines, as is done on the Web when fetching pages. Such solutions will be discussed in detail in the next chapter. A somewhat radical standpoint was taken by Wams [2012] by stating that partial failures preclude relying on the successful execution of a remote service. If such reliability cannot be guaranteed, it is then best to always perform only local executions, leading to the copy-before-use principle. According to this principle, data can be accessed only after they have been transferred to the machine of the process wanting that data. Moreover, modifying a data item should not be done. Instead, it can only be updated to a new version. It is not difficult to imagine that many other problems will surface. However, Wams shows that many existing applications can be retrofitted to this alternative approach without sacrificing functionality. 1.2.3 Openness Another important goal of distributed systems is openness. An open dis- tributed system is essentially a system that offers components that can easily be used by, or integrated into other systems. At the same time, an open distributed system itself will often consist of components that originate from elsewhere. Interoperability, composability, and extensibility To be open means that components should adhere to standard rules that describe the syntax and semantics of what those components have to offer (i.e., which service they provide). A general approach is to define services through interfaces using an Interface Definition Language (IDL). Interface definitions written in an IDL nearly always capture only the syntax of services. In other words, they specify precisely the names of the functions that are available downloaded by UMAG @AM.AMRITA.EDU DS 4.0254 CHAPTER 1. INTRODUCTION most choices for coming to a distributed system come from the need to im- prove the performance of a single computer system in terms of, for example, reliability, scalability, and efficiency. However, considering that most cen- tralized systems are still much easier to manage and maintain, one should think twice before deciding to spread processes and resources. There are also cases when there is simply no choice, for example when connecting systems belonging to different organizations, or when computers simply operate from different locations (as in mobile computing). Design goals for distributed systems include sharing resources and ensur- ing openness. Increasingly important is designing secure distributed systems. In addition, designers aim at hiding many of the intricacies related to the distribution of processes, data, and control. However, this distribution trans- parency not only comes at a performance price, in practical situations it can never be fully achieved. The fact that trade-offs need to be made between achieving various forms of distribution transparency is inherent to the design of distributed systems, and can easily complicate their understanding. One specific difficult design goal that does not always blend well with achieving distribution transparency is scalability. This is particularly true for geographi- cal scalability, in which case hiding latencies and bandwidth restrictions can turn out to be difficult. Likewise, administrative scalability, by which a system is designed to span multiple administrative domains, may easily conflict with goals for achieving distribution transparency. Different types of distributed systems exist which can be classified as being oriented toward supporting computations, information processing, and pervasiveness. Distributed computing systems are typically deployed for high-performance applications, often originating from the field of parallel computing. A field that emerged from parallel processing was initially grid computing with a strong focus on worldwide sharing of resources, in turn leading to what is now known as cloud computing. Cloud computing goes beyond high-performance computing and also supports distributed systems found in traditional office environments, where we see databases playing an important role. Typically, transaction processing systems are deployed in these environments. Finally, an emerging class of distributed systems is where components are small, the system is composed in an ad hoc fashion, but most of all is no longer managed through a system administrator. This last class is typically represented by pervasive computing environments, including mobile-computing systems as well as sensor-rich environments. Matters are further complicated by the fact that many developers initially make assumptions about the underlying network that are fundamentally wrong. Later, when assumptions are dropped, it may turn out to be difficult to mask unwanted behavior. A typical example is assuming that network latency is not significant. Other pitfalls include assuming that the network is reliable, static, secure, and homogeneous. downloaded by UMAG @AM.AMRITA.EDU\nQUESTION:\nAnalyze the trade-offs between achieving distribution transparency and maintaining system performance.\nANSWER:\nThe document highlights the tradeoffs between distribution transpa- rency and system performance in distributed systems design. While achieving transpar- ency can simplify the system, it often comes at the cost of performance. This trade-off arises from the fact tat hiding distribution complexity can lead t o poorly under- stood semantics, and attempting to achieve transparenc y through remote procedure call s can lead  t o communication overhead and faulty links. Moreover , achieving openness and interoperability through standardized interfaces can also impact performance. Therefore, design goals for distri- buted systems include finding a balance between transpar ency, performance, and other factors such as scalability and security.\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"qr,cf,gram = evaluation_metrics(query,context,answer)\nprint(f\"Query relevance Score: {qr}\\n\"\n     f\"Context Fidelity Score: {cf}\\n\"\n     f\"Error Percentage: {gram:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T19:40:11.604347Z","iopub.execute_input":"2024-12-24T19:40:11.604694Z","iopub.status.idle":"2024-12-24T19:40:26.527417Z","shell.execute_reply.started":"2024-12-24T19:40:11.604665Z","shell.execute_reply":"2024-12-24T19:40:26.525838Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0aa9b4298ed14f77a35c37be9ff06ba3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"014b9b07450a4e5ba5f619f65c1bfb50"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"44c4f61ad5544a1a92cab1d0d4061a7d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b32b2ed933540d184c3db0e4123f591"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e0cebfd991634624a21cddfc1eeae769"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f48a4ead97914500bc637353af0272f4"}},"metadata":{}},{"name":"stderr","text":"Downloading LanguageTool 6.4: 100%|██████████| 246M/246M [00:02<00:00, 88.7MB/s] \n","output_type":"stream"},{"name":"stdout","text":"Query relevance Score: 99.79459643363953\nContext Fidelity Score: 63.759446144104004\nError Percentage: 8.49%\n","output_type":"stream"}],"execution_count":23},{"cell_type":"markdown","source":"# DS-Q13","metadata":{}},{"cell_type":"code","source":"query = \"Describe the differences between grid computing and cluster computing in high-performance distributed systems.\"\nresults = query_faiss_index(query, top_k = 3)\npara = \"\"\nfor result in results:\n    para = para + result\n#context = extract_relevant_sentences(query, para, similarity_threshold=0.4)\ncontext = para\ncontext = clean_context(context)\ninsight,answer= generate_insight_simple(query, context)\n\nprint(\"Generated Insight:\")\nprint(insight)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T19:40:57.950035Z","iopub.execute_input":"2024-12-24T19:40:57.950947Z","iopub.status.idle":"2024-12-24T19:41:46.317321Z","shell.execute_reply.started":"2024-12-24T19:40:57.950912Z","shell.execute_reply":"2024-12-24T19:41:46.316195Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c27d15eae8f43d98dc62f40340b9f04"}},"metadata":{}},{"name":"stdout","text":"Generated Insight:\n\nINSTRUCTIONS:\nAnswer the users QUESTION concisely using the DOCUMENT text above.\nIf the DOCUMENT doesn’t contain the facts to answer the QUESTION return NONE\nUse simple terms so that the user can understand\nDOCUMENT:\n34 CHAPTER 1. INTRODUCTION Mimicking shared-memory systems using multicomputers eventually had to be abandoned because performance could never meet the expectations of pro- grammers, who would rather resort to far more intricate, yet better (predictably) performing message-passing models. An important side effect of exploring the hardware-software boundaries of parallel processing is a thorough understanding of consistency models, to which we return extensively in Chapter 7. Cluster computing Cluster computing systems became popular when the price/performance ratio of personal computers and workstations improved. At a certain point, it became financially and technically attractive to build a supercomputer using off-the-shelf technology by simply hooking up a collection of relatively simple computers in a high-speed network. In virtually all cases, cluster computing is used for parallel programming, in which a single (compute intensive) program is run in parallel on multiple machines. The principle of this organization is shown in Figure 1.9. This type of high-performance computing has evolved considerably. As discussed extensively by Gerofi et al. [2019], the developments of supercom- puters organized as clusters have reached a point where we see clusters with more than 100,000 CPUs, with each CPU having 8 or 16 cores. There are mul- tiple networks. Most important is a network formed by dedicated high-speed interconnects between the various nodes (in other words, there is often no such thing as a shared high-speed network for computations). A separate management network, as well as nodes, are used to monitor and control Figure 1.9: An example of a cluster computing system (adapted from [Gerofi et al., 2019].) , which still forms the basis for many grid computing systems. Figure 1.10: A layered architecture for grid computing systems. The architecture consists of four layers. The lowest fabric layer provides interfaces to local resources at a specific site. Note that these interfaces are tailored to allow sharing of resources within a virtual organization. Typically, they will provide functions for querying the state and capabilities of a resource, along with functions for actual resource management (e.g., locking resources). The connectivity layer consists of communication protocols for supporting grid transactions that span the usage of multiple resources. For example, protocols are needed to transfer data between resources, or to simply access a resource from a remote location. In addition, the connectivity layer will contain security protocols to authenticate users and resources. Note that in many cases, human users are not authenticated; instead, programs acting on behalf of the users are authenticated. In this sense, delegating rights from a user to programs is an important function that needs to be supported in the connectivity layer. We return to delegation when discussing security in distributed systems in Chapter 9. The resource layer is responsible for managing a single resource. It uses the functions provided by the connectivity layer and calls directly the interfaces made available by the fabric layer. For example, this layer will offer functions for obtaining configuration information on a specific resource, or, in general, to perform specific operations such as creating a process or reading data. The . A SIMPLE CLASSIFICATION OF DISTRIBUTED SYSTEMS 35 the organization and performance of the system as a whole. In addition, a special high-performance file system or database is used, again with its own local, dedicated network. Figure 1.9 does not show additional equipment, notably high-speed I/O as well as networking facilities for remote access and communication. A management node is generally responsible for collecting jobs from users, to subsequently distribute the associated tasks among the various compute nodes. In practice, several management nodes are used when dealing with very large clusters. As such, a management node actually runs the software needed for the execution of programs and management of the cluster, while the compute nodes are equipped with a standard operating system extended with typical functions for communication, storage, fault tolerance, and so on. An interesting development, as explained in Gerofi et al. [2019], is the role of the operating system. There has been a clear trend to minimize the operating system to lightweight kernels, essentially ensuring the least possible overhead. A drawback is that such operating systems become highly spe- cialized and fine-tuned toward the underlying hardware. This specialization affects compatibility, or openness. To compensate, we are now gradually seeing so-called multikernel approaches, in which a full-fledged operating system operates next to a lightweight kernel, thus achieving the best of two worlds. This combination is also necessary given increasingly more often, a high-performance compute node is required to run multiple, independent jobs simultaneously. At present, 95% of all high-performance computers run Linux-based systems; multikernel approaches are developed for multicore CPUs, with most cores running a lightweight kernel and the other running a regular Linux system. In this way, new developments such as contain- ers (which we discuss in Chapter 3) can also be supported. The effects for computing performance still needs to be seen. Grid computing A characteristic feature of traditional cluster computing is its homogeneity. In most cases, the computers in a cluster are largely the same, have the same operating system, and are all connected through the same network. However, as we just discussed, there is a continuous trend toward more hybrid architectures in which nodes are specifically configured for certain tasks. This diversity is even more prevalent in grid-computing systems : no assumptions are made concerning similarity of hardware, operating systems, networks, administrative domains, security policies, etc. [Rajaraman, 2016]. A key issue in a grid-computing system is that resources from different organizations are brought together to allow the collaboration of a group of people from different institutions, indeed forming a federation of systems. Such a collaboration is realized in the form of a virtual organization . The processes belonging to the same virtual organization have access rights to the downloaded by UMAG @AM.AMRITA.EDU DS 4.02\nQUESTION:\nDescribe the differences between grid computing and cluster computing in high-performance distributed systems.\nANSWER:\nGrid computing andcluster computing are both types of high -performance distribu ted systems, but they have some key differences:\n1. Homogeneity: Cluster computers are typically homogeneous, meaning they have the sam e operating system and hardware configuration. In contrast, grid computingsystems are heterogeneous, with nodes having different hardware and software configurations.\n2. Networking: Clusters typically have a shared network, while grid computing system s have multiple networks, including a management network and a separate network for resource sharing.\n3. Resource management: In a cluster, resources are managed by a single node or a small group of nodes, while in agrid computing system, resourcesare managed by multiple nodes across different organizations.\n4. Security: Grid computing systems have more complex security mechanisms in place to ensure the privacy and integrity of data, as resources come from different organizat ions.\n5. Scalability: Grid computin g systems are more scalable than cluster computing systems, as they can easily add new nodes to the system to increase processing power.\n6. Architecture: Grid computer ing systems have a layered architec ture, with different layers responsible for different functions, such as resource management, connectivity, and security. Cluste r computing systems typically havea simpler architecture, with all functions integrated into a single layer.\n7. Usage: Clus ters are typically used for compute-intensive applications, while grids are used for applications that require access to multiple resources across different organiz ations.\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"qr,cf,gram = evaluation_metrics(query,context,answer)\nprint(f\"Query relevance Score: {qr}\\n\"\n     f\"Context Fidelity Score: {cf}\\n\"\n     f\"Error Percentage: {gram:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T19:42:27.191111Z","iopub.execute_input":"2024-12-24T19:42:27.191874Z","iopub.status.idle":"2024-12-24T19:42:38.514470Z","shell.execute_reply.started":"2024-12-24T19:42:27.191839Z","shell.execute_reply":"2024-12-24T19:42:38.513566Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b7dfb4a78f2a410ca7a95e17421168df"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2508309b73294bd1844256782e3cfef9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a092673c63e452d881eeda3d3038ed7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"899f304dfb55412f9f050897d423dfd9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ec407f671e246b0bb4805cc29d9ebb9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"35d5621c9f6545bf83d4e94ea8e305dd"}},"metadata":{}},{"name":"stdout","text":"Query relevance Score: 99.98869895935059\nContext Fidelity Score: 72.52702713012695\nError Percentage: 6.06%\n","output_type":"stream"}],"execution_count":25},{"cell_type":"markdown","source":"# DS-Q14","metadata":{}},{"cell_type":"code","source":"query = \"Discuss the implications of partial failures in distributed systems.\"\nresults = query_faiss_index(query, top_k = 3)\npara = \"\"\nfor result in results:\n    para = para + result\n#context = extract_relevant_sentences(query, para, similarity_threshold=0.4)\ncontext = para\ncontext = clean_context(context)\ninsight,answer= generate_insight_simple(query, context)\n\nprint(\"Generated Insight:\")\nprint(insight)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T19:42:52.353859Z","iopub.execute_input":"2024-12-24T19:42:52.354230Z","iopub.status.idle":"2024-12-24T19:43:27.631016Z","shell.execute_reply.started":"2024-12-24T19:42:52.354186Z","shell.execute_reply":"2024-12-24T19:43:27.630068Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8bbb0adfcf4d4e719d7d49427fa20731"}},"metadata":{}},{"name":"stdout","text":"Generated Insight:\n\nINSTRUCTIONS:\nAnswer the users QUESTION concisely using the DOCUMENT text above.\nIf the DOCUMENT doesn’t contain the facts to answer the QUESTION return NONE\nUse simple terms so that the user can understand\nDOCUMENT:\n462 CHAPTER 8. FAULT TOLERANCE A characteristic feature of distributed systems that distinguishes them from single-machine systems is the notion of partial failure: part of the system is failing while the remaining part continues to operate, and seemingly correctly. An important goal in distributed-systems design is to construct the system in such a way that it can automatically recover from partial failures without seriously affecting the overall performance. In particular, whenever a failure occurs, the system should continue to operate in an acceptable way while repairs are being made. In other words, a distributed system is expected to be fault tolerant. In this chapter, we take a closer look at techniques to achieve fault toler- ance. After providing some general background, we will first look at process resilience through process groups. In this case, multiple identical processes cooperate, providing the appearance of a single logical process, to ensure that one or more of them can fail without a client noticing. A specifically difficult point in process groups is reaching consensus among the group members on which a client-requested operation is to perform. By now, Paxos is a commonly adopted, yet relatively intricate algorithm. We take two approaches in explaining Paxos. One that builds on how the protocol can be logically viewed as it is now, and one that gradually builds it up from scratch. The latter may help to understand many of its design decisions. We also pay extensive attention to the case in which servers may not just crash, but actually produce faulty results that cannot be immediately recognized as being faulty. Achieving fault tolerance and reliable communication are strongly related. Next to reliable client-server communication, we pay attention to reliable group communication and notably atomic multicasting. In the latter case, a message is delivered to all nonfaulty processes in a group, or to none. Having atomic multicasting makes development of fault-tolerant solutions much easier. Atomicity is a property that is important in many applications. In this chapter, we look into what are known as distributed commit protocols by which a group of processes is conducted to either jointly commit their local work, or collectively abort and return to a previous system state. Finally, we will examine how to recover from a failure. In particular, we consider when and how the state of a distributed system should be saved to allow recovery to that state later on. 8.1 Introduction to fault tolerance Fault tolerance has been subject to much research in computer science. In this section, we start with presenting the basic concepts related to processing failures, followed by a discussion of failure models. The key technique for handling failures is redundancy, which is also discussed. For more general . SUMMARY 53 Nevertheless, by following several design principles, distributed systems can be developed that strongly adhere to the goals we set out in this chapter. Distributed systems differ from traditional software because components are dispersed across a network. Not taking this dispersion into account during design time is what makes so many systems needlessly complex and results in flaws that need to be patched later on. Peter Deutsch, at the time working at Sun Microsystems, formulated these flaws as the following false assumptions that many make when developing a distributed application for the first time: • The network is reliable • The network is secure • The network is homogeneous • The topology does not change • Latency is zero • Bandwidth is infinite • Transport cost is zero • There is one administrator Note how these assumptions relate to properties that are unique to dis- tributed systems: reliability, security, heterogeneity, and topology of the network; latency and bandwidth; transport costs; and finally administrative domains. When developing nondistributed applications, most of these issues will most likely not show up. Most of the principles we discuss in this book relate immediately to these assumptions. In all cases, we will be discussing solutions to problems that are caused by the fact that one or more assumptions are false. For example, reliable networks simply do not exist and lead to the impossibility of achieving failure transparency. We devote an entire chapter to deal with the fact that networked communication is inherently insecure. We have already argued that distributed systems need to be open and take heterogeneity into account. Likewise, when discussing replication for solving scalability problems, we are essentially tackling latency and bandwidth problems. We will also touch upon management issues at various points throughout this book. 1.5 Summary A distributed system is a collection of networked computer systems in which processes and resources are spread across different computers. We make a distinction between sufficiently and necessarily spread, where the latter relates to decentralized systems. This distinction is important to make, as spreading processes and resources cannot be considered to be a goal by itself. Instead, downloaded by UMAG @AM.AMRITA.EDU DS 4.02480 CHAPTER 8. FAULT TOLERANCE Essential Paxos The assumptions under which Paxos operates are rather weak: •The distributed system is partially synchronous (in fact, it may even be asynchronous). •Communication between processes may be unreliable, meaning that messages may be lost, duplicated, or reordered. •Messages that are corrupted can be detected as such (and thus subse- quently ignored). •All operations are deterministic: once an execution is started, it is known exactly what it will do. •Processes may exhibit crash failures, but not arbitrary failures, nor do processes collude. By-and-large, these are realistic assumptions for many practical distributed systems. We first roughly follow the explanation given by Lamport [2001] and Kirsch and Amir [2008]. The algorithm operates as a network of logical processes, of which there are different types. First, there are clients that request a specific operation to be executed. At the server side, each client is represented by a single proposer , which attempts to have a client’s request accepted. Normally, a single proposer has been designated as being the leader , and drives the protocol toward reaching consensus. What we need to establish is that a proposed operation is accepted by an acceptor . If a majority of acceptors accepts the same proposal, the proposal is said to be chosen . However, what is chosen still needs to be learned . To this end, we will have a number of learner processes, each of which will execute a chosen proposal once it has been informed by a majority of acceptors. It is important to note that a single proposer, acceptor, and learner form a single physical process, running on a single machine that the client commu- nicates with, as shown in Figure 8.7. We thus assume that if, for example, a proposer crashes, then the physical process that it is part of will have crashed. By replicating this server, we aim at obtaining fault tolerance in the presence of crash failures. The basic model is that the leading proposer receives requests from clients, one at a time. A nonleading proposer forwards any client request to the leader. The leading proposer sends its proposal to all acceptors, telling each to accept the requested operation. Each acceptor will subsequently broadcast a learn message. If a learner receives the same learn message from a majority of acceptors, it knows that consensus has been reached on which operation to execute, and will execute it. DS 4.02 downloaded by UMAG @AM.AMRITA.EDU\nQUESTION:\nDiscuss the implications of partial failures in distributed systems.\nANSWER:\nPartial failures are a characteristic feature in distributed system, where part of system fails while remaining part continue to operates seemingly correct. The goal of distributed system design is fault toleranc, which means that system should automatically recover fro, partial failur without seriously affetcting overall performance .When a failure occur, system should contiou to operate acceptably while repair are being make. Distribute system differs from traditional softwares, as component are dispursed acroos network. Failure transparancy is difficult to achieve in distributed systen due to network reliability issues. Redundancy is key technique f handling failu, which involves replicatig processes and resource across different computer. Distribut system design must take into account network heterogeneities, latency, bandwidth, transport costs, and administrative domains .By following design principles presented in this chaper, distributed system can be develped that strongly aheir to fault tluranc goal.\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"qr,cf,gram = evaluation_metrics(query,context,answer)\nprint(f\"Query relevance Score: {qr}\\n\"\n     f\"Context Fidelity Score: {cf}\\n\"\n     f\"Error Percentage: {gram:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T19:43:34.222694Z","iopub.execute_input":"2024-12-24T19:43:34.223085Z","iopub.status.idle":"2024-12-24T19:43:48.071735Z","shell.execute_reply.started":"2024-12-24T19:43:34.223041Z","shell.execute_reply":"2024-12-24T19:43:48.070820Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b548300a98654ca28760220e46565a36"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bea0fb969e9a4f49851d8566f9422986"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6744e4bdf1184058aa0476820060a06c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00478c754bcf4e42a71bdc865474c04b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"41740750edbe4dc896482dc782975db9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d542cf6d5cc4dcfb75256e2980abb71"}},"metadata":{}},{"name":"stdout","text":"Query relevance Score: 99.87643957138062\nContext Fidelity Score: 73.08513522148132\nError Percentage: 17.27%\n","output_type":"stream"}],"execution_count":27},{"cell_type":"markdown","source":"# DS-Q15","metadata":{}},{"cell_type":"code","source":"query = \"How does cryptography contribute to security in distributed systems?\"\nresults = query_faiss_index(query, top_k = 3)\npara = \"\"\nfor result in results:\n    para = para + result\n#context = extract_relevant_sentences(query, para, similarity_threshold=0.4)\ncontext = para\ncontext = clean_context(context)\ninsight,answer= generate_insight_simple(query, context)\n\nprint(\"Generated Insight:\")\nprint(insight)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T19:43:53.987984Z","iopub.execute_input":"2024-12-24T19:43:53.988382Z","iopub.status.idle":"2024-12-24T19:44:16.963297Z","shell.execute_reply.started":"2024-12-24T19:43:53.988349Z","shell.execute_reply":"2024-12-24T19:44:16.962323Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7136112b039e431ebd798d8509e6958b"}},"metadata":{}},{"name":"stdout","text":"Generated Insight:\n\nINSTRUCTIONS:\nAnswer the users QUESTION concisely using the DOCUMENT text above.\nIf the DOCUMENT doesn’t contain the facts to answer the QUESTION return NONE\nUse simple terms so that the user can understand\nDOCUMENT:\n10 CHAPTER 1. INTRODUCTION •As also mentioned, there is no such thing as a nonsecured distributed system. The security perspective focuses on how to ensure authorized access to resources. To that end, we need to discuss trust in distributed systems, along with authentication, namely verifying a claimed identity. The security perspective comes last, yet later in this chapter we shall discuss a few basic instruments that are needed to understand the role of security in the previous perspectives. 1.2 Design goals Just because it is possible to build distributed systems does not necessarily mean that it is a good idea. In this section, we discuss four important goals that should be met to make building a distributed system worth the effort. A distributed system should make resources easily accessible; it should hide the fact that resources are distributed across a network; it should be open; and it should be scalable. 1.2.1 Resource sharing An important goal of a distributed system is to make it easy for users (and applications) to access and share remote resources. Resources can be virtually anything, but typical examples include peripherals, storage facilities, data, files, services, and networks, to name just a few. There are many reasons for wanting to share resources. One obvious reason is that of economics. For example, it is cheaper to have a single high-end reliable storage facility be shared than having to buy and maintain storage for each user separately. Connecting users and resources also makes it easier to collaborate and exchange information, as is illustrated by the success of the Internet with its simple protocols for exchanging files, mail, documents, audio, and video. The connectivity of the Internet has allowed geographically widely dispersed groups of people to work together by all kinds of groupware , that is, software for collaborative editing, teleconferencing, and so on, as is illustrated by multinational software-development companies that have outsourced much of their code production to Asia, but also the myriad of collaboration tools that became (more easily) available due to the COVID-19 pandemic. Resource sharing in distributed systems is also illustrated by the success of file-sharing peer-to-peer networks like BitTorrent . These distributed sys- tems make it simple for users to share files across the Internet. Peer-to-peer networks are often associated with distribution of media files such as au- dio and video. In other cases, the technology is used for distributing large amounts of data, as in the case of software updates, backup services, and data synchronization across multiple servers. Seamless integration of resource-sharing facilities in a networked environ- ment is also now commonplace. A group of users can simply place files into a downloaded by UMAG @AM.AMRITA.EDU1.2. DESIGN GOALS 21 1.2.5 Security A distributed system that is not secure, is not dependable. As mentioned, special attention is needed to ensure confidentiality and integrity, both of which are directly coupled to authorized disclosure and access of information and resources. In any computer system, authorization is done by checking whether an identified entity has proper access rights. In turn, this means that the system should know it is indeed dealing with the proper entity. For this reason, authentication is essential: verifying the correctness of a claimed identity. Equally important is the notion of trust . If a system can positively authenticate a person, what is that authentication worth if the person cannot be trusted? For this reason alone, proper authorization is important, as it may be used to limit any damage that a person, who could in hindsight not be trusted, can cause. For example, in financial systems, authorization may limit the amount of money a person is allowed to transfer between various accounts. We will discuss trust, authentication, and authorization at length in Chapter 9. Key elements needed to understand security An essential technique to making distributed systems secure is cryptography. This is not the place in this book to extensively discuss cryptography (which we also defer until Chapter 9), yet to understand how security fits into various perspectives in the following chapters, we informally introduce some of its basic elements. Keeping matters simple, security in distributed systems is all about en- crypting and decrypting data using security keys . The easiest way of consid- ering a security key Kis to see it as a function operating on some data data. We use the notation K(data)to express the fact that the key Koperates on data. There are two ways of encrypting and decrypting data. In a symmetric cryptosystem , encryption and decryption takes place with a single key. Denot- ing by EK(data)the encryption of data using key EK, and likewise DK(data) for decryption with key DK, then in a symmetric cryptosystem, the same key is used for encryption and decryption, i.e., ifdata=DK(EK(data))then DK=EK. Note that in a symmetric cryptosystem, the key will need to be kept secret by all parties that are authorized to encrypt or decrypt data. In an asymmetric cryptosystem , the keys used for encryption and decryption are different. In particular, there is a public key PKthat can be used by anyone, and a secret key SKthat is, as its name suggests, to be kept secret. Asymmetric cryptosystems are also called public-key systems . downloaded by UMAG @AM.AMRITA.EDU DS 4.02\nQUESTION:\nHow does cryptography contribute to security in distributed systems?\nANSWER:\nCryptography plays a crucial role in ensuring security in distri- buted systems. It is used to encrypt and decrypted data, ensuring that only authorized parties can access the data. Cryptography uses security keys to encrypt data, and these keys are kept secret to prevent unauthorized access. In symmetric cryptography, the Same key is use for encryption decryption. In asymmetric cryp- tography, there are public and secret keys, where the public key can be shared with anyone, while the secret key is kept private. Crypto- graphy is an essential technique for making distributed system secure.\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"qr,cf,gram = evaluation_metrics(query,context,answer)\nprint(f\"Query relevance Score: {qr}\\n\"\n     f\"Context Fidelity Score: {cf}\\n\"\n     f\"Error Percentage: {gram:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T19:44:20.965479Z","iopub.execute_input":"2024-12-24T19:44:20.966319Z","iopub.status.idle":"2024-12-24T19:44:35.754115Z","shell.execute_reply.started":"2024-12-24T19:44:20.966286Z","shell.execute_reply":"2024-12-24T19:44:35.752976Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"065ab4620ca3478987b7ecb1077e565f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fbf8ca21b4d448cea0293b158680bcce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8bd6a008512142aca9bab1cec522695d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"859fc0c954d14efb842b44bf700a21a7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c3001887627f4ffd91c39cfcc3c1640f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a3c028a5a044f8aa2611576342fb376"}},"metadata":{}},{"name":"stdout","text":"Query relevance Score: 99.9263346195221\nContext Fidelity Score: 53.043532371520996\nError Percentage: 3.19%\n","output_type":"stream"}],"execution_count":29},{"cell_type":"markdown","source":"# **Unused part**","metadata":{}},{"cell_type":"markdown","source":"# Q11","metadata":{}},{"cell_type":"code","source":"query = \"Assume that a class is implementing two interfaces. Both interfaces have one common method.What will happen? Justify your answer.\"\nresults = query_faiss_index(query, top_k = 3)\npara = \"\"\nfor result in results:\n    para = para + result\n#context = extract_relevant_sentences(query, para, similarity_threshold=0.4)\ncontext = para\ncontext = clean_context(context)\ninsight,answer= generate_insight_simple(query, context)\n\nprint(\"Generated Insight:\")\nprint(insight)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"qr,cf,gram = evaluation_metrics(query,context,answer)\nprint(f\"Query relevance Score: {qr}\\n\"\n     f\"Context Fidelity Score: {cf}\\n\"\n     f\"Error Percentage: {gram:.2f}%\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Q12","metadata":{}},{"cell_type":"code","source":"query = \"Differentiate between byte stream, character stream, data stream and object stream.\"\nresults = query_faiss_index(query, top_k = 3)\npara = \"\"\nfor result in results:\n    para = para + result\n#context = extract_relevant_sentences(query, para, similarity_threshold=0.4)\ncontext = para\ncontext = clean_context(context)\ninsight,answer= generate_insight_simple(query, context)\n\nprint(\"Generated Insight:\")\nprint(insight)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"qr,cf,gram = evaluation_metrics(query,context,answer)\nprint(f\"Query relevance Score: {qr}\\n\"\n     f\"Context Fidelity Score: {cf}\\n\"\n     f\"Error Percentage: {gram:.2f}%\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Q1-Simple**","metadata":{}},{"cell_type":"code","source":"query = \"What is the role of a constructor ?\"\nresults = query_faiss_index(query, top_k = 3)\npara = \"\"\nfor result in results:\n    para = para + result\n#context = extract_relevant_sentences(query, para, similarity_threshold=0.4)\ncontext = clean_context(para)\ninsight,answer = generate_insight_simple(query, context)\n\nprint(\"Generated Insight:\")\nprint(insight)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"query = \"What is the role of a constructor ?\"\nresults = query_faiss_index(query, top_k = 3)\npara = \"\"\nfor result in results:\n    para = para + result\n#context = extract_relevant_sentences(query, para, similarity_threshold=0.4)\ncontext = clean_context(para)\ninsight,answer = generate_insight_simple(query, context)\n\nprint(\"Generated Insight:\")\nprint(insight)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"query = \"What is the essential difference between Error and Exception in Java?\"\nresults = query_faiss_index(query, top_k = 3)\npara = \"\"\nfor result in results:\n    para = para + result\n#context = extract_relevant_sentences(query, para, similarity_threshold=0.4)\ncontext = para\ncontext = clean_context(context)\ninsight,answer = generate_insight_short(query, context)\n\nprint(\"Generated Insight:\")\nprint(insight)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"qr,cf,gram = evaluation_metrics(query,context,answer)\nprint(f\"Query relevance Score: {qr}\\n\"\n     f\"Context Fidelity Score: {cf}\\n\"\n     f\"Error Percentage: {gram:.2f}%\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Q2-short**","metadata":{}},{"cell_type":"code","source":"query = \"What is a static variable??\"\nresults = query_faiss_index(query, top_k = 3)\npara = \"\"\nfor result in results:\n    para = para + result\n#context = extract_relevant_sentences(query, para, similarity_threshold=0.4)\ncontext = para\ncontext = clean_context(context)\ninsight,answer = generate_insight_short(query, context)\n\nprint(\"Generated Insight:\")\nprint(insight)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"query = \"What year did the modern computer era begin?\"\nresults = query_faiss_index(query, top_k = 3)\npara = \"\"\nfor result in results:\n    para = para + result\ncontext = extract_relevant_sentences(query, para, similarity_threshold=0.4)\ncontext = clean_context(context)\ninsight,answer = generate_insight_short(query, context)\n\nprint(\"Generated Insight:\")\nprint(insight)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"query = \"What year did the modern computer era begin?\"\nresults = query_faiss_index(query, top_k = 3)\npara = \"\"\nfor result in results:\n    para = para + result\ncontext = extract_relevant_sentences(query, para, similarity_threshold=0.4)\ncontext = clean_context(context)\ninsight,answer = generate_insight_simple(query, context)\n\nprint(\"Generated Insight:\")\nprint(insight)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"qr,cf,gram = evaluation_metrics(query,context,answer)\nprint(f\"Query relevance Score: {qr}\\n\"\n     f\"Context Fidelity Score: {cf}\\n\"\n     f\"Error Percentage: {gram:.2f}%\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"query = \"Explain the concept of distribution transparency in distributed systems.\"\nresults = query_faiss_index(query, top_k = 3)\npara = \"\"\nfor result in results:\n    para = para + result\ncontext = extract_relevant_sentences(query, para, similarity_threshold=0.4)\ncontext = clean_context(context)\ninsight,answer = generate_insight_short(query, context)\n\nprint(\"Generated Insight:\")\nprint(insight)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"qr,cf,gram = evaluation_metrics(query,context,answer)\nprint(f\"Query relevance Score: {qr}\\n\"\n     f\"Context Fidelity Score: {cf}\\n\"\n     f\"Error Percentage: {gram:.2f}%\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"query = \"Explain the concept of distribution transparency in distributed systems.\"\nresults = query_faiss_index(query, top_k = 3)\npara = \"\"\nfor result in results:\n    para = para + result\ncontext = extract_relevant_sentences(query, para, similarity_threshold=0.4)\ncontext = clean_context(context)\ninsight,answer = generate_insight_simple(query, context)\n\nprint(\"Generated Insight:\")\nprint(insight)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"qr,cf,gram = evaluation_metrics(query,context,answer)\nprint(f\"Query relevance Score: {qr}\\n\"\n     f\"Context Fidelity Score: {cf}\\n\"\n     f\"Error Percentage: {gram:.2f}%\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"similarity = calculate_Query_relevance(query, answer)\nprint(f\"Query relevance Score: {similarity}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fidelity_score = calculate_context_fidelity(context, answer)\nprint(f\"Context Fidelity Score: {fidelity_score}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"num_errors, error_percentage = evaluate_grammar_accuracy(answer)\nprint(f\"Number of Errors: {num_errors}\")\nprint(f\"Error Percentage: {error_percentage:.2f}%\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"query = \"Differentiate between decentralized and distributed systems\"\nresults = query_faiss_index(query, top_k = 3)\npara = \"\"\nfor result in results:\n    para = para + result\ncontext = extract_relevant_sentences(query, para, similarity_threshold=0.4)\ncontext = clean_context(context)\ninsight = generate_insight_short(query, context)\n\nprint(\"Generated Insight:\")\nprint(insight)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"query = \"Differentiate between decentralized and distributed systems\"\nresults = query_faiss_index(query, top_k = 3)\npara = \"\"\nfor result in results:\n    para = para + result\ncontext = extract_relevant_sentences(query, para, similarity_threshold=0.4)\ncontext = clean_context(context)\ninsight = generate_insight_short(query, context)\n\nprint(\"Generated Insight:\")\nprint(insight)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"query = \"Differentiate between decentralized and distributed systems\"\nresults = query_faiss_index(query, top_k = 3)\npara = \"\"\nfor result in results:\n    para = para + result\ncontext = extract_relevant_sentences(query, para, similarity_threshold=0.4)\ncontext = clean_context(context)\ninsight = generate_insight_simple(query, context)\n\nprint(\"Generated Insight:\")\nprint(insight)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"query = \"What are the challenges of maintaining consistency in a distributed system with replicated data?\"\nresults = query_faiss_index(query, top_k = 3)\npara = \"\"\nfor result in results:\n    para = para + result\ncontext = extract_relevant_sentences(query, para, similarity_threshold=0.4)\ncontext = clean_context(context)\ninsight = generate_insight_short(query, context)\n\nprint(\"Generated Insight:\")\nprint(insight)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"query = \"What are the challenges of maintaining consistency in a distributed system with replicated data?\"\nresults = query_faiss_index(query, top_k = 3)\npara = \"\"\nfor result in results:\n    para = para + result\ncontext = extract_relevant_sentences(query, para, similarity_threshold=0.4)\ncontext = clean_context(context)\ninsight = generate_insight_simple(query, context)\n\nprint(\"Generated Insight:\")\nprint(insight)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"query = \"What are the two key technological developments that led to the rise of distributed systems?\"\nresults = query_faiss_index(query, top_k = 3)\npara = \"\"\nfor result in results:\n    para = para + result\ncontext = extract_relevant_sentences(query, para, similarity_threshold=0.4)\ncontext = clean_context(context)\ninsight = generate_insight_short(query, context)\n\nprint(\"Generated Insight:\")\nprint(insight)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"query = \"What are the two key technological developments that led to the rise of distributed systems?\"\nresults = query_faiss_index(query, top_k = 3)\npara = \"\"\nfor result in results:\n    para = para + result\ncontext = extract_relevant_sentences(query, para, similarity_threshold=0.4)\ncontext = clean_context(context)\ninsight = generate_insight_simple(query, context)\n\nprint(\"Generated Insight:\")\nprint(insight)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"query = \"What are the two key technological developments that led to the rise of distributed systems?\"\nresults = query_faiss_index(query, top_k = 3)\npara = \"\"\nfor result in results:\n    para = para + result\ncontext = extract_relevant_sentences(query, para, similarity_threshold=0.4)\ncontext = clean_context(context)\ninsight = generate_insight_simple(query, context)\n\nprint(\"Generated Insight:\")\nprint(insight)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"query = \"Define a decentralized system.\"\nresults = query_faiss_index(query, top_k = 3)\npara = \"\"\nfor result in results:\n    para = para + result\ncontext = extract_relevant_sentences(query, para, similarity_threshold=0.4)\ncontext = clean_context(context)\ninsight = generate_insight_simple(query, context)\n\nprint(\"Generated Insight:\")\nprint(insight)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"query = \"Define a decentralized system.\"\nresults = query_faiss_index(query, top_k = 3)\npara = \"\"\nfor result in results:\n    para = para + result\ncontext = extract_relevant_sentences(query, para, similarity_threshold=0.4)\ncontext = clean_context(context)\ninsight = generate_insight_short(query, context)\n\nprint(\"Generated Insight:\")\nprint(insight)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"query = \"What is the primary goal of a distributed system in terms of resource sharing?\"\nresults = query_faiss_index(query, top_k = 3)\npara = \"\"\nfor result in results:\n    para = para + result\ncontext = extract_relevant_sentences(query, para, similarity_threshold=0.4)\ncontext = clean_context(context)\ninsight = generate_insight_short(query, context)\n\nprint(\"Generated Insight:\")\nprint(insight)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"query = \"What is the primary goal of a distributed system in terms of resource sharing?\"\nresults = query_faiss_index(query, top_k = 3)\npara = \"\"\nfor result in results:\n    para = para + result\ncontext = extract_relevant_sentences(query, para, similarity_threshold=0.4)\ncontext = clean_context(context)\ninsight = generate_insight_simple(query, context)\n\nprint(\"Generated Insight:\")\nprint(insight)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"query = \"Analyze the trade-offs between scalability and distribution transparency in distributed systems.\"\nresults = query_faiss_index(query, top_k = 3)\npara = \"\"\nfor result in results:\n    para = para + result\ncontext = extract_relevant_sentences(query, para, similarity_threshold=0.4)\ncontext = clean_context(context)\ninsight = generate_insight_simple(query, context)\n\nprint(\"Generated Insight:\")\nprint(insight)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"query = \"Analyze the trade-offs between scalability and distribution transparency in distributed systems.\"\nresults = query_faiss_index(query, top_k = 3)\npara = \"\"\nfor result in results:\n    para = para + result\ncontext = extract_relevant_sentences(query, para, similarity_threshold=0.4)\ncontext = clean_context(context)\ninsight = generate_insight_short(query, context)\n\nprint(\"Generated Insight:\")\nprint(insight)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"query = \"Analyze the trade-offs between scalability and distribution transparency in distributed systems.\"\ngenerated_answer = \"The trade-Off between scalabilty and distribution tranparency are:1. In geographic scalability hiding latency and bandwith restriction can be difficult2. Administrative scalability may easily conflic with goals of achieving distrubution transparancy3. Full distribution transaprency is impossible to achieve and making distribution explicit can help users understand the behavior of distributed system better.\"\nsimilarity = calculate_semantic_similarity(query, generated_answer)\nprint(f\"Semantic Similarity Score: {similarity}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer, util\ndef calculate_fidelity_to_source(context, generated_answer):\n    # Generate embeddings for the context and the generated answer\n    context_embedding = model.encode(context, convert_to_tensor=True)\n    answer_embedding = model.encode(generated_answer, convert_to_tensor=True)\n    \n    # Calculate cosine similarity between the embeddings\n    similarity_score = util.pytorch_cos_sim(answer_embedding, context_embedding)\n    \n    return similarity_score.item()  # Convert tensor to a scalar value\n\n# Example usage\ncontext = (\"INTRODUCTION most choices for coming to a distributed system come from the need to im- prove the performance of a single computer system in terms of, for example, reliability, scalability, and efficiency. Design goals for distributed systems include sharing resources and ensur- ing openness. Increasingly important is designing secure distributed systems. The fact that trade-offs need to be made between achieving various forms of distribution transparency is inherent to the design of distributed systems, and can easily complicate their understanding. One specific difficult design goal that does not always blend well with achieving distribution transparency is scalability. This is particularly true for geographi- cal scalability, in which case hiding latencies and bandwidth restrictions can turn out to be difficult. Likewise, administrative scalability, by which a system is designed to span multiple administrative domains, may easily conflict with goals for achieving distribution transparency. Different types of distributed systems exist which can be classified as being oriented toward supporting computations, information processing, and pervasiveness. Distributed computing systems are typically deployed for high-performance applications, often originating from the field of parallel computing. Finally, an emerging class of distributed systems is where components are small, the system is composed in an ad hoc fashion, but most of all is no longer managed through a system administrator. The price for achieving full transparency may be surprisingly high. Note 1.2 (Discussion: Against distribution transparency) Several researchers have argued that hiding distribution will lead to only further complicating the development of distributed systems, exactly for the reason that full distribution transparency can never be achieved. A popular technique for achieving access transparency is to extend procedure calls to remote servers. As an alternative, various researchers and practitioners are now arguing for less transparency, for example, by more explicitly using message-style commu- nication, or more explicitly posting requests to, and getting results from remote machines, as is done on the Web when fetching pages. 1.2.3 Openness Another important goal of distributed systems is openness. At the same time, an open distributed system itself will often consist of components that originate from elsewhere. INTRODUCTION Degree of distribution transparency Although distribution transparency is generally considered preferable for any distributed system, there are situations in which blindly attempting to hide all distribution aspects from users is not a good idea. Likewise, a wide-area distributed system that connects a process in San Francisco to a process in Amsterdam cannot be expected to hide the fact that Mother Nature will not allow it to send a message from one process to the other in less than approximately 35 milliseconds. There is also a trade-off between a high degree of transparency and the performance of a system. Finally, there are situations in which it is not at all obvious that hiding distribution is a good idea. As distributed systems are expanding to devices that people carry around and where the very notion of location and context awareness is becoming increasingly important, it may be best to actually expose distribution rather than trying to hide it. There are other arguments against distribution transparency. Recognizing that full distribution transparency is simply impossible, we should ask our- selves whether it is even wise to pretend that we can achieve it. It may be much better to make distribution explicit so that the user and application developer are never tricked into believing that there is such a thing as transparency. The result will be that users will much better understand the (sometimes unex- pected) behavior of a distributed system, and are thus much better prepared to deal with this behavior. The conclusion is that aiming for distribution transparency may be a nice goal when designing and implementing distributed systems, but that DS 4.02 downloaded by UMAG @AM.AMRITA.EDU\"\n)\ngenerated_answer=\"The trade-Off between scalabilty and distribution tranparency are:1. In geographic scalability hiding latency and bandwith restriction can be difficult2. Administrative scalability may easily conflic with goals of achieving distrubution transparancy3. Full distribution transaprency is impossible to achieve and making distribution explicit can help users understand the behavior of distributed system better.\"\nfidelity_score = calculate_fidelity_to_source(context, generated_answer)\nprint(f\"Fidelity to Source Material Score: {fidelity_score}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"query = \"Discuss the implications of fault tolerance in centralized versus decentralized systems.\"\nresults = query_faiss_index(query, top_k = 3)\npara = \"\"\nfor result in results:\n    para = para + result\ncontext = extract_relevant_sentences(query, para, similarity_threshold=0.4)\ncontext = clean_context(context)\ninsight = generate_insight_short(query, context)\n\nprint(\"Generated Insight:\")\nprint(insight)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer, util\ndef calculate_fidelity_to_source(context, generated_answer):\n    # Generate embeddings for the context and the generated answer\n    context_embedding = model.encode(context, convert_to_tensor=True)\n    answer_embedding = model.encode(generated_answer, convert_to_tensor=True)\n    \n    # Calculate cosine similarity between the embeddings\n    similarity_score = util.pytorch_cos_sim(answer_embedding, context_embedding)\n    \n    return similarity_score.item()  # Convert tensor to a scalar value\n\n# Example usage\ncontext = (\"FAULT TOLERANCE Essential Paxos The assumptions under which Paxos operates are rather weak: •The distributed system is partially synchronous (in fact, it may even be asynchronous). By-and-large, these are realistic assumptions for many practical distributed systems. By replicating this server, we aim at obtaining fault tolerance in the presence of crash failures. PROCESS RESILIENCE 505 It should also be noted that the schemes described so far assume that nodes are either Byzantine, or collaborative. A first step toward a solution is captured in the form of BAR fault tolerance , which stands for Byzantine, Altruism, and Rationality. BAR fault tolerance is described in Aiyer et al. Consistency, availability, and partitioning Strongly related to the conditions under which consensus can (not) be reached, is when consistency can be reached. We introduced process groups to improve fault tolerance, and, more specifically, to improve availability. Being consistent in responses while also being highly available is not an unreasonable requirement for services that are part of a distributed system. In 2000, Eric Brewer posed an important theorem which was later proven to be correct by Gilbert and Lynch [2002]: CAP Theorem : Any networked system providing shared data can provide only two of the following three properties: •C: consistency, by which a shared and replicated data item appears as a single, up-to-date copy •A: availability, by which updates will always be eventually executed •P: Tolerant to the partitioning of process group (e.g., because of a failing network). COORDINATION Virtually all algorithms suffer badly in the event of crashes. It is somewhat ironic that distributed algorithms are generally more sensitive to crashes than centralized ones. In this sense, it should not come as a surprise that, indeed, centralized mutual exclusion is widely applied: it is simple to understand the behavior, and relatively easy to increase the fault tolerance of the centralized server. 5.3.6 Example: Simple locking with ZooKeeper For many practical reasons, mutual exclusion in distributed systems is often done with a centralized coordinator, not in the least because the behavior of these solutions is much easier to understand than many other noncentralized versions. Let us briefly look at a system that is designed for coordination tasks in distributed systems, and which is by now also widely deployed. It has been designed for scalability and fault tolerance. ZooKeeper’s fault tolerance aspects are discussed in Chapter 8.\")\ngenerated_answer=\"In centralized systems, fault tolerant mechanisms such as replication can be used to ensure consistency and availability of data. However, in decentralize systems, achieving fault toleranc can be more challenging due to the lack of a central authority that can enforce consistency. Instead, decentralizes systems often rely on consensus protocols such as Paxo, which can tolerate faulty nodes but may not provide strong consistency guarantees. Additionally, decentrilized systems may require more complex fault toleran mechanisms, such as Byzantium fault tolerace, to ensure the system's continuity in the face of faults or failures\"\nfidelity_score = calculate_fidelity_to_source(context, generated_answer)\nprint(f\"Fidelity to Source Material Score: {fidelity_score}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\ndef calculate_semantic_similarity(query, generated_answer):\n    # Generate embeddings for both the query and the generated answer\n    query_embedding = model.encode(query, convert_to_tensor=True)\n    answer_embedding = model.encode(generated_answer, convert_to_tensor=True)\n    \n    # Calculate cosine similarity between the embeddings\n    similarity_score = util.pytorch_cos_sim(query_embedding, answer_embedding)\n    \n    return similarity_score.item()  # Convert tensor to a scalar value\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"query = \"Discuss the implications of fault tolerance in centralized versus decentralized systems.\"\ngenerated_answer = \"In centralized systems, fault tolerant mechanisms such as replication can be used to ensure consistency and availability of data. However, in decentralize systems, achieving fault toleranc can be more challenging due to the lack of a central authority that can enforce consistency. Instead, decentralizes systems often rely on consensus protocols such as Paxo, which can tolerate faulty nodes but may not provide strong consistency guarantees. Additionally, decentrilized systems may require more complex fault toleran mechanisms, such as Byzantium fault tolerace, to ensure the system's continuity in the face of faults or failures\"\nsimilarity = calculate_semantic_similarity(query, generated_answer)\nprint(f\"Semantic Similarity Score: {similarity}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"query = \"Discuss the implications of fault tolerance in centralized versus decentralized systems.\"\ngenerated_answer = \"Fault tolerance refers to the ability of a system to continue functioning correctly even when one or more of its components fail or malfunction. In centralized systems, fault tolerant mechanisms are typically designed to protect the central component from failures, while in decentralize systems, the focus is on protecting the overall system from failuers.A real-life example of fault-tolerant centralized system is a bank's core banking system. This system is critical to the bank' operations and must be available at all times. To ensure fault toleranc, the system is designed with redundant components, such as multiple servers, storage systems, a nd network connections. If one of these components fails, the other components can take over, ensuring that the system remains available.On the other hand, a decentralzed system such as a distributed ledger like blockchain is designed to be fault-toleant by design. Since there is no central component, the failure of one node does not affect the entire system. Instead, the nodes work together to achieve consensus on the state of the ledger, ensurimg that the data remains consistent across the system.In summary, centralize systems are designed to tolerate faults in the central componenet, while decentralze systems are desgned to tolerat faults across the entire sytem.\"\nsimilarity = calculate_semantic_similarity(query, generated_answer)\nprint(f\"Semantic Similarity Score: {similarity}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"query = \"Discuss the implications of fault tolerance in centralized versus decentralized systems.\"\nresults = query_faiss_index(query, top_k = 3)\npara = \"\"\nfor result in results:\n    para = para + result\ncontext = extract_relevant_sentences(query, para, similarity_threshold=0.4)\ncontext = clean_context(context)\ninsight = generate_insight_simple(query, context)\n\nprint(\"Generated Insight:\")\nprint(insight)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"query = \"Discuss the implications of fault tolerance in centralized versus decentralized systems.\"\nresults = query_faiss_index(query, top_k = 3)\npara = \"\"\nfor result in results:\n    para = para + result\ncontext = extract_relevant_sentences(query, para, similarity_threshold=0.4)\ncontext = clean_context(context)\ninsight = generate_insight_simple(query, context)\n\nprint(\"Generated Insight:\")\nprint(insight)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"query = \"what is the port number of HTTP\"\nresults = query_faiss_index(query, top_k = 3)\npara = \"\"\nfor result in results:\n    para = para + result\ncontext = extract_relevant_sentences(query, para, similarity_threshold=0.4)\ncontext = clean_context(context)\ninsight = generate_insight_short(query, context)\n\nprint(\"Generated Insight:\")\nprint(insight)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"query = \"what is a three way handshake?\"\nresults = query_faiss_index(query, top_k = 3)\npara = \"\"\nfor result in results:\n    para = para + result\ncontext = extract_relevant_sentences(query, para, similarity_threshold=0.4)\ncontext = clean_context(context)\ninsight = generate_insight_short(query, context)\n\nprint(\"Generated Insight:\")\nprint(insight)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"query = \"when does data transfer happen in a three way handshake?\"\nresults = query_faiss_index(query, top_k = 3)\npara = \"\"\nfor result in results:\n    para = para + result\ncontext = extract_relevant_sentences(query, para, similarity_threshold=0.4)\ncontext = clean_context(context)\ninsight = generate_insight_short(query, context)\n\nprint(\"Generated Insight:\")\nprint(insight)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"query = \"what is subnetting?\"\nresults = query_faiss_index(query, top_k = 3)\npara = \"\"\nfor result in results:\n    para = para + result\ncontext = extract_relevant_sentences(query, para, similarity_threshold=0.4)\ncontext = clean_context(context)\ninsight = generate_insight_short(query, context)\n\nprint(\"Generated Insight:\")\nprint(insight)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"query = \"what is dijkstra algorithm and how it is relevant to computer networks?\"\nresults = query_faiss_index(query, top_k = 3)\npara = \"\"\nfor result in results:\n    para = para + result\ncontext = extract_relevant_sentences(query, para, similarity_threshold=0.4)\ncontext = clean_context(context)\ninsight = generate_insight_short(query, context)\n\nprint(\"Generated Insight:\")\nprint(insight)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def generate_insight_short(query):\n    # Construct a structured prompt with a clear marker\n    combined_input = (\n        f\"Imagine you are a teacher and i am a student who has no knowledge about the subject.\"\n        \n        f\"Question: {query}\\n answer the question concisely with correct spellings\"\n        f\"\\nAnswer:\"\n    )\n\n    if tokenizer.pad_token is None:\n        tokenizer.pad_token = tokenizer.eos_token\n\n    # Encode the prompt\n    inputs = tokenizer.encode_plus(\n        combined_input,\n        return_tensors='pt',\n        padding=True,\n        truncation=True,\n        max_length=4000\n    ).to('cuda')\n\n    input_ids = inputs['input_ids']\n    attention_mask = inputs['attention_mask']\n\n    # Generate the output using the model\n    \n    outputs = llm_model.generate(\n        input_ids,\n        attention_mask=attention_mask,\n        #max_new_tokens=150,\n        num_return_sequences=1,\n        no_repeat_ngram_size=3,\n        temperature=0.33,\n        top_k=10,\n        do_sample=True,\n        pad_token_id=tokenizer.eos_token_id\n    )\n\n    # Decode the generated text\n    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n\n\n    return generated_text\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"query = \"what is the prot number of HTTP?\"\ninsight = generate_insight_short(query)\n\nprint(\"Generated Insight:\")\nprint(insight)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"query = \"what is distribution transparency?\"\ninsight = generate_insight_short(query)\n\nprint(\"Generated Insight:\")\nprint(insight)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"query = \"what is three way handshake?\"\ninsight = generate_insight_short(query)\n\nprint(\"Generated Insight:\")\nprint(insight)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"query = \"what is computer networking\"\ninsight = generate_insight_short(query)\n\nprint(\"Generated Insight:\")\nprint(insight)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install textstat\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import textstat\n\n# Function to calculate various readability scores\ndef calculate_readability_scores(text):\n    scores = {\n        \"Flesch Reading Ease\": textstat.flesch_reading_ease(text),\n        \"Flesch-Kincaid Grade Level\": textstat.flesch_kincaid_grade(text),\n        \"Gunning Fog Index\": textstat.gunning_fog(text),\n        \"SMOG Index\": textstat.smog_index(text),\n        \"Automated Readability Index\": textstat.automated_readability_index(text),\n        \"Coleman-Liau Index\": textstat.coleman_liau_index(text),\n        \"Dale-Chall Readability Score\": textstat.dale_chall_readability_score(text),\n        \"Text Standard\": textstat.text_standard(text)\n    }\n    return scores\n\n# Example generated answer\ngenerated_answer = \"\"\"\nDistribution transparence is the degree to which the distribution of goods, services, or resources is openly and easily understood and accessible to all stakeholders. It refers to the ability to see how resources are allocated and how decisions are made, and to have a say in those decisions. In a transparent distribution system, information is readily available and easily accessible, and decision-making processes are open and inclusive. This can help to build trust and accountability, and can lead to more equitable and efficient distribution of resources.\n\"\"\"\n\n# Calculate readability scores\nreadability_scores = calculate_readability_scores(generated_answer)\n\n# Print the readability scores\nprint(\"Readability Scores:\")\nfor metric, score in readability_scores.items():\n    print(f\"{metric}: {score}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install language-tool-python\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import language_tool_python\n\ndef evaluate_grammar_accuracy(text):\n    # Initialize the LanguageTool object for English language\n    tool = language_tool_python.LanguageTool('en-US')\n    \n    # Check the text for grammatical errors\n    matches = tool.check(text)\n    \n    # Calculate the number of errors\n    num_errors = len(matches)\n    \n    # Print out the errors (optional, for detailed analysis\n    # Calculate the percentage of errors per word\n    num_words = len(text.split())\n    error_percentage = (num_errors / num_words) * 100 if num_words > 0 else 0\n    \n    return num_errors, error_percentage\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Example generated text\ngenerated_text = \"Computer networking is the process of connecting computers and other devices together to share resources and exchange data. It involves the use of hardware and software technologies to create a network infrastructure that allows devices to communicate and exchange information. This can include local area networks (LANs), wide area networks(WANs) and the internet.\"\n# Evaluate grammatical accuracy\nnum_errors, error_percentage = evaluate_grammar_accuracy(generated_text)\n\nprint(f\"Number of Errors: {num_errors}\")\nprint(f\"Error Percentage: {error_percentage:.2f}%\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Example data\nx = [1, 2, 3, 4, 5,6,7,8,9,10,11,12]\ny1 = [77.356112, 74.44374561, 66.12750888,79.72038388,81.69698715,10.31930596,77.64601111,\n      84.69850421,67.61313677,69.6780324,70.43831348,76.43733025]  # First line\ny2 = [78.37123871,85.71727276,60.00449657,76.70654655,82.02352524,33.73324275,64.6933198,\n      75.27422905,75.26009083,55.56576252,69.03122663,77.19646692]  # Second line\n\n# Create a plot\nplt.plot(x, y1, label='Line 1', marker='o')\nplt.plot(x, y2, label='Line 2', marker='s')\n\n# Adding title and labels\nplt.title('Double Line Graph')\nplt.xlabel('X-axis')\nplt.ylabel('Y-axis')\n\n# Adding a legend\nplt.legend()\n\n# Show the plot\nplt.grid(True)\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Example data\nx = [1, 2, 3, 4, 5,6,7,8,9,10,11,12]\ny1 = [60.51571369,54.1473031,55.15674353,59.38210487,61.00667715,19.71448809,81.62000179,\n      68.90394092,45.2965498,62.93884516,76.7865181,78.50136161]  # First line\ny2 = [60.0430727,52.42186785,46.0766077,59.44015384,78.53261828,31.54866993,73.2598424,\n      63.62524033,45.42482793,47.96879292,74.63451028,70.87694407]  # Second line\n\n# Create a plot\nplt.plot(x, y1, label='Line 1', marker='o')\nplt.plot(x, y2, label='Line 2', marker='s')\n\n# Adding title and labels\nplt.title('Double Line Graph')\nplt.xlabel('X-axis')\nplt.ylabel('Y-axis')\n\n# Adding a legend\nplt.legend()\n\n# Show the plot\nplt.grid(True)\nplt.show()\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Example data\nx = [1, 2, 3, 4, 5,6,7,8,9,10,11,12]\ny1 = [17.27,0,9.02,4.55,3.77,0,7.05,4.92,4.26,7.45,5.71,11.46]  # First line\ny2 = [0,5.88,6.67,2.22,1.85,0,3.45,5.56,0,4.23,0,0]  # Second line\n\n# Create a plot\nplt.plot(x, y1, label='Line 1', marker='o')\nplt.plot(x, y2, label='Line 2', marker='s')\n\n# Adding title and labels\nplt.title('Double Line Graph')\nplt.xlabel('X-axis')\nplt.ylabel('Y-axis')\n\n# Adding a legend\nplt.legend()\n\n# Show the plot\nplt.grid(True)\nplt.show()\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sentence_transformers import util\nfrom nltk.tokenize import sent_tokenize\ndef extract_relevant_sentences(query, paragraphs, similarity_threshold=0.5):\n    # Encode the query\n    query_embedding = model.encode(query, convert_to_tensor=True)\n    relevant_sentences = []\n    \n    # Split paragraph into sentences\n    sentences = sent_tokenize(paragraphs)\n    sentence_embeddings = model.encode(sentences, convert_to_tensor=True)\n\n    # Compute cosine similarity between the query and each sentence\n    similarities = util.pytorch_cos_sim(query_embedding, sentence_embeddings)\n\n    # Filter sentences based on the similarity threshold\n    for idx, similarity_score in enumerate(similarities[0]):\n        if similarity_score.item() >= similarity_threshold:\n            relevant_sentences.append(sentences[idx])\n\n    # Combine the relevant sentences back into a single text block\n    return ' '.join(relevant_sentences)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# *Streamlit*","metadata":{}},{"cell_type":"code","source":"%%writefile app.py\nimport streamlit as st\nimport os\nimport nltk\nfrom sentence_transformers import SentenceTransformer\nimport faiss\nimport PyPDF2\nimport numpy as np\nimport re\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nfrom language_tool_python import LanguageTool\n\nst.set_page_config(page_title=\"Teachmate Assistant\", layout=\"wide\")\n\n# Debugging logs\ndef log_debug(message):\n    print(f\"DEBUG: {message}\")\n    st.write(f\"DEBUG: {message}\")\n\n# Load models using Kaggle's GPU environment\n@st.cache_resource\ndef load_transformer_models():\n    log_debug(\"Loading Transformer models...\")\n    tokenizer = AutoTokenizer.from_pretrained(\"/kaggle/input/llama-2/pytorch/7b-chat-hf/1\", trust_remote_code=True)\n    model = AutoModelForCausalLM.from_pretrained(\n        \"/kaggle/input/llama-2/pytorch/7b-chat-hf/1\",\n        trust_remote_code=True,\n        device_map=\"auto\",\n        offload_folder=\"offload\"\n    )\n    log_debug(\"Transformer models loaded.\")\n    return tokenizer, model\n\n@st.cache_resource\ndef load_sentence_transformer():\n    log_debug(\"Loading SentenceTransformer...\")\n    model = SentenceTransformer('all-MiniLM-L6-v2')\n    log_debug(\"SentenceTransformer loaded.\")\n    return model\n\n# Utility functions\ndef extract_text_with_metadata(pdf_paths):\n    log_debug(\"Extracting text with metadata from PDFs...\")\n    paragraphs = []\n    metadata = []\n\n    for name, pdf_path in pdf_paths:\n        with open(pdf_path, 'rb') as file:\n            reader = PyPDF2.PdfReader(file)\n            for page_num, page in enumerate(reader.pages):\n                page_text = page.extract_text()\n                if page_text:\n                    lines = page_text.split('\\n')\n                    page_paragraphs = '\\n'.join(lines) + '\\n\\n'\n                    split_paragraphs = [p.strip() for p in page_paragraphs.split('\\n\\n') if p.strip()]\n                    paragraphs.extend(split_paragraphs)\n                    metadata.extend([(name, page_num + 1)] * len(split_paragraphs))\n    log_debug(f\"Extracted {len(paragraphs)} paragraphs.\")\n    return paragraphs, metadata\n\ndef query_faiss_index(query, top_k, model, paragraphs):\n    log_debug(\"Querying FAISS index...\")\n    embeddings = model.encode(paragraphs, show_progress_bar=False)\n    embeddings = embeddings / np.linalg.norm(embeddings, axis=1, keepdims=True)\n    dimension = embeddings.shape[1]\n    index = faiss.IndexFlatIP(dimension)\n    index.add(embeddings)\n    query_embedding = model.encode([query])\n    distances, indices = index.search(query_embedding, top_k)\n    log_debug(f\"FAISS query returned {len(indices[0])} results.\")\n    return [paragraphs[i] for i in indices[0]]\n\ndef clean_context(context):\n    log_debug(\"Cleaning context...\")\n    cleaned_text = context.replace('\\n', ' ')\n    cleaned_text = re.sub(r'DS \\d+\\.\\d+ downloaded by .*?@.*?\\d+\\.\\d+', '', cleaned_text)\n    return re.sub(r'\\s+', ' ', cleaned_text).strip()\n\ndef generate_insight_simple(query, context, tokenizer, llm_model):\n    log_debug(\"Generating insight...\")\n    input_text = (\n        f\"INSTRUCTIONS:\\n\"\n        f\"Answer the QUESTION using the DOCUMENT text above. If DOCUMENT does not contain facts, return NONE.\\n\"\n        f\"DOCUMENT:\\n{context}\\n\"\n        f\"QUESTION:\\n{query}\\n\"\n        f\"ANSWER:\\n\"\n    )\n    inputs = tokenizer.encode_plus(input_text, return_tensors='pt', max_length=4000, truncation=True).to('cuda')\n    outputs = llm_model.generate(inputs['input_ids'], max_new_tokens=500, no_repeat_ngram_size=3, temperature=0.3)\n    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    answer_start = generated_text.find(\"ANSWER:\") + len(\"ANSWER:\")\n    log_debug(\"Insight generated successfully.\")\n    return generated_text[answer_start:].strip()\n\n# Load models\nlog_debug(\"Initializing models...\")\nsentence_model = load_sentence_transformer()\ntokenizer, llm_model = load_transformer_models()\nlog_debug(\"Models initialized.\")\n\n# Streamlit UI\n#st.set_page_config(page_title=\"Teachmate Assistant\", layout=\"wide\")\nst.sidebar.title(\"Teachmate Assistant\")\nst.sidebar.markdown(\"An intelligent assistant to query and generate insights from uploaded documents.\")\n\npage = st.sidebar.radio(\"Navigate\", [\"Upload PDF\", \"Query & Generate Insights\"])\n\n# Upload PDFs\nif page == \"Upload PDF\":\n    st.title(\"Upload PDF\")\n    uploaded_files = st.file_uploader(\"Upload your PDF files\", type=\"pdf\", accept_multiple_files=True)\n    if uploaded_files:\n        log_debug(\"PDF files uploaded.\")\n        pdf_paths = [(file.name, file) for file in uploaded_files]\n        paragraphs, metadata = extract_text_with_metadata(pdf_paths)\n        st.session_state[\"paragraphs\"] = paragraphs\n        st.success(f\"{len(paragraphs)} paragraphs extracted and ready for querying!\")\n\n# Query and Insights\nif page == \"Query & Generate Insights\":\n    st.title(\"Query & Generate Insights\")\n    if \"paragraphs\" not in st.session_state:\n        st.warning(\"Please upload a PDF file first!\")\n    else:\n        query = st.text_input(\"Enter your query:\")\n        top_k = st.slider(\"Number of top results\", 1, 10, 3)\n\n        if st.button(\"Generate Insight\"):\n            log_debug(\"Generating insight...\")\n            paragraphs = st.session_state[\"paragraphs\"]\n            results = query_faiss_index(query, top_k, sentence_model, paragraphs)\n            context = clean_context(\" \".join(results))\n            st.write(\"### Top Results\")\n            for i, result in enumerate(results):\n                st.write(f\"**Result {i + 1}:** {result}\")\n\n            if context:\n                st.write(\"### Generating Insight...\")\n                insight = generate_insight_simple(query, context, tokenizer, llm_model)\n                st.write(f\"**Insight:** {insight}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T04:18:32.281016Z","iopub.execute_input":"2024-12-23T04:18:32.281360Z","iopub.status.idle":"2024-12-23T04:18:32.289725Z","shell.execute_reply.started":"2024-12-23T04:18:32.281317Z","shell.execute_reply":"2024-12-23T04:18:32.288890Z"}},"outputs":[{"name":"stdout","text":"Writing app.py\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"%%writefile app.py\nimport streamlit as st\nimport os\nimport nltk\nfrom sentence_transformers import SentenceTransformer\nimport faiss\nimport PyPDF2\nimport numpy as np\nimport re\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nfrom language_tool_python import LanguageTool\n\n# Load models using Kaggle's GPU environment\n@st.cache_resource\ndef load_transformer_models():\n    tokenizer = AutoTokenizer.from_pretrained(\"/kaggle/input/llama-2/pytorch/7b-chat-hf/1\", trust_remote_code=True)\n    model = AutoModelForCausalLM.from_pretrained(\n        \"/kaggle/input/llama-2/pytorch/7b-chat-hf/1\",\n        trust_remote_code=True,\n        device_map=\"auto\",\n        offload_folder=\"offload\"\n    )\n    return tokenizer, model\n\n@st.cache_resource\ndef load_sentence_transformer():\n    return SentenceTransformer('all-MiniLM-L6-v2')\n\n# Utility functions\ndef extract_text_with_metadata(pdf_paths):\n    paragraphs = []\n    metadata = []\n\n    for name, pdf_path in pdf_paths:\n        with open(pdf_path, 'rb') as file:\n            reader = PyPDF2.PdfReader(file)\n            for page_num, page in enumerate(reader.pages):\n                page_text = page.extract_text()\n                if page_text:\n                    lines = page_text.split('\\n')\n                    page_paragraphs = '\\n'.join(lines) + '\\n\\n'\n                    split_paragraphs = [p.strip() for p in page_paragraphs.split('\\n\\n') if p.strip()]\n                    paragraphs.extend(split_paragraphs)\n                    metadata.extend([(name, page_num + 1)] * len(split_paragraphs))\n    return paragraphs, metadata\n\ndef query_faiss_index(query, top_k, model, paragraphs):\n    embeddings = model.encode(paragraphs, show_progress_bar=False)\n    embeddings = embeddings / np.linalg.norm(embeddings, axis=1, keepdims=True)\n    dimension = embeddings.shape[1]\n    index = faiss.IndexFlatIP(dimension)\n    index.add(embeddings)\n    query_embedding = model.encode([query])\n    distances, indices = index.search(query_embedding, top_k)\n    return [paragraphs[i] for i in indices[0]]\n\ndef clean_context(context):\n    cleaned_text = context.replace('\\n', ' ')\n    cleaned_text = re.sub(r'DS \\d+\\.\\d+ downloaded by .*?@.*?\\d+\\.\\d+', '', cleaned_text)\n    return re.sub(r'\\s+', ' ', cleaned_text).strip()\n\ndef generate_insight_simple(query, context, tokenizer, llm_model):\n    input_text = (\n        f\"INSTRUCTIONS:\\n\"\n        f\"Answer the QUESTION using the DOCUMENT text above. If DOCUMENT does not contain facts, return NONE.\\n\"\n        f\"DOCUMENT:\\n{context}\\n\"\n        f\"QUESTION:\\n{query}\\n\"\n        f\"ANSWER:\\n\"\n    )\n    inputs = tokenizer.encode_plus(input_text, return_tensors='pt', max_length=4000, truncation=True).to('cuda')\n    outputs = llm_model.generate(inputs['input_ids'], max_new_tokens=500, no_repeat_ngram_size=3, temperature=0.3)\n    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    answer_start = generated_text.find(\"ANSWER:\") + len(\"ANSWER:\")\n    return generated_text[answer_start:].strip()\n\n# Load models\nsentence_model = load_sentence_transformer()\ntokenizer, llm_model = load_transformer_models()\n\n# Streamlit UI\nst.set_page_config(page_title=\"Teachmate Assistant\", layout=\"wide\")\nst.sidebar.title(\"Teachmate Assistant\")\nst.sidebar.markdown(\"An intelligent assistant to query and generate insights from uploaded documents.\")\n\npage = st.sidebar.radio(\"Navigate\", [\"Upload PDF\", \"Query & Generate Insights\"])\n\n# Upload PDFs\nif page == \"Upload PDF\":\n    st.title(\"Upload PDF\")\n    uploaded_files = st.file_uploader(\"Upload your PDF files\", type=\"pdf\", accept_multiple_files=True)\n    if uploaded_files:\n        pdf_paths = [(file.name, file) for file in uploaded_files]\n        paragraphs, metadata = extract_text_with_metadata(pdf_paths)\n        st.session_state[\"paragraphs\"] = paragraphs\n        st.success(f\"{len(paragraphs)} paragraphs extracted and ready for querying!\")\n\n# Query and Insights\nif page == \"Query & Generate Insights\":\n    st.title(\"Query & Generate Insights\")\n    if \"paragraphs\" not in st.session_state:\n        st.warning(\"Please upload a PDF file first!\")\n    else:\n        query = st.text_input(\"Enter your query:\")\n        top_k = st.slider(\"Number of top results\", 1, 10, 3)\n\n        if st.button(\"Generate Insight\"):\n            paragraphs = st.session_state[\"paragraphs\"]\n            results = query_faiss_index(query, top_k, sentence_model, paragraphs)\n            context = clean_context(\" \".join(results))\n            st.write(\"### Top Results\")\n            for i, result in enumerate(results):\n                st.write(f\"**Result {i + 1}:** {result}\")\n\n            if context:\n                st.write(\"### Generating Insight...\")\n                insight = generate_insight_simple(query, context, tokenizer, llm_model)\n                st.write(f\"**Insight:** {insight}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install streamlit","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T04:18:51.783710Z","iopub.execute_input":"2024-12-23T04:18:51.783995Z","iopub.status.idle":"2024-12-23T04:19:02.680602Z","shell.execute_reply.started":"2024-12-23T04:18:51.783968Z","shell.execute_reply":"2024-12-23T04:19:02.679522Z"}},"outputs":[{"name":"stdout","text":"Collecting streamlit\n  Downloading streamlit-1.41.1-py2.py3-none-any.whl.metadata (8.5 kB)\nRequirement already satisfied: altair<6,>=4.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (5.4.0)\nRequirement already satisfied: blinker<2,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (1.8.2)\nRequirement already satisfied: cachetools<6,>=4.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (4.2.4)\nRequirement already satisfied: click<9,>=7.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (8.1.7)\nRequirement already satisfied: numpy<3,>=1.23 in /opt/conda/lib/python3.10/site-packages (from streamlit) (1.26.4)\nRequirement already satisfied: packaging<25,>=20 in /opt/conda/lib/python3.10/site-packages (from streamlit) (21.3)\nRequirement already satisfied: pandas<3,>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (2.2.2)\nRequirement already satisfied: pillow<12,>=7.1.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (9.5.0)\nRequirement already satisfied: protobuf<6,>=3.20 in /opt/conda/lib/python3.10/site-packages (from streamlit) (3.20.3)\nRequirement already satisfied: pyarrow>=7.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (16.1.0)\nRequirement already satisfied: requests<3,>=2.27 in /opt/conda/lib/python3.10/site-packages (from streamlit) (2.32.3)\nRequirement already satisfied: rich<14,>=10.14.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (13.7.1)\nRequirement already satisfied: tenacity<10,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (8.3.0)\nRequirement already satisfied: toml<2,>=0.10.1 in /opt/conda/lib/python3.10/site-packages (from streamlit) (0.10.2)\nRequirement already satisfied: typing-extensions<5,>=4.3.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (4.12.2)\nCollecting watchdog<7,>=2.1.5 (from streamlit)\n  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /opt/conda/lib/python3.10/site-packages (from streamlit) (3.1.43)\nCollecting pydeck<1,>=0.8.0b4 (from streamlit)\n  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\nRequirement already satisfied: tornado<7,>=6.0.3 in /opt/conda/lib/python3.10/site-packages (from streamlit) (6.4.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit) (3.1.4)\nRequirement already satisfied: jsonschema>=3.0 in /opt/conda/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit) (4.22.0)\nRequirement already satisfied: narwhals>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit) (1.4.2)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging<25,>=20->streamlit) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas<3,>=1.4.0->streamlit) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas<3,>=1.4.0->streamlit) (2024.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (2024.7.4)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\nRequirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.2.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\nRequirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\nRequirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.18.1)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.16.0)\nDownloading streamlit-1.41.1-py2.py3-none-any.whl (9.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m95.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: watchdog, pydeck, streamlit\nSuccessfully installed pydeck-0.9.1 streamlit-1.41.1 watchdog-6.0.0\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"!streamlit run app.py --server.port 8501 --server.headless true --browser.serverAddress=0.0.0.0 --browser.gatherUsageStats=false","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install pyngrok\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T04:18:42.531170Z","iopub.execute_input":"2024-12-23T04:18:42.532289Z","iopub.status.idle":"2024-12-23T04:18:51.782031Z","shell.execute_reply.started":"2024-12-23T04:18:42.532240Z","shell.execute_reply":"2024-12-23T04:18:51.780979Z"}},"outputs":[{"name":"stdout","text":"Collecting pyngrok\n  Downloading pyngrok-7.2.2-py3-none-any.whl.metadata (8.4 kB)\nRequirement already satisfied: PyYAML>=5.1 in /opt/conda/lib/python3.10/site-packages (from pyngrok) (6.0.2)\nDownloading pyngrok-7.2.2-py3-none-any.whl (22 kB)\nInstalling collected packages: pyngrok\nSuccessfully installed pyngrok-7.2.2\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"from pyngrok import ngrok\n\n# Expose the Streamlit app on port 8501\npublic_url = ngrok.connect(8501)\nprint(f\"Access your Streamlit app at: {public_url}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!ngrok authtoken 2qYhwo7TvkByosPhNPAi863W1rk_7ETwHNM8ypsWkFDKZGiWP","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T04:19:04.129914Z","iopub.execute_input":"2024-12-23T04:19:04.130689Z","iopub.status.idle":"2024-12-23T04:19:05.881247Z","shell.execute_reply.started":"2024-12-23T04:19:04.130652Z","shell.execute_reply":"2024-12-23T04:19:05.880180Z"}},"outputs":[{"name":"stdout","text":"Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml                                \n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"from pyngrok import ngrok\nimport subprocess\n\n# Start the Streamlit server as a background process\nsubprocess.Popen([\"streamlit\", \"run\", \"app.py\", \"--server.port\", \"8501\", \"--server.headless\", \"true\"])\n\n# Create an ngrok tunnel to the Streamlit port\npublic_url = ngrok.connect(8501)\nprint(f\"Access your Streamlit app at: {public_url}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T04:19:09.315356Z","iopub.execute_input":"2024-12-23T04:19:09.315768Z","iopub.status.idle":"2024-12-23T04:19:09.694652Z","shell.execute_reply.started":"2024-12-23T04:19:09.315735Z","shell.execute_reply":"2024-12-23T04:19:09.693816Z"}},"outputs":[{"name":"stdout","text":"Access your Streamlit app at: NgrokTunnel: \"https://46c2-35-227-82-169.ngrok-free.app\" -> \"http://localhost:8501\"\n\nCollecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n\n\n  You can now view your Streamlit app in your browser.\n\n  Local URL: http://localhost:8501\n  Network URL: http://172.19.2.2:8501\n  External URL: http://35.227.82.169:8501\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"DEBUG: Initializing models...\nDEBUG: Loading SentenceTransformer...\nDEBUG: SentenceTransformer loaded.\nDEBUG: Loading Transformer models...\n","output_type":"stream"},{"name":"stderr","text":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"!streamlit run app.py --server.port 8501 --server.headless true","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!ps -ef | grep streamlit\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}